[
    {
        "id": "http://arxiv.org/abs/2601.19774v1",
        "title": "Cure models: from mixture to matrix distributions",
        "summary": "Cure rate models address survival data in which a proportion of individuals will never experience the event of interest. Existing parametric approaches are predominantly based on finite mixtures, which impose restrictive assumptions on both the cure mechanism and the distribution of susceptible event times. A cure model based on phase-type distributions is introduced, leveraging their latent Markov jump process representation to allow immunity to occur either at baseline or dynamically during follow-up. This structure yields a flexible and interpretable formulation of long-term survival while encompassing classical mixture cure models as special cases. A unified regression framework is developed for covariate effects on both the cure rate and the susceptible survival distribution, and the proposed model class is dense, reducing the impact of parametric misspecification. Estimation is performed via expectation-maximization algorithms, accompanied by an automatic model selection strategy. Simulation studies and a real-data example demonstrate the practical advantages of the approach.",
        "authors": "Martin Bladt, Jorge Yslas",
        "url": "http://arxiv.org/abs/2601.19774v1",
        "pdf_url": "https://arxiv.org/pdf/2601.19774v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 3,
            "Clarity": 4
        },
        "reason_zh": "这篇论文提出了基于相型分布的治愈率模型，利用隐式马尔可夫跳跃过程，提供了统一的回归框架和理论上的“密集模型类”特性，并采用EM算法进行估计。其严谨的统计建模和理论分析与您的偏好高度契合。"
    },
    {
        "id": "http://arxiv.org/abs/2601.19759v1",
        "title": "Unique Preference Aggregation in Design and Decision Making",
        "summary": "Preference aggregation is a core operation in multi-objective design optimisation and group decision-making, as it determines the best-fit-for-common-purpose alternative within complex socio-technical contexts. Therefore, their aggregation requires a rigorous measurement-theoretic foundation to ensure mathematical validity, interpretability, and uniqueness. PFM establishes the principal axioms of unique preference aggregation, providing a rigorous basis on which aggregation can be demonstrated.   In this paper, it is shown that commonly used aggregation approaches in MCDM - such as weighted arithmetic and geometric means, as well as weighted distance-based optimisation methods - often fail to produce consistent rankings and are therefore unsuitable for pure MCDM. In contrast, the unique preference aggregation presented here clarifies the mathematical limits of valid aggregation and provides a principled, implementable foundation for robust multi-criteria decision analysis (MCDA) and multi-objective design optimisation (MODO) in multi-faceted problems.",
        "authors": "A. R. M., Wolfert",
        "url": "http://arxiv.org/abs/2601.19759v1",
        "pdf_url": "https://arxiv.org/pdf/2601.19759v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 3,
            "Clarity": 4
        },
        "reason_zh": "该论文建立了偏好聚合的严格测量理论基础，强调数学有效性和唯一性，并对现有MCDM方法进行了批判性分析。其对数学基础和理论严谨性的追求与您的研究方向非常吻合。"
    },
    {
        "id": "http://arxiv.org/abs/2601.19730v1",
        "title": "Stability and Generalization of Nonconvex Optimization with Heavy-Tailed Noise",
        "summary": "The empirical evidence indicates that stochastic optimization with heavy-tailed gradient noise is more appropriate to characterize the training of machine learning models than that with standard bounded gradient variance noise. Most existing works on this phenomenon focus on the convergence of optimization errors, while the analysis for generalization bounds under the heavy-tailed gradient noise remains limited. In this paper, we develop a general framework for establishing generalization bounds under heavy-tailed noise. Specifically, we introduce a truncation argument to achieve the generalization error bound based on the algorithmic stability under the assumption of bounded $p$th centered moment with $p\\in(1,2]$. Building on this framework, we further provide the stability and generalization analysis for several popular stochastic algorithms under heavy-tailed noise, including clipped and normalized stochastic gradient descent, as well as their mini-batch and momentum variants.",
        "authors": "Hongxu Chen, Ke Wei, Xiaoming Yuan, Luo Luo",
        "url": "http://arxiv.org/abs/2601.19730v1",
        "pdf_url": "https://arxiv.org/pdf/2601.19730v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 3,
            "Clarity": 4
        },
        "reason_zh": "这篇论文针对重尾梯度噪声下的非凸优化，提出了建立泛化界限的通用框架，并对多种随机算法的稳定性和泛化性进行了理论分析。这在优化收敛性和统计保证方面具有极高的理论严谨性。"
    },
    {
        "id": "http://arxiv.org/abs/2601.19666v1",
        "title": "Direct Doubly Robust Estimation of Conditional Quantile Contrasts",
        "summary": "Within heterogeneous treatment effect (HTE) analysis, various estimands have been proposed to capture the effect of a treatment conditional on covariates. Recently, the conditional quantile comparator (CQC) has emerged as a promising estimand, offering quantile-level summaries akin to the conditional quantile treatment effect (CQTE) while preserving some interpretability of the conditional average treatment effect (CATE). It achieves this by summarising the treated response conditional on both the covariates and the untreated response. Despite these desirable properties, the CQC's current estimation is limited by the need to first estimate the difference in conditional cumulative distribution functions and then invert it. This inversion obscures the CQC estimate, hampering our ability to both model and interpret it. To address this, we propose the first direct estimator of the CQC, allowing for explicit modelling and parameterisation. This explicit parameterisation enables better interpretation of our estimate while also providing a means to constrain and inform the model. We show, both theoretically and empirically, that our estimation error depends directly on the complexity of the CQC itself, improving upon the existing estimation procedure. Furthermore, it retains the desirable double robustness property with respect to nuisance parameter estimation. We further show our method to outperform existing procedures in estimation accuracy across multiple data scenarios while varying sample size and nuisance error. Finally, we apply it to real-world data from an employment scheme, uncovering a reduced range of potential earnings improvement as participant age increases.",
        "authors": "Josh Givens, Song Liu, Henry W J Reeve, Katarzyna Reluga",
        "url": "http://arxiv.org/abs/2601.19666v1",
        "pdf_url": "https://arxiv.org/pdf/2601.19666v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该论文提出了条件分位数对比（CQC）的首个直接估计器，理论上证明了其估计误差与CQC本身的复杂性相关，并保留了双重鲁棒性。这在因果推断和统计保证方面提供了强大的理论贡献。"
    },
    {
        "id": "http://arxiv.org/abs/2601.19597v1",
        "title": "The Geometric Mechanics of Contrastive Representation Learning: Alignment Potentials, Entropic Dispersion, and Cross-Modal Divergence",
        "summary": "While InfoNCE powers modern contrastive learning, its geometric mechanisms remain under-characterized beyond the canonical alignment--uniformity decomposition. We present a measure-theoretic framework that models learning as the evolution of representation measures on a fixed embedding manifold. By establishing value and gradient consistency in the large-batch limit, we bridge the stochastic objective to explicit deterministic energy landscapes, uncovering a fundamental geometric bifurcation between the unimodal and multimodal regimes. In the unimodal setting, the intrinsic landscape is strictly convex with a unique Gibbs equilibrium; here, entropy acts merely as a tie-breaker, clarifying \"uniformity\" as a constrained expansion within the alignment basin. In contrast, the symmetric multimodal objective contains a persistent negative symmetric divergence term that remains even after kernel sharpening. We show that this term induces barrier-driven co-adaptation, enforcing a population-level modality gap as a structural geometric necessity rather than an initialization artifact. Our results shift the analytical lens from pointwise discrimination to population geometry, offering a principled basis for diagnosing and controlling distributional misalignment.",
        "authors": "Yichao Cai, Zhen Zhang, Yuhang Liu, Javen Qinfeng Shi",
        "url": "http://arxiv.org/abs/2601.19597v1",
        "pdf_url": "https://arxiv.org/pdf/2601.19597v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 3,
            "Clarity": 4
        },
        "reason_zh": "这篇论文提出了对比学习的测度论几何机制框架，分析了其能量景观、吉布斯均衡和对称多模态目标中的负对称散度项。这篇论文对现代AI系统的理论基础进行了深入的数学分析，创新性和严谨性都极高。"
    },
    {
        "id": "http://arxiv.org/abs/2601.19595v1",
        "title": "Intersectional Fairness via Mixed-Integer Optimization",
        "summary": "The deployment of Artificial Intelligence in high-risk domains, such as finance and healthcare, necessitates models that are both fair and transparent. While regulatory frameworks, including the EU's AI Act, mandate bias mitigation, they are deliberately vague about the definition of bias. In line with existing research, we argue that true fairness requires addressing bias at the intersections of protected groups. We propose a unified framework that leverages Mixed-Integer Optimization (MIO) to train intersectionally fair and intrinsically interpretable classifiers. We prove the equivalence of two measures of intersectional fairness (MSD and SPSF) in detecting the most unfair subgroup and empirically demonstrate that our MIO-based algorithm improves performance in finding bias. We train high-performing, interpretable classifiers that bound intersectional bias below an acceptable threshold, offering a robust solution for regulated industries and beyond.",
        "authors": "Jiří Němeček, Mark Kozdoba, Illia Kryvoviaz, Tomáš Pevný, Jakub Mareček",
        "url": "http://arxiv.org/abs/2601.19595v1",
        "pdf_url": "https://arxiv.org/pdf/2601.19595v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该论文利用混合整数优化（MIO）框架实现交叉公平性，并理论证明了两种公平性度量（MSD和SPSF）的等价性。这篇论文在优化理论和统计保证（公平性）方面具有很强的理论基础。"
    },
    {
        "id": "http://arxiv.org/abs/2601.19321v1",
        "title": "Predictive Accuracy versus Interpretability in Energy Markets: A Copula-Enhanced TVP-SVAR Analysis",
        "summary": "This paper investigates whether structural econometric models can rival machine learning in forecasting energy--macro dynamics while retaining causal interpretability. Using monthly data from 1999 to 2025, we develop a unified framework that integrates Time-Varying Parameter Structural VARs (TVP-SVAR) with advanced dependence structures, including DCC-GARCH, t-copulas, and mixed Clayton--Frank--Gumbel copulas. These models are empirically evaluated against leading machine learning techniques Gaussian Process Regression (GPR), Artificial Neural Networks, Random Forests, and Support Vector Regression across seven macro-financial and energy variables, with Brent crude oil as the central asset. The findings reveal three major insights. First, TVP-SVAR consistently outperforms standard VAR models, confirming structural instability in energy transmission channels. Second, copula-based extensions capture non-linear and tail dependence more effectively than symmetric DCC models, particularly during periods of macroeconomic stress. Third, despite their methodological differences, copula-enhanced econometric models and GPR achieve statistically equivalent predictive accuracy (t-test p = 0.8444). However, only the econometric approach provides interpretable impulse responses, regime shifts, and tail-risk diagnostics. We conclude that machine learning can replicate predictive performance but cannot substitute the explanatory power of structural econometrics. This synthesis offers a pathway where AI accuracy and economic interpretability jointly inform energy policy and risk management.",
        "authors": "Fredy Pokou, Jules Sadefo Kamdem, Kpante Emmanuel Gnandi",
        "url": "http://arxiv.org/abs/2601.19321v1",
        "pdf_url": "https://arxiv.org/pdf/2601.19321v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "这篇论文结合时变参数结构VAR模型和高级Copula结构，对能源市场进行预测和因果解释。强调了结构计量经济学模型的因果可解释性，并在理论上处理了非线性和尾部依赖性，统计严谨性高。"
    },
    {
        "id": "http://arxiv.org/abs/2601.19256v1",
        "title": "E-QRGMM: Efficient Generative Metamodeling for Covariate-Dependent Uncertainty Quantification",
        "summary": "Covariate-dependent uncertainty quantification in simulation-based inference is crucial for high-stakes decision-making but remains challenging due to the limitations of existing methods such as conformal prediction and classical bootstrap, which struggle with covariate-specific conditioning. We propose Efficient Quantile-Regression-Based Generative Metamodeling (E-QRGMM), a novel framework that accelerates the quantile-regression-based generative metamodeling (QRGMM) approach by integrating cubic Hermite interpolation with gradient estimation. Theoretically, we show that E-QRGMM preserves the convergence rate of the original QRGMM while reducing grid complexity from $O(n^{1/2})$ to $O(n^{1/5})$ for the majority of quantile levels, thereby substantially improving computational efficiency. Empirically, E-QRGMM achieves a superior trade-off between distributional accuracy and training speed compared to both QRGMM and other advanced deep generative models on synthetic and practical datasets. Moreover, by enabling bootstrap-based construction of confidence intervals for arbitrary estimands of interest, E-QRGMM provides a practical solution for covariate-dependent uncertainty quantification.",
        "authors": "Zhiyang Liang, Qingkai Zhang",
        "url": "http://arxiv.org/abs/2601.19256v1",
        "pdf_url": "https://arxiv.org/pdf/2601.19256v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该论文提出了高效的生成式元建模方法用于协变量依赖的不确定性量化，理论上证明了其收敛速度和网格复杂度的改进，并支持基于Bootstrap的置信区间构建。这篇论文在统计保证和理论效率方面表现出色。"
    },
    {
        "id": "http://arxiv.org/abs/2601.19223v1",
        "title": "Nonlocal Kramers-Moyal formulas and data-driven discovery of stochastic dynamical systems with multiplicative Lévy noise",
        "summary": "Traditional data-driven methods, effective for deterministic systems or stochastic differential equations (SDEs) with Gaussian noise, fail to handle the discontinuous sample paths and heavy-tailed fluctuations characteristic of Lévy processes, particularly when the noise is state-dependent. To bridge this gap, we establish nonlocal Kramers-Moyal formulas, rigorously generalizing the classical Kramers-Moyal relations to SDEs with multiplicative Lévy noise. These formulas provide a direct link between short-time transition probability densities (or sample path statistics) and the underlying SDE coefficients: the drift vector, diffusion matrix, Lévy jump measure kernel, and Lévy noise intensity functions. Leveraging these theoretical foundations, we develop novel data-driven algorithms capable of simultaneously identifying all governing components from data and establish convergence results and error analysis for the algorithms. We validate the framework through extensive numerical experiments on prototypical systems. This work provides a principled and practical toolbox for discovering interpretable SDE models governing complex systems influenced by discontinuous, heavy-tailed, state-dependent fluctuations, with broad applicability in climate science, neuroscience, epidemiology, finance, and biological physics.",
        "authors": "Yang Li, Jinqiao Duan",
        "url": "http://arxiv.org/abs/2601.19223v1",
        "pdf_url": "https://arxiv.org/pdf/2601.19223v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 3,
            "Clarity": 4
        },
        "reason_zh": "这篇论文严格推广了Kramers-Moyal公式到乘性Lévy噪声下的随机微分方程，并建立了数据驱动算法的收敛性和误差分析。这在随机过程和数学推导方面具有极高的理论深度和严谨性。"
    },
    {
        "id": "http://arxiv.org/abs/2601.19208v1",
        "title": "How Do Transformers Learn to Associate Tokens: Gradient Leading Terms Bring Mechanistic Interpretability",
        "summary": "Semantic associations such as the link between \"bird\" and \"flew\" are foundational for language modeling as they enable models to go beyond memorization and instead generalize and generate coherent text. Understanding how these associations are learned and represented in language models is essential for connecting deep learning with linguistic theory and developing a mechanistic foundation for large language models. In this work, we analyze how these associations emerge from natural language data in attention-based language models through the lens of training dynamics. By leveraging a leading-term approximation of the gradients, we develop closed-form expressions for the weights at early stages of training that explain how semantic associations first take shape. Through our analysis, we reveal that each set of weights of the transformer has closed-form expressions as simple compositions of three basis functions (bigram, token-interchangeability, and context mappings), reflecting the statistics of the text corpus and uncovering how each component of the transformer captures semantic associations based on these compositions. Experiments on real-world LLMs demonstrate that our theoretical weight characterizations closely match the learned weights, and qualitative analyses further show how our theorem shines light on interpreting the learned associations in transformers.",
        "authors": "Shawn Im, Changdae Oh, Zhen Fang, Sharon Li",
        "url": "http://arxiv.org/abs/2601.19208v1",
        "pdf_url": "https://arxiv.org/pdf/2601.19208v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该论文通过梯度主导项近似，为Transformer学习token关联性提供了闭式表达式，揭示了其学习机制。这篇论文对现代AI核心模型（Transformer）的学习原理进行了深入的数学分析和理论推导。"
    },
    {
        "id": "http://arxiv.org/abs/2601.19195v1",
        "title": "On the SOS Rank of Simple and Diagonal Biquadratic Forms",
        "summary": "We study the sum-of-squares (SOS) rank of simple and diagonal biquadratic forms. For simple biquadratic forms in $3 \\times 3$ variables, we show that the maximum SOS rank is exactly $6$, attained by a specific six-term form. We further prove that for any $m \\ge 3$, there exists an $m \\times m$ simple biquadratic form whose SOS rank is exactly $2m$, providing a general lower bound that extends the $3\\times3$ case. For diagonal biquadratic forms with nonnegative coefficients, we prove an SOS rank upper bound of $7$, improving the general bound of $8$ for $3 \\times 3$ forms. In addition, we extend the techniques to a broader class of \\textbf{sparse biquadratic forms}, obtaining combinatorial upper bounds and constructing explicit families whose SOS rank grows linearly with the number of terms. These results provide new lower and upper bounds on the worst-case SOS rank of biquadratic forms and highlight the role of structure in reducing the required number of squares.",
        "authors": "Yi Xu, Chufeng Cui, Liqun Qi",
        "url": "http://arxiv.org/abs/2601.19195v1",
        "pdf_url": "https://arxiv.org/pdf/2601.19195v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 2,
            "Clarity": 4
        },
        "reason_zh": "这是一篇纯数学论文，研究了双二次形式的平方和（SOS）秩，提供了新的上下界和组合上界。这篇论文在数学逻辑和理论基础方面非常严谨。"
    },
    {
        "id": "http://arxiv.org/abs/2601.19186v1",
        "title": "Double Fairness Policy Learning: Integrating Action Fairness and Outcome Fairness in Decision-making",
        "summary": "Fairness is a central pillar of trustworthy machine learning, especially in domains where accuracy- or profit-driven optimization is insufficient. While most fairness research focuses on supervised learning, fairness in policy learning remains less explored. Because policy learning is interventional, it induces two distinct fairness targets: action fairness (equitable action assignments) and outcome fairness (equitable downstream consequences). Crucially, equalizing actions does not generally equalize outcomes when groups face different constraints or respond differently to the same action. We propose a novel double fairness learning (DFL) framework that explicitly manages the trade-off among three objectives: action fairness, outcome fairness, and value maximization. We integrate fairness directly into a multi-objective optimization problem for policy learning and employ a lexicographic weighted Tchebyshev method that recovers Pareto solutions beyond convex settings, with theoretical guarantees on the regret bounds. Our framework is flexible and accommodates various commonly used fairness notions. Extensive simulations demonstrate improved performance relative to competing methods. In applications to a motor third-party liability insurance dataset and an entrepreneurship training dataset, DFL substantially improves both action and outcome fairness while incurring only a modest reduction in overall value.",
        "authors": "Zeyu Bian, Lan Wang, Chengchun Shi, Zhengling Qi",
        "url": "http://arxiv.org/abs/2601.19186v1",
        "pdf_url": "https://arxiv.org/pdf/2601.19186v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该论文提出了双重公平性策略学习框架，将其建模为多目标优化问题，并提供了关于遗憾界限的理论保证。这篇论文在优化理论、公平性理论和统计保证方面具有强大的理论基础。"
    },
    {
        "id": "http://arxiv.org/abs/2601.19121v1",
        "title": "LLMs as Orchestrators: Constraint-Compliant Multi-Agent Optimization for Recommendation Systems",
        "summary": "Recommendation systems must optimize multiple objectives while satisfying hard business constraints such as fairness and coverage. For example, an e-commerce platform may require every recommendation list to include items from multiple sellers and at least one newly listed product; violating such constraints--even once--is unacceptable in production. Prior work on multi-objective recommendation and recent LLM-based recommender agents largely treat constraints as soft penalties or focus on item scoring and interaction, leading to frequent violations in real-world deployments. How to leverage LLMs for coordinating constrained optimization in recommendation systems remains underexplored. We propose DualAgent-Rec, an LLM-coordinated dual-agent framework for constrained multi-objective e-commerce recommendation. The framework separates optimization into an Exploitation Agent that prioritizes accuracy under hard constraints and an Exploration Agent that promotes diversity through unconstrained Pareto search. An LLM-based coordinator adaptively allocates resources between agents based on optimization progress and constraint satisfaction, while an adaptive epsilon-relaxation mechanism guarantees feasibility of final solutions. Experiments on the Amazon Reviews 2023 dataset demonstrate that DualAgent-Rec achieves 100% constraint satisfaction and improves Pareto hypervolume by 4-6% over strong baselines, while maintaining competitive accuracy-diversity trade-offs. These results indicate that LLMs can act as effective orchestration agents for deployable and constraint-compliant recommendation systems.",
        "authors": "Guilin Zhang, Kai Zhao, Jeffrey Friedman, Xu Chu",
        "url": "http://arxiv.org/abs/2601.19121v1",
        "pdf_url": "https://arxiv.org/pdf/2601.19121v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "这篇论文利用LLM协调多智能体进行受限多目标优化，并引入自适应epsilon-松弛机制，保证最终解的可行性，并提供理论保证。这在优化理论和约束满足方面具有严谨的数学逻辑。"
    },
    {
        "id": "http://arxiv.org/abs/2601.19084v1",
        "title": "A Probabilistic Interpretation of the Master Equation Arising from Mean Field Games with Jump Diffusion",
        "summary": "In this paper we study the classical solution to the master equation arising from mean-field games (MFGs) driven by jump-diffusion processes. The master equation, a nonlinear partial differential equation on Wasserstein space, characterizes the value function of MFGs and is challenging to analyze directly due to its measure-valued derivatives. We propose a probabilistic interpretation using coupled McKean-Vlasov forward-backward stochastic differential equations (MV-FBSDEs) with jumps. Under suitable Lipschitz and differentiability assumptions on the coefficients, we first establish the well-posedness of the MV-FBSDEs on a small time interval via a contraction mapping argument. We then prove the existence and regularity of the first- and second-order derivatives of the solutions with respect to the spatial and measure variables, relying on careful estimates involving jump terms and measure derivatives. Finally, we show that the decoupling field of the MV-FBSDEs satisfies the master equation in the classical sense, providing both existence and uniqueness of the solution. Our work extends earlier results on diffusion-driven MFGs to the jump-diffusion setting and offers a probabilistic framework for analyzing and numerically solving such kind of master equations.",
        "authors": "Jiusheng Liu, Jing Zhang",
        "url": "http://arxiv.org/abs/2601.19084v1",
        "pdf_url": "https://arxiv.org/pdf/2601.19084v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 3,
            "Clarity": 4
        },
        "reason_zh": "该论文为跳跃扩散过程驱动的平均场博弈（MFGs）中的主方程提供了概率解释，并严格证明了MV-FBSDEs的适定性、解的存在性、唯一性和正则性。这在随机过程、偏微分方程和数学推导方面具有极高的理论深度和严谨性。"
    }
]