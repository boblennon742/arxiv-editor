[
    {
        "id": "http://arxiv.org/abs/2512.05116v1",
        "title": "Value Gradient Guidance for Flow Matching Alignment",
        "summary": "While methods exist for aligning flow matching models--a popular and effective class of generative models--with human preferences, existing approaches fail to achieve both adaptation efficiency and probabilistically sound prior preservation. In this work, we leverage the theory of optimal control and propose VGG-Flow, a gradient-matching-based method for finetuning pretrained flow matching models. The key idea behind this algorithm is that the optimal difference between the finetuned velocity field and the pretrained one should be matched with the gradient field of a value function. This method not only incorporates first-order information from the reward model but also benefits from heuristic initialization of the value function to enable fast adaptation. Empirically, we show on a popular text-to-image flow matching model, Stable Diffusion 3, that our method can finetune flow matching models under limited computational budgets while achieving effective and prior-preserving alignment.",
        "authors": "Zhen Liu, Tim Z. Xiao, Carles Domingo-Enrich, Weiyang Liu, Dinghuai Zhang",
        "url": "http://arxiv.org/abs/2512.05116v1",
        "pdf_url": "https://arxiv.org/pdf/2512.05116v1",
        "scores": {
            "Novelty": 4.5,
            "Rigor": 4.5,
            "Impact": 4.5,
            "Clarity": 4.5
        },
        "reason_zh": "这篇论文利用最优控制理论，提出了VGG-Flow方法来微调流匹配生成模型，解决了现有方法在适应效率和概率保真方面的局限。其理论基础扎实，直接针对生成模型对齐的效率瓶颈，具有很强的理论创新性和实际应用价值。"
    },
    {
        "id": "http://arxiv.org/abs/2512.05106v1",
        "title": "NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation",
        "summary": "Standard diffusion corrupts data using Gaussian noise whose Fourier coefficients have random magnitudes and random phases. While effective for unconditional or text-to-image generation, corrupting phase components destroys spatial structure, making it ill-suited for tasks requiring geometric consistency, such as re-rendering, simulation enhancement, and image-to-image translation. We introduce Phase-Preserving Diffusion φ-PD, a model-agnostic reformulation of the diffusion process that preserves input phase while randomizing magnitude, enabling structure-aligned generation without architectural changes or additional parameters. We further propose Frequency-Selective Structured (FSS) noise, which provides continuous control over structural rigidity via a single frequency-cutoff parameter. φ-PD adds no inference-time cost and is compatible with any diffusion model for images or videos. Across photorealistic and stylized re-rendering, as well as sim-to-real enhancement for driving planners, φ-PD produces controllable, spatially aligned results. When applied to the CARLA simulator, φ-PD improves CARLA-to-Waymo planner performance by 50\\%. The method is complementary to existing conditioning approaches and broadly applicable to image-to-image and video-to-video generation. Videos, additional examples, and code are available on our \\href{https://yuzeng-at-tri.github.io/ppd-page/}{project page}.",
        "authors": "Yu Zeng, Charles Ochoa, Mingyuan Zhou, Vishal M. Patel, Vitor Guizilini, Rowan McAllister",
        "url": "http://arxiv.org/abs/2512.05106v1",
        "pdf_url": "https://arxiv.org/pdf/2512.05106v1",
        "scores": {
            "Novelty": 4.5,
            "Rigor": 4.5,
            "Impact": 4.5,
            "Clarity": 4.5
        },
        "reason_zh": "该研究引入了相位保持扩散（φ-PD），对扩散过程进行了模型无关的重新表述，解决了标准扩散模型在需要几何一致性任务中破坏空间结构的问题。其对扩散过程的理论性改进，以及在结构对齐生成和模拟增强方面的显著效果，体现了深厚的理论洞察和实际影响力。"
    },
    {
        "id": "http://arxiv.org/abs/2512.05094v1",
        "title": "From Generated Human Videos to Physically Plausible Robot Trajectories",
        "summary": "Video generation models are rapidly improving in their ability to synthesize human actions in novel contexts, holding the potential to serve as high-level planners for contextual robot control. To realize this potential, a key research question remains open: how can a humanoid execute the human actions from generated videos in a zero-shot manner? This challenge arises because generated videos are often noisy and exhibit morphological distortions that make direct imitation difficult compared to real video. To address this, we introduce a two-stage pipeline. First, we lift video pixels into a 4D human representation and then retarget to the humanoid morphology. Second, we propose GenMimic-a physics-aware reinforcement learning policy conditioned on 3D keypoints, and trained with symmetry regularization and keypoint-weighted tracking rewards. As a result, GenMimic can mimic human actions from noisy, generated videos. We curate GenMimicBench, a synthetic human-motion dataset generated using two video generation models across a spectrum of actions and contexts, establishing a benchmark for assessing zero-shot generalization and policy robustness. Extensive experiments demonstrate improvements over strong baselines in simulation and confirm coherent, physically stable motion tracking on a Unitree G1 humanoid robot without fine-tuning. This work offers a promising path to realizing the potential of video generation models as high-level policies for robot control.",
        "authors": "James Ni, Zekai Wang, Wei Lin, Amir Bar, Yann LeCun, Trevor Darrell, Jitendra Malik, Roei Herzig",
        "url": "http://arxiv.org/abs/2512.05094v1",
        "pdf_url": "https://arxiv.org/pdf/2512.05094v1",
        "scores": {
            "Novelty": 4.0,
            "Rigor": 4.0,
            "Impact": 4.5,
            "Clarity": 4.0
        },
        "reason_zh": "这篇论文提出了一个两阶段的GenMimic管道，将视频生成模型中的人类动作转化为物理上可行的机器人轨迹。通过物理感知的强化学习策略，解决了生成视频噪声和形态畸变导致机器人模仿困难的实际瓶颈，为机器人控制提供了新的思路。"
    },
    {
        "id": "http://arxiv.org/abs/2512.05092v1",
        "title": "Foundations of Diffusion Models in General State Spaces: A Self-Contained Introduction",
        "summary": "Although diffusion models now occupy a central place in generative modeling, introductory treatments commonly assume Euclidean data and seldom clarify their connection to discrete-state analogues. This article is a self-contained primer on diffusion over general state spaces, unifying continuous domains and discrete/categorical structures under one lens. We develop the discrete-time view (forward noising via Markov kernels and learned reverse dynamics) alongside its continuous-time limits -- stochastic differential equations (SDEs) in $\\mathbb{R}^d$ and continuous-time Markov chains (CTMCs) on finite alphabets -- and derive the associated Fokker--Planck and master equations. A common variational treatment yields the ELBO that underpins standard training losses. We make explicit how forward corruption choices -- Gaussian processes in continuous spaces and structured categorical transition kernels (uniform, masking/absorbing and more) in discrete spaces -- shape reverse dynamics and the ELBO. The presentation is layered for three audiences: newcomers seeking a self-contained intuitive introduction; diffusion practitioners wanting a global theoretical synthesis; and continuous-diffusion experts looking for an analogy-first path into discrete diffusion. The result is a unified roadmap to modern diffusion methodology across continuous domains and discrete sequences, highlighting a compact set of reusable proofs, identities, and core theoretical principles.",
        "authors": "Vincent Pauline, Tobias Höppe, Kirill Neklyudov, Alexander Tong, Stefan Bauer, Andrea Dittadi",
        "url": "http://arxiv.org/abs/2512.05092v1",
        "pdf_url": "https://arxiv.org/pdf/2512.05092v1",
        "scores": {
            "Novelty": 4.0,
            "Rigor": 5,
            "Impact": 4.0,
            "Clarity": 5
        },
        "reason_zh": "这篇论文为通用状态空间中的扩散模型提供了统一的理论基础，将连续域和离散结构整合在一个框架下。对于数理统计博士生而言，这种对前沿生成模型（扩散模型）的深刻理论综合和严谨推导，是理解和进一步创新算法的宝贵资源。"
    },
    {
        "id": "http://arxiv.org/abs/2512.04985v1",
        "title": "Towards a unified framework for guided diffusion models",
        "summary": "Guided or controlled data generation with diffusion models\\blfootnote{Partial preliminary results of this work appeared in International Conference on Machine Learning 2025 \\citep{li2025provable}.} has become a cornerstone of modern generative modeling. Despite substantial advances in diffusion model theory, the theoretical understanding of guided diffusion samplers remains severely limited. We make progress by developing a unified algorithmic and theoretical framework that accommodates both diffusion guidance and reward-guided diffusion. Aimed at fine-tuning diffusion models to improve certain rewards, we propose injecting a reward guidance term -- constructed from the difference between the original and reward-reweighted scores -- into the backward diffusion process, and rigorously quantify the resulting reward improvement over the unguided counterpart. As a key application, our framework shows that classifier-free guidance (CFG) decreases the expected reciprocal of the classifier probability, providing the first theoretical characterization of the specific performance metric that CFG improves for general target distributions. When applied to reward-guided diffusion, our framework yields a new sampler that is easy-to-train and requires no full diffusion trajectories during training. Numerical experiments further corroborate our theoretical findings.",
        "authors": "Yuchen Jiao, Yuxin Chen, Gen Li",
        "url": "http://arxiv.org/abs/2512.04985v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04985v1",
        "scores": {
            "Novelty": 4.5,
            "Rigor": 5,
            "Impact": 4.5,
            "Clarity": 4.5
        },
        "reason_zh": "该研究提出了一个统一的引导扩散模型算法和理论框架，解决了引导扩散采样器理论理解不足的局限性。其对奖励引导扩散的严格量化和对CFG性能指标的首次理论表征，展现了极高的理论严谨性和对前沿算法的深刻洞察。"
    },
    {
        "id": "http://arxiv.org/abs/2512.04969v1",
        "title": "Rethinking the Use of Vision Transformers for AI-Generated Image Detection",
        "summary": "Rich feature representations derived from CLIP-ViT have been widely utilized in AI-generated image detection. While most existing methods primarily leverage features from the final layer, we systematically analyze the contributions of layer-wise features to this task. Our study reveals that earlier layers provide more localized and generalizable features, often surpassing the performance of final-layer features in detection tasks. Moreover, we find that different layers capture distinct aspects of the data, each contributing uniquely to AI-generated image detection. Motivated by these findings, we introduce a novel adaptive method, termed MoLD, which dynamically integrates features from multiple ViT layers using a gating-based mechanism. Extensive experiments on both GAN- and diffusion-generated images demonstrate that MoLD significantly improves detection performance, enhances generalization across diverse generative models, and exhibits robustness in real-world scenarios. Finally, we illustrate the scalability and versatility of our approach by successfully applying it to other pre-trained ViTs, such as DINOv2.",
        "authors": "NaHyeon Park, Kunhee Kim, Junsuk Choe, Hyunjung Shim",
        "url": "http://arxiv.org/abs/2512.04969v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04969v1",
        "scores": {
            "Novelty": 4.5,
            "Rigor": 4.5,
            "Impact": 4.0,
            "Clarity": 4.5
        },
        "reason_zh": "GeoPE提出了一种统一的几何位置嵌入，通过将旋转扩展到3D欧几里得空间并利用李代数中的几何平均来恢复2D空间流形。这种数学上严谨的理论创新，解决了现有位置编码在处理结构化张量时空间拓扑被破坏的问题，对Vision Transformer架构有重要意义。"
    },
    {
        "id": "http://arxiv.org/abs/2512.04949v1",
        "title": "CARL: Critical Action Focused Reinforcement Learning for Multi-Step Agent",
        "summary": "Agents capable of accomplishing complex tasks through multiple interactions with the environment have emerged as a popular research direction. However, in such multi-step settings, the conventional group-level policy optimization algorithm becomes suboptimal because of its underlying assumption that each action holds equal contribution, which deviates significantly from reality. Our analysis reveals that only a small fraction of actions are critical in determining the final outcome. Building on this insight, we propose CARL, a critical-action-focused reinforcement learning algorithm tailored for multi-step agents. CARL achieves focused training through providing action-level optimization signals for high-criticality actions while excluding low-criticality actions from model update. Extensive experiments demonstrate that CARL achieves both stronger performance and higher efficiency during training and inference across diverse evaluation settings.",
        "authors": "Leyang Shen, Yang Zhang, Chun Kai Ling, Xiaoyan Zhao, Tat-Seng Chua",
        "url": "http://arxiv.org/abs/2512.04949v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04949v1",
        "scores": {
            "Novelty": 4.5,
            "Rigor": 4.0,
            "Impact": 4.5,
            "Clarity": 4.5
        },
        "reason_zh": "CARL是一种专注于关键动作的强化学习算法，解决了多步智能体中传统策略优化算法因假设每个动作贡献相等而次优的问题。其基于对关键动作的洞察进行优化，显著提升了训练效率和性能，是强化学习算法的理论创新和效率提升的典范。"
    },
    {
        "id": "http://arxiv.org/abs/2512.04923v1",
        "title": "Algorithmic Thinking Theory",
        "summary": "Large language models (LLMs) have proven to be highly effective for solving complex reasoning tasks. Surprisingly, their capabilities can often be improved by iterating on previously generated solutions. In this context, a reasoning plan for generating and combining a set of solutions can be thought of as an algorithm for reasoning using a probabilistic oracle.   We introduce a theoretical framework for analyzing such reasoning algorithms. This framework formalizes the principles underlying popular techniques for iterative improvement and answer aggregation, providing a foundation for designing a new generation of more powerful reasoning methods. Unlike approaches for understanding models that rely on architectural specifics, our model is grounded in experimental evidence. As a result, it offers a general perspective that may extend to a wide range of current and future reasoning oracles.",
        "authors": "MohammadHossein Bateni, Vincent Cohen-Addad, Yuzhou Gu, Silvio Lattanzi, Simon Meierhans, Christopher Mohri",
        "url": "http://arxiv.org/abs/2512.04923v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04923v1",
        "scores": {
            "Novelty": 4.0,
            "Rigor": 5,
            "Impact": 4.0,
            "Clarity": 5
        },
        "reason_zh": "这篇论文提出了一个分析LLM推理算法的理论框架，形式化了迭代改进和答案聚合的原理。对于专注于AI前沿算法和架构的博士生来说，这种对LLM推理机制的深层理论探索，为设计更强大的推理方法奠定了基础，具有极高的理论价值。"
    },
    {
        "id": "http://arxiv.org/abs/2512.04829v1",
        "title": "Model-Based and Sample-Efficient AI-Assisted Math Discovery in Sphere Packing",
        "summary": "Sphere packing, Hilbert's eighteenth problem, asks for the densest arrangement of congruent spheres in n-dimensional Euclidean space. Although relevant to areas such as cryptography, crystallography, and medical imaging, the problem remains unresolved: beyond a few special dimensions, neither optimal packings nor tight upper bounds are known. Even a major breakthrough in dimension $n=8$, later recognised with a Fields Medal, underscores its difficulty. A leading technique for upper bounds, the three-point method, reduces the problem to solving large, high-precision semidefinite programs (SDPs). Because each candidate SDP may take days to evaluate, standard data-intensive AI approaches are infeasible. We address this challenge by formulating SDP construction as a sequential decision process, the SDP game, in which a policy assembles SDP formulations from a set of admissible components. Using a sample-efficient model-based framework that combines Bayesian optimisation with Monte Carlo Tree Search, we obtain new state-of-the-art upper bounds in dimensions $4-16$, showing that model-based search can advance computational progress in longstanding geometric problems. Together, these results demonstrate that sample-efficient, model-based search can make tangible progress on mathematically rigid, evaluation limited problems, pointing towards a complementary direction for AI-assisted discovery beyond large-scale LLM-driven exploration.",
        "authors": "Rasul Tutunov, Alexandre Maraval, Antoine Grosnit, Xihan Li, Jun Wang, Haitham Bou-Ammar",
        "url": "http://arxiv.org/abs/2512.04829v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04829v1",
        "scores": {
            "Novelty": 4.5,
            "Rigor": 4.5,
            "Impact": 4.5,
            "Clarity": 4.5
        },
        "reason_zh": "该研究将球体堆积问题中的SDP构建公式化为序贯决策过程，并利用贝叶斯优化和蒙特卡洛树搜索相结合的模型化、样本高效框架，在数学发现领域取得了SOTA成果。它展示了样本高效的模型化搜索在解决数学难题中的潜力，是AI辅助科学发现的理论创新应用。"
    },
    {
        "id": "http://arxiv.org/abs/2512.04771v1",
        "title": "Complementary Characterization of Agent-Based Models via Computational Mechanics and Diffusion Models",
        "summary": "This article extends the preprint \"Characterizing Agent-Based Model Dynamics via $ε$-Machines and Kolmogorov-Style Complexity\" by introducing diffusion models as orthogonal and complementary tools for characterizing the output of agent-based models (ABMs). Where $ε$-machines capture the predictive temporal structure and intrinsic computation of ABM-generated time series, diffusion models characterize high-dimensional cross-sectional distributions, learn underlying data manifolds, and enable synthetic generation of plausible population-level outcomes. We provide a formal analysis demonstrating that the two approaches operate on distinct mathematical domains -- processes vs. distributions -- and show that their combination yields a two-axis representation of ABM behavior based on temporal organization and distributional geometry. To our knowledge, this is the first framework to integrate computational mechanics with score-based generative modeling for the structural analysis of ABM outputs, thereby situating ABM characterization within the broader landscape of modern machine-learning methods for density estimation and intrinsic computation. The framework is validated using the same elder-caregiver ABM dataset introduced in the companion paper, and we provide precise definitions and propositions formalizing the mathematical complementarity between $ε$-machines and diffusion models. This establishes a principled methodology for jointly analyzing temporal predictability and high-dimensional distributional structure in complex simulation models.",
        "authors": "Roberto Garrone",
        "url": "http://arxiv.org/abs/2512.04771v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04771v1",
        "scores": {
            "Novelty": 4.5,
            "Rigor": 5,
            "Impact": 4.0,
            "Clarity": 4.5
        },
        "reason_zh": "这篇论文将计算力学（ε-机器）与扩散模型相结合，用于表征基于智能体的模型（ABM）的输出，提出了基于时间组织和分布几何的双轴表示。其对两种数学领域方法的整合和形式化分析，提供了理解复杂模拟模型的新理论框架，严谨性极高。"
    },
    {
        "id": "http://arxiv.org/abs/2512.04745v1",
        "title": "Neural Policy Composition from Free Energy Minimization",
        "summary": "The ability to compose acquired skills to plan and execute behaviors is a hallmark of natural intelligence. Yet, despite remarkable cross-disciplinary efforts, a principled account of how task structure shapes gating and how such computations could be delivered in neural circuits, remains elusive. Here we introduce GateMod, an interpretable theoretically grounded computational model linking the emergence of gating to the underlying decision-making task, and to a neural circuit architecture. We first develop GateFrame, a normative framework casting policy gating into the minimization of the free energy. This framework, relating gating rules to task, applies broadly across neuroscience, cognitive and computational sciences. We then derive GateFlow, a continuous-time energy based dynamics that provably converges to GateFrame optimal solution. Convergence, exponential and global, follows from a contractivity property that also yields robustness and other desirable properties. Finally, we derive a neural circuit from GateFlow, GateNet. This is a soft-competitive recurrent circuit whose components perform local and contextual computations consistent with known dendritic and neural processing motifs. We evaluate GateMod across two different settings: collective behaviors in multi-agent systems and human decision-making in multi-armed bandits. In all settings, GateMod provides interpretable mechanistic explanations of gating and quantitatively matches or outperforms established models. GateMod offers a unifying framework for neural policy gating, linking task objectives, dynamical computation, and circuit-level mechanisms. It provides a framework to understand gating in natural agents beyond current explanations and to equip machines with this ability.",
        "authors": "Francesca Rossi, Veronica Centorrino, Francesco Bullo, Giovanni Russo",
        "url": "http://arxiv.org/abs/2512.04745v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04745v1",
        "scores": {
            "Novelty": 4.5,
            "Rigor": 5,
            "Impact": 4.0,
            "Clarity": 4.5
        },
        "reason_zh": "GateMod是一个理论基础扎实的计算模型，将策略门控与决策任务和神经回路联系起来，通过自由能最小化来推导。其提出的GateFrame、GateFlow和GateNet，为理解自然智能体的门控机制和赋予机器此能力提供了统一框架，具有深刻的理论创新性。"
    },
    {
        "id": "http://arxiv.org/abs/2512.04709v1",
        "title": "Multi Task Denoiser Training for Solving Linear Inverse Problems",
        "summary": "Plug-and-Play Priors (PnP) and Regularisation by Denoising (RED) have established that image denoisers can effectively replace traditional regularisers in linear inverse problem solvers for tasks like super-resolution, demosaicing, and inpainting. It is now well established in the literature that a denoiser's residual links to the gradient of the image log prior (Miyasawa and Tweedie), enabling iterative, gradient ascent-based image generation (e.g., diffusion models), as well as new methods for solving inverse problems. Building on this, we propose enhancing Kadkhodaie and Simoncelli's gradient-based inverse solvers by fine-tuning the denoiser within the iterative solving process itself. Training the denoiser end-to-end across the solver framework and simultaneously across multiple tasks yields a single, versatile denoiser optimised for inverse problems. We demonstrate that even a simple baseline model fine-tuned this way achieves an average PSNR improvement of +1.34 dB across six diverse inverse problems while reducing the required iterations. Furthermore, we analyse the fine-tuned denoiser's properties, finding that its optimisation objective implicitly shifts from minimising standard denoising error (MMSE) towards approximating an ideal prior gradient specifically tailored for guiding inverse recovery.",
        "authors": "Clément Bled, François Pitié",
        "url": "http://arxiv.org/abs/2512.04709v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04709v1",
        "scores": {
            "Novelty": 4.5,
            "Rigor": 4.5,
            "Impact": 4.5,
            "Clarity": 4.5
        },
        "reason_zh": "该研究通过在迭代求解过程中微调去噪器，解决了线性逆问题。其核心洞察在于去噪器的残差与图像对数先验的梯度相关，并证明了优化目标从MMSE转向近似理想先验梯度。这是一种对现有算法的理论性增强，显著提升了逆问题求解的效率和精度。"
    },
    {
        "id": "http://arxiv.org/abs/2512.04680v1",
        "title": "Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap",
        "summary": "Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this paper aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI's within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.",
        "authors": "Jialong Li, Mingyue Zhang, Nianyu Li, Danny Weyns, Zhi Jin, Kenji Tei",
        "url": "http://arxiv.org/abs/2512.04680v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04680v1",
        "scores": {
            "Novelty": 2.0,
            "Rigor": 4.0,
            "Impact": 2.5,
            "Clarity": 4.0
        },
        "reason_zh": "这篇论文是一篇关于生成式AI在自适应系统中的综述和研究路线图。虽然内容清晰且对领域有指导意义，但作为一篇综述，其本身不包含原创的算法或架构创新，与您偏好的“理论创新性”不符，因此不推荐。"
    },
    {
        "id": "http://arxiv.org/abs/2512.04632v1",
        "title": "Turbo-Muon: Accelerating Orthogonality-Based Optimization with Pre-Conditioning",
        "summary": "Orthogonality-based optimizers, such as Muon, have recently shown strong performance across large-scale training and community-driven efficiency challenges. However, these methods rely on a costly gradient orthogonalization step. Even efficient iterative approximations such as Newton-Schulz remain expensive, typically requiring dozens of matrix multiplications to converge. We introduce a preconditioning procedure that accelerates Newton-Schulz convergence and reduces its computational cost. We evaluate its impact and show that the overhead of our preconditioning can be made negligible. Furthermore, the faster convergence it enables allows us to remove one iteration out of the usual five without degrading approximation quality. Our publicly available implementation achieves up to a 2.8x speedup in the Newton-Schulz approximation. We also show that this has a direct impact on end-to-end training runtime with 5-10% improvement in realistic training scenarios across two efficiency-focused tasks. On challenging language or vision tasks, we validate that our method maintains equal or superior model performance while improving runtime. Crucially, these improvements require no hyperparameter tuning and can be adopted as a simple drop-in replacement. Our code is publicly available on github.",
        "authors": "Thibaut Boissin, Thomas Massena, Franck Mamalet, Mathieu Serrurier",
        "url": "http://arxiv.org/abs/2512.04632v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04632v1",
        "scores": {
            "Novelty": 4.5,
            "Rigor": 4.5,
            "Impact": 4.5,
            "Clarity": 4.5
        },
        "reason_zh": "Turbo-Muon通过预处理程序加速正交性优化器，解决了梯度正交化步骤计算成本高昂的瓶颈。其在优化算法上的创新，显著提升了训练运行时效率，且无需超参数调整，是AI算法效率优化的优秀范例。"
    },
    {
        "id": "http://arxiv.org/abs/2512.04619v1",
        "title": "Denoise to Track: Harnessing Video Diffusion Priors for Robust Correspondence",
        "summary": "In this work, we introduce HeFT (Head-Frequency Tracker), a zero-shot point tracking framework that leverages the visual priors of pretrained video diffusion models. To better understand how they encode spatiotemporal information, we analyze the internal representations of Video Diffusion Transformer (VDiT). Our analysis reveals that attention heads act as minimal functional units with distinct specializations for matching, semantic understanding, and positional encoding. Additionally, we find that the low-frequency components in VDiT features are crucial for establishing correspondences, whereas the high-frequency components tend to introduce noise. Building on these insights, we propose a head- and frequency-aware feature selection strategy that jointly selects the most informative attention head and low-frequency components to enhance tracking performance. Specifically, our method extracts discriminative features through single-step denoising, applies feature selection, and employs soft-argmax localization with forward-backward consistency checks for correspondence estimation. Extensive experiments on TAP-Vid benchmarks demonstrate that HeFT achieves state-of-the-art zero-shot tracking performance, approaching the accuracy of supervised methods while eliminating the need for annotated training data. Our work further underscores the promise of video diffusion models as powerful foundation models for a wide range of downstream tasks, paving the way toward unified visual foundation models.",
        "authors": "Tianyu Yuan, Yuanbo Yang, Lin-Zhuo Chen, Yao Yao, Zhuzhong Qian",
        "url": "http://arxiv.org/abs/2512.04619v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04619v1",
        "scores": {
            "Novelty": 4.5,
            "Rigor": 4.5,
            "Impact": 4.5,
            "Clarity": 4.5
        },
        "reason_zh": "HeFT框架利用预训练视频扩散模型的视觉先验进行零样本点跟踪。通过对VDiT内部表示的深入分析，提出了头部和频率感知的特征选择策略，从理论上揭示了扩散模型内部机制，并将其应用于解决鲁棒对应这一实际瓶颈，具有很强的创新性和严谨性。"
    },
    {
        "id": "http://arxiv.org/abs/2512.04596v1",
        "title": "QoSDiff: An Implicit Topological Embedding Learning Framework Leveraging Denoising Diffusion and Adversarial Attention for Robust QoS Prediction",
        "summary": "Accurate Quality of Service (QoS) prediction is fundamental to service computing, providing essential data-driven guidance for service selection and ensuring superior user experiences. However, prevalent approaches, particularly Graph Neural Networks (GNNs), heavily rely on constructing explicit user--service interaction graphs. This dependency introduces severe scalability bottlenecks and limits performance when explicit connections are sparse or corrupted by noise. To address these challenges, this paper introduces \\emph{QoSDiff}, a novel embedding learning framework that bypasses the prerequisite of explicit graph construction. Specifically, it leverages a denoising diffusion probabilistic model to recover intrinsic latent structures from noisy initializations. To further capture high-order interactions, we propose an adversarial interaction module that integrates a bidirectional hybrid attention mechanism. This adversarial paradigm dynamically distinguishes informative patterns from noise, enabling a dual-perspective modeling of intricate user--service associations. Extensive experiments on two large-scale real-world datasets demonstrate that QoSDiff significantly outperforms state-of-the-art baselines. Notably, the results highlight the framework's superior cross-dataset generalization capability and exceptional robustness against data sparsity and observational noise.",
        "authors": "Guanchen Du, Jianlong Xu, Wei Wei",
        "url": "http://arxiv.org/abs/2512.04596v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04596v1",
        "scores": {
            "Novelty": 4.5,
            "Rigor": 4.5,
            "Impact": 4.5,
            "Clarity": 4.5
        },
        "reason_zh": "QoSDiff是一个隐式拓扑嵌入学习框架，利用去噪扩散和对抗性注意力机制进行QoS预测，避免了显式图构建的局限。其理论上通过扩散模型恢复内在潜在结构，并通过对抗性模块捕捉高阶交互，解决了图神经网络在数据稀疏或噪声情况下的可扩展性和性能瓶颈。"
    },
    {
        "id": "http://arxiv.org/abs/2512.04559v1",
        "title": "Diffusion Fine-Tuning via Reparameterized Policy Gradient of the Soft Q-Function",
        "summary": "Diffusion models excel at generating high-likelihood samples but often require alignment with downstream objectives. Existing fine-tuning methods for diffusion models significantly suffer from reward over-optimization, resulting in high-reward but unnatural samples and degraded diversity. To mitigate over-optimization, we propose \\textbf{Soft Q-based Diffusion Finetuning (SQDF)}, a novel KL-regularized RL method for diffusion alignment that applies a reparameterized policy gradient of a training-free, differentiable estimation of the soft Q-function. SQDF is further enhanced with three innovations: a discount factor for proper credit assignment in the denoising process, the integration of consistency models to refine Q-function estimates, and the use of an off-policy replay buffer to improve mode coverage and manage the reward-diversity trade-off. Our experiments demonstrate that SQDF achieves superior target rewards while preserving diversity in text-to-image alignment. Furthermore, in online black-box optimization, SQDF attains high sample efficiency while maintaining naturalness and diversity.",
        "authors": "Hyeongyu Kang, Jaewoo Lee, Woocheol Shin, Kiyoung Om, Jinkyoo Park",
        "url": "http://arxiv.org/abs/2512.04559v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04559v1",
        "scores": {
            "Novelty": 4.5,
            "Rigor": 4.5,
            "Impact": 4.5,
            "Clarity": 4.5
        },
        "reason_zh": "SQDF是一种新颖的KL正则化RL方法，用于扩散模型对齐，通过软Q函数的重参数化策略梯度来缓解奖励过度优化问题。其理论上严谨地解决了扩散模型微调中的一个关键瓶颈，同时保持了生成多样性，对前沿生成模型有重要意义。"
    },
    {
        "id": "http://arxiv.org/abs/2512.04532v1",
        "title": "PhyVLLM: Physics-Guided Video Language Model with Motion-Appearance Disentanglement",
        "summary": "Video Large Language Models (Video LLMs) have shown impressive performance across a wide range of video-language tasks. However, they often fail in scenarios requiring a deeper understanding of physical dynamics. This limitation primarily arises from their reliance on appearance-based matching. Incorporating physical motion modeling is crucial for deeper video understanding, but presents three key challenges: (1) motion signals are often entangled with appearance variations, making it difficult to extract clean physical cues; (2) effective motion modeling requires not only continuous-time motion representations but also capturing physical dynamics; and (3) collecting accurate annotations for physical attributes is costly and often impractical. To address these issues, we propose PhyVLLM, a physical-guided video-language framework that explicitly incorporates physical motion into Video LLMs. Specifically, PhyVLLM disentangles visual appearance and object motion through a dual-branch encoder. To model physical dynamics over time, we incorporate a Neural Ordinary Differential Equation (Neural ODE) module, which generates differentiable physical dynamic representations. The resulting motion-aware representations are projected into the token space of a pretrained LLM, enabling physics reasoning without compromising the model's original multimodal capabilities. To circumvent the need for explicit physical labels, PhyVLLM employs a self-supervised manner to model the continuous evolution of object motion. Experimental results demonstrate that PhyVLLM significantly outperforms state-of-the-art Video LLMs on both physical reasoning and general video understanding tasks, highlighting the advantages of incorporating explicit physical modeling.",
        "authors": "Yu-Wei Zhan, Xin Wang, Hong Chen, Tongtong Feng, Wei Feng, Ren Wang, Guangyao Li, Qing Li, Wenwu Zhu",
        "url": "http://arxiv.org/abs/2512.04532v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04532v1",
        "scores": {
            "Novelty": 4.5,
            "Rigor": 4.5,
            "Impact": 4.5,
            "Clarity": 4.5
        },
        "reason_zh": "PhyVLLM是一个物理引导的视频语言模型框架，通过双分支编码器解耦运动和外观，并引入神经ODE模块建模物理动态。其理论创新在于将物理运动显式整合到VLLM中，解决了现有模型依赖外观匹配的局限，提升了对物理动态的理解，对多模态AI架构有重要贡献。"
    },
    {
        "id": "http://arxiv.org/abs/2512.04519v1",
        "title": "VideoSSM: Autoregressive Long Video Generation with Hybrid State-Space Memory",
        "summary": "Autoregressive (AR) diffusion enables streaming, interactive long-video generation by producing frames causally, yet maintaining coherence over minute-scale horizons remains challenging due to accumulated errors, motion drift, and content repetition. We approach this problem from a memory perspective, treating video synthesis as a recurrent dynamical process that requires coordinated short- and long-term context. We propose VideoSSM, a Long Video Model that unifies AR diffusion with a hybrid state-space memory. The state-space model (SSM) serves as an evolving global memory of scene dynamics across the entire sequence, while a context window provides local memory for motion cues and fine details. This hybrid design preserves global consistency without frozen, repetitive patterns, supports prompt-adaptive interaction, and scales in linear time with sequence length. Experiments on short- and long-range benchmarks demonstrate state-of-the-art temporal consistency and motion stability among autoregressive video generator especially at minute-scale horizons, enabling content diversity and interactive prompt-based control, thereby establishing a scalable, memory-aware framework for long video generation.",
        "authors": "Yifei Yu, Xiaoshan Wu, Xinting Hu, Tao Hu, Yangtian Sun, Xiaoyang Lyu, Bo Wang, Lin Ma, Yuewen Ma, Zhongrui Wang, Xiaojuan Qi",
        "url": "http://arxiv.org/abs/2512.04519v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04519v1",
        "scores": {
            "Novelty": 4.5,
            "Rigor": 4.5,
            "Impact": 4.5,
            "Clarity": 4.5
        },
        "reason_zh": "VideoSSM将自回归扩散与混合状态空间记忆相结合，解决了长视频生成中累积误差、运动漂移和内容重复的挑战。其将视频合成视为需要短时和长时上下文协调的循环动力学过程，在理论和架构上都具有创新性，有效提升了长视频生成的一致性和稳定性。"
    },
    {
        "id": "http://arxiv.org/abs/2512.04499v1",
        "title": "Back to Basics: Motion Representation Matters for Human Motion Generation Using Diffusion Model",
        "summary": "Diffusion models have emerged as a widely utilized and successful methodology in human motion synthesis. Task-oriented diffusion models have significantly advanced action-to-motion, text-to-motion, and audio-to-motion applications. In this paper, we investigate fundamental questions regarding motion representations and loss functions in a controlled study, and we enumerate the impacts of various decisions in the workflow of the generative motion diffusion model. To answer these questions, we conduct empirical studies based on a proxy motion diffusion model (MDM). We apply v loss as the prediction objective on MDM (vMDM), where v is the weighted sum of motion data and noise. We aim to enhance the understanding of latent data distributions and provide a foundation for improving the state of conditional motion diffusion models. First, we evaluate the six common motion representations in the literature and compare their performance in terms of quality and diversity metrics. Second, we compare the training time under various configurations to shed light on how to speed up the training process of motion diffusion models. Finally, we also conduct evaluation analysis on a large motion dataset. The results of our experiments indicate clear performance differences across motion representations in diverse datasets. Our results also demonstrate the impacts of distinct configurations on model training and suggest the importance and effectiveness of these decisions on the outcomes of motion diffusion models.",
        "authors": "Yuduo Jin, Brandon Haworth",
        "url": "http://arxiv.org/abs/2512.04499v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04499v1",
        "scores": {
            "Novelty": 3.5,
            "Rigor": 3.0,
            "Impact": 3.5,
            "Clarity": 4.0
        },
        "reason_zh": "这篇论文主要探讨了人体运动生成扩散模型中运动表示和损失函数的基础问题，通过实证研究来增强理解。虽然对基础问题有贡献，但其理论创新性相对较低，更侧重于经验性分析，与您偏好的“理论创新性”要求略有偏差，因此不推荐。"
    },
    {
        "id": "http://arxiv.org/abs/2512.04476v1",
        "title": "Context-Aware Mixture-of-Experts Inference on CXL-Enabled GPU-NDP Systems",
        "summary": "Mixture-of-Experts (MoE) models scale large language models through conditional computation, but inference becomes memory-bound once expert weights exceed the capacity of GPU memory. In this case, weights must be offloaded to external memory, and fetching them incurs costly and repeated transfers. We address this by adopting CXL-attached near-data processing (CXL-NDP) as the offloading tier to execute cold experts in place, converting expensive parameter movement into cheaper activation movement. Unlike prior GPU-NDP systems that are largely context-agnostic and reactive, we develop a context-aware MoE system that uses prefill-stage activation statistics to guide decoding-stage expert placement, dynamically pins hot experts in GPU-side HBM, and maps the remainder to CXL-NDP. To meet NDP's limited compute throughput, we introduce context-aware mixed-precision quantization that allocates per-expert bitwidths (1-4 bit) based on prefill stage. The resulting MoE inference system overlaps GPU and NDP execution while minimizing cross-device movement. The evaluation on the GPU-NDP system shows that our approach achieves up to an 8.7-fold decoding throughput improvement over the state-of-the-art method, while incurring only a 0.13% average accuracy drop.",
        "authors": "Zehao Fan, Zhenyu Liu, Yunzhen Liu, Yayue Hou, Hadjer Benmeziane, Kaoutar El Maghraoui, Liu Liu",
        "url": "http://arxiv.org/abs/2512.04476v1",
        "pdf_url": "https://arxiv.org/pdf/2512.04476v1",
        "scores": {
            "Novelty": 4.5,
            "Rigor": 4.5,
            "Impact": 4.5,
            "Clarity": 4.5
        },
        "reason_zh": "该研究提出了一个上下文感知的MoE推理系统，用于CXL-Enabled GPU-NDP系统，解决了当专家权重超出GPU内存容量时的内存瓶颈。其通过动态固定热专家和上下文感知混合精度量化，实现了显著的解码吞吐量提升，是AI架构和效率优化的前沿工作。"
    }
]