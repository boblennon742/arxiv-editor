[
    {
        "id": "http://arxiv.org/abs/2511.01680v1",
        "title": "Making Interpretable Discoveries from Unstructured Data: A High-Dimensional Multiple Hypothesis Testing Approach",
        "summary": "Social scientists are increasingly turning to unstructured datasets to unlock new empirical insights, e.g., estimating causal effects on text outcomes, measuring beliefs from open-ended survey responses. In such settings, unsupervised analysis is often of interest, in that the researcher does not want to pre-specify the objects of measurement or otherwise artificially delimit the space of measurable concepts; they are interested in discovery. This paper proposes a general and flexible framework for pursuing discovery from unstructured data in a statistically principled way. The framework leverages recent methods from the literature on machine learning interpretability to map unstructured data points to high-dimensional, sparse, and interpretable dictionaries of concepts; computes (test) statistics of these dictionary entries; and then performs selective inference on them using newly developed statistical procedures for high-dimensional exceedance control of the $k$-FWER under arbitrary dependence. The proposed framework has few researcher degrees of freedom, is fully replicable, and is cheap to implement -- both in terms of financial cost and researcher time. Applications to recent descriptive and causal analyses of unstructured data in empirical economics are explored. An open source Jupyter notebook is provided for researchers to implement the framework in their own projects.",
        "authors": "Jacob Carlson",
        "url": "http://arxiv.org/abs/2511.01680v1",
        "pdf_url": "http://arxiv.org/pdf/2511.01680v1",
        "reason_zh": "这篇论文完美契合了您作为数理统计博士生对“严谨数学逻辑应用于现代AI系统，以提升鲁棒性和效果”的核心追求。它提出了一个从非结构化数据中进行可解释发现的框架，核心采用**高维多重假设检验**和**选择性推断**等严谨的统计学方法。论文明确提及“高维统计”、“文本结果上的因果效应”（直接关联因果推断和LLM在数据科学中的应用）、“机器学习可解释性”，并强调了“新开发的统计过程”如$k$-FWER控制下的推断。这种结合了基础统计理论（高维、因果）、现代AI应用（处理非结构化数据，潜在的LLM输出）以及提升AI可解释性和统计保证（鲁棒性与效果）的特点，正是您所寻找的“逻辑性强、可落地的知识”，且避免了纯粹抽象的理论空谈。",
        "reason_en": "This paper perfectly aligns with your core pursuit as a mathematical statistics PhD student focusing on applying rigorous mathematical logic to modern AI systems for robustness and effectiveness. It proposes a framework for making interpretable discoveries from unstructured data, leveraging rigorous statistical methods like **high-dimensional multiple hypothesis testing** and **selective inference**. The paper explicitly mentions 'high-dimensional statistics,' 'causal effects on text outcomes' (directly linking to causal inference and LLM applications in data science), and 'machine learning interpretability.' It highlights 'newly developed statistical procedures' such as inference under $k$-FWER control. This combination of foundational statistical theory (high-dimensional, causal), modern AI application (handling unstructured data, implicitly LLM outputs), and enhancing AI interpretability and statistical guarantees (robustness and effectiveness) precisely matches your preference for 'logical and implementable knowledge,' while avoiding purely abstract theoretical discussions."
    },
    {
        "id": "http://arxiv.org/abs/2511.01196v1",
        "title": "An Interdisciplinary and Cross-Task Review on Missing Data Imputation",
        "summary": "Missing data is a fundamental challenge in data science, significantly hindering analysis and decision-making across a wide range of disciplines, including healthcare, bioinformatics, social science, e-commerce, and industrial monitoring. Despite decades of research and numerous imputation methods, the literature remains fragmented across fields, creating a critical need for a comprehensive synthesis that connects statistical foundations with modern machine learning advances. This work systematically reviews core concepts-including missingness mechanisms, single versus multiple imputation, and different imputation goals-and examines problem characteristics across various domains. It provides a thorough categorization of imputation methods, spanning classical techniques (e.g., regression, the EM algorithm) to modern approaches like low-rank and high-rank matrix completion, deep learning models (autoencoders, GANs, diffusion models, graph neural networks), and large language models. Special attention is given to methods for complex data types, such as tensors, time series, streaming data, graph-structured data, categorical data, and multimodal data. Beyond methodology, we investigate the crucial integration of imputation with downstream tasks like classification, clustering, and anomaly detection, examining both sequential pipelines and joint optimization frameworks. The review also assesses theoretical guarantees, benchmarking resources, and evaluation metrics. Finally, we identify critical challenges and future directions, emphasizing model selection and hyperparameter optimization, the growing importance of privacy-preserving imputation via federated learning, and the pursuit of generalizable models that can adapt across domains and data types, thereby outlining a roadmap for future research.",
        "authors": "Jicong Fan",
        "url": "http://arxiv.org/abs/2511.01196v1",
        "pdf_url": "http://arxiv.org/pdf/2511.01196v1",
        "reason_zh": "这篇论文是一篇关于**缺失数据归因**的跨学科和跨任务的综合性综述，与您的兴趣点高度契合。它明确指出旨在“将统计基础与现代机器学习进展相连接”，这正是您作为数理统计博士生所追求的。综述内容涵盖了缺失机制、经典统计方法（如回归、EM算法）以及现代深度学习模型（如自编码器、GANs、GNNs）和**大型语言模型（LLMs）**在归因中的应用。它还特别关注**时间序列数据**，这对您的量化金融项目（加密货币因子构造）具有直接指导作用。此外，论文探讨了“理论保证”和“可泛化模型”，这直接对应了您对“模型泛化界限的数学基础”和提升AI系统“鲁棒性和效果”的兴趣。其全面的性质和对基础性、理论性和实践性的平衡，使其成为理解该领域理论瓶颈和最新进展的极佳资源。",
        "reason_en": "This paper is a comprehensive, interdisciplinary, and cross-task review on **missing data imputation**, which highly aligns with your interests. It explicitly states its goal to 'connect statistical foundations with modern machine learning advances,' precisely what you, as a mathematical statistics PhD student, seek. The review covers missingness mechanisms, classical statistical methods (e.g., regression, EM algorithm), and modern deep learning models (e.g., autoencoders, GANs, GNNs) and **Large Language Models (LLMs)** in imputation. It also pays special attention to **time series data**, which provides direct guidance for your quantitative finance project (cryptocurrency factor construction). Furthermore, the paper discusses 'theoretical guarantees' and 'generalizable models,' directly addressing your interest in 'mathematical foundations of model generalization bounds' and enhancing AI systems' 'robustness and effectiveness.' Its comprehensive nature and balance of foundational, theoretical, and practical aspects make it an excellent resource for understanding theoretical bottlenecks and recent advancements in this field."
    }
]