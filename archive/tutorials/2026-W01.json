[
    {
        "id": "http://arxiv.org/abs/2512.23343v1",
        "title": "AI Meets Brain: Memory Systems from Cognitive Neuroscience to Autonomous Agents",
        "summary": "Memory serves as the pivotal nexus bridging past and future, providing both humans and AI systems with invaluable concepts and experience to navigate complex tasks. Recent research on autonomous agents has increasingly focused on designing efficient memory workflows by drawing on cognitive neuroscience. However, constrained by interdisciplinary barriers, existing works struggle to assimilate the essence of human memory mechanisms. To bridge this gap, we systematically synthesizes interdisciplinary knowledge of memory, connecting insights from cognitive neuroscience with LLM-driven agents. Specifically, we first elucidate the definition and function of memory along a progressive trajectory from cognitive neuroscience through LLMs to agents. We then provide a comparative analysis of memory taxonomy, storage mechanisms, and the complete management lifecycle from both biological and artificial perspectives. Subsequently, we review the mainstream benchmarks for evaluating agent memory. Additionally, we explore memory security from dual perspectives of attack and defense. Finally, we envision future research directions, with a focus on multimodal memory systems and skill acquisition.",
        "authors": "Jiafeng Liang, Hao Li, Chang Li, Jiaqi Zhou, Shixin Jiang, Zekun Wang, Changkai Ji, Zhihao Zhu, Runxuan Liu, Tao Ren, Jinlan Fu, See-Kiong Ng, Xia Liang, Ming Liu, Bing Qin",
        "url": "http://arxiv.org/abs/2512.23343v1",
        "pdf_url": "https://arxiv.org/pdf/2512.23343v1",
        "type": "前沿深度",
        "scores": {
            "Novelty": 4,
            "Rigor": 4,
            "Clarity": 4,
            "Utility": 5
        },
        "core_value_zh": "跨学科综述，深入探讨AI（特别是LLM和Agent）的记忆系统，与认知神经科学建立联系，为LLM理论机制和未来研究提供宏观视角。",
        "reason_zh": "这篇综述将认知神经科学的记忆概念与LLM驱动的Agent记忆系统进行系统性整合，直接契合了您对“LLM理论机制”的兴趣，并能指引未来研究方向。其跨学科的视野和对记忆管理生命周期的比较分析，对于理解LLM的深层工作机制和设计更智能的Agent具有极高的实用价值。"
    },
    {
        "id": "http://arxiv.org/abs/2512.24736v1",
        "title": "Some Studies on Stochastic Optimization based Quantitative Risk Management",
        "summary": "Risk management often plays an important role in decision making under uncertainty. In quantitative risk management, assessing and optimizing risk metrics requires efficient computing techniques and reliable theoretical guarantees. In this paper, we introduce several topics on quantitative risk management and review some of the recent studies and advancements on the topics. We consider several risk metrics and study decision models that involve the metrics, with a main focus on the related computing techniques and theoretical properties. We show that stochastic optimization, as a powerful tool, can be leveraged to effectively address these problems.",
        "authors": "Zhaolin Hu",
        "url": "http://arxiv.org/abs/2512.24736v1",
        "pdf_url": "https://arxiv.org/pdf/2512.24736v1",
        "type": "前沿深度",
        "scores": {
            "Novelty": 4,
            "Rigor": 4,
            "Clarity": 4,
            "Utility": 5
        },
        "core_value_zh": "综述随机优化在量化风险管理中的最新进展，为加密货币量化等金融统计领域提供理论和计算工具。",
        "reason_zh": "您明确表示对“加密货币量化”感兴趣，而量化风险管理是其核心组成部分。这篇论文综述了随机优化在风险管理中的应用和最新进展，随机优化本身也是高等统计学和运筹学的交叉前沿，对于希望在金融领域应用统计学知识的博士生来说，具有很高的实用性和前瞻性。"
    },
    {
        "id": "http://arxiv.org/abs/2512.23889v1",
        "title": "How Large Language Models Systematically Misrepresent American Climate Opinions",
        "summary": "Federal agencies and researchers increasingly use large language models to analyze and simulate public opinion. When AI mediates between the public and policymakers, accuracy across intersecting identities becomes consequential; inaccurate group-level estimates can mislead outreach, consultation, and policy design. While research examines intersectionality in LLM outputs, no study has compared these outputs against real human responses across intersecting identities. Climate policy is one such domain, and this is particularly urgent for climate change, where opinion is contested and diverse. We investigate how LLMs represent intersectional patterns in U.S. climate opinions. We prompted six LLMs with profiles of 978 respondents from a nationally representative U.S. climate opinion survey and compared AI-generated responses to actual human answers across 20 questions. We find that LLMs appear to compress the diversity of American climate opinions, predicting less-concerned groups as more concerned and vice versa. This compression is intersectional: LLMs apply uniform gender assumptions that match reality for White and Hispanic Americans but misrepresent Black Americans, where actual gender patterns differ. These patterns, which may be invisible to standard auditing approaches, could undermine equitable climate governance.",
        "authors": "Sola Kim, Jieshu Wang, Marco A. Janssen, John M. Anderies",
        "url": "http://arxiv.org/abs/2512.23889v1",
        "pdf_url": "https://arxiv.org/pdf/2512.23889v1",
        "type": "前沿深度",
        "scores": {
            "Novelty": 4,
            "Rigor": 4,
            "Clarity": 4,
            "Utility": 4
        },
        "core_value_zh": "揭示LLM在模拟和分析公众意见时存在的系统性偏差，特别是在交叉身份群体中的不准确性，对LLM的公平性和理论机制理解至关重要。",
        "reason_zh": "这篇研究通过实证分析揭示了LLM在处理复杂社会数据时可能出现的偏见和不准确性，这对于理解“LLM理论机制”的局限性、伦理影响以及如何改进LLM的公平性至关重要。它提供了LLM在实际应用中需要关注的关键问题，具有重要的研究价值。"
    },
    {
        "id": "http://arxiv.org/abs/2512.23684v1",
        "title": "Multilingual Hidden Prompt Injection Attacks on LLM-Based Academic Reviewing",
        "summary": "Large language models (LLMs) are increasingly considered for use in high-impact workflows, including academic peer review. However, LLMs are vulnerable to document-level hidden prompt injection attacks. In this work, we construct a dataset of approximately 500 real academic papers accepted to ICML and evaluate the effect of embedding hidden adversarial prompts within these documents. Each paper is injected with semantically equivalent instructions in four different languages and reviewed using an LLM. We find that prompt injection induces substantial changes in review scores and accept/reject decisions for English, Japanese, and Chinese injections, while Arabic injections produce little to no effect. These results highlight the susceptibility of LLM-based reviewing systems to document-level prompt injection and reveal notable differences in vulnerability across languages.",
        "authors": "Panagiotis Theocharopoulos, Ajinkya Kulkarni, Mathew Magimai. -Doss",
        "url": "http://arxiv.org/abs/2512.23684v1",
        "pdf_url": "https://arxiv.org/pdf/2512.23684v1",
        "type": "前沿深度",
        "scores": {
            "Novelty": 4,
            "Rigor": 4,
            "Clarity": 4,
            "Utility": 4
        },
        "core_value_zh": "探讨LLM在学术评审等高影响力场景中面临的隐藏提示注入攻击，揭示多语言环境下LLM的脆弱性，对LLM安全性和鲁棒性研究具有指导意义。",
        "reason_zh": "提示注入是LLM安全性的一个核心问题，这篇论文通过实证研究揭示了多语言环境下隐藏提示注入攻击的有效性，直接关系到“LLM理论机制”的鲁棒性和安全性。对于研究LLM在关键应用中的可靠性，这是一篇非常具有前沿性和实用性的资料。"
    },
    {
        "id": "http://arxiv.org/abs/2512.22899v1",
        "title": "HiSciBench: A Hierarchical Multi-disciplinary Benchmark for Scientific Intelligence from Reading to Discovery",
        "summary": "The rapid advancement of large language models (LLMs) and multimodal foundation models has sparked growing interest in their potential for scientific research. However, scientific intelligence encompasses a broad spectrum of abilities ranging from understanding fundamental knowledge to conducting creative discovery, and existing benchmarks remain fragmented. Most focus on narrow tasks and fail to reflect the hierarchical and multi-disciplinary nature of real scientific inquiry. We introduce \\textbf{HiSciBench}, a hierarchical benchmark designed to evaluate foundation models across five levels that mirror the complete scientific workflow: \\textit{Scientific Literacy} (L1), \\textit{Literature Parsing} (L2), \\textit{Literature-based Question Answering} (L3), \\textit{Literature Review Generation} (L4), and \\textit{Scientific Discovery} (L5). HiSciBench contains 8,735 carefully curated instances spanning six major scientific disciplines, including mathematics, physics, chemistry, biology, geography, and astronomy, and supports multimodal inputs including text, equations, figures, and tables, as well as cross-lingual evaluation. Unlike prior benchmarks that assess isolated abilities, HiSciBench provides an integrated, dependency-aware framework that enables detailed diagnosis of model capabilities across different stages of scientific reasoning. Comprehensive evaluations of leading models, including GPT-5, DeepSeek-R1, and several multimodal systems, reveal substantial performance gaps: while models achieve up to 69\\% accuracy on basic literacy tasks, performance declines sharply to 25\\% on discovery-level challenges. HiSciBench establishes a new standard for evaluating scientific Intelligence and offers actionable insights for developing models that are not only more capable but also more reliable. The benchmark will be publicly released to facilitate future research.",
        "authors": "Yaping Zhang, Qixuan Zhang, Xingquan Zhang, Zhiyuan Chen, Wenwen Zhuang, Yupu Liang, Lu Xiang, Yang Zhao, Jiajun Zhang, Yu Zhou, Chengqing Zong",
        "url": "http://arxiv.org/abs/2512.22899v1",
        "pdf_url": "https://arxiv.org/pdf/2512.22899v1",
        "type": "前沿深度",
        "scores": {
            "Novelty": 5,
            "Rigor": 4,
            "Clarity": 4,
            "Utility": 5
        },
        "core_value_zh": "提出一个分层、多学科的基准测试HiSciBench，用于全面评估LLM在科学智能方面的能力，从阅读理解到科学发现，为LLM的科学应用和理论发展提供关键评估工具。",
        "reason_zh": "评估框架对于理解和推动LLM发展至关重要。HiSciBench提供了一个前所未有的全面基准，涵盖了科学研究的各个阶段和多个学科，直接服务于您对“LLM理论机制”的兴趣，特别是其在复杂科学任务中的表现。它能有效指引未来LLM在科学领域的研发方向。"
    }
]