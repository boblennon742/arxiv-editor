import streamlit as st
import json
import os
from datetime import date, timedelta
# import pandas as pd # (ç›®å‰ä¸éœ€è¦ï¼Œä½†æœªæ¥åˆ†æå¯èƒ½éœ€è¦)

# --- 1. é…ç½® (V17.1 - 3æ ¸è¯„åˆ†ç‰ˆ + æ–°å‘½å) ---
ARCHIVE_DIR = "archive"

st.set_page_config(page_title="ç§äºº AI æ€»ç¼–è¾‘", layout="wide")

# (V17.1) å…³é”®ä¿®æ”¹ï¼šæ›´æ–°ä¸º 3 æ ¸é…ç½®å’Œæ–°åç§°
YOUR_DOMAINS_OF_INTEREST = {
    "phd_foundations": {
        "name_zh": "AI ç†è®ºä¸ç»Ÿè®¡åŸºç¡€",
        "name_en": "AI Theory & Statistical Foundations"
    },
    "phd_methods": {
        "name_zh": "å‰æ²¿ AI æ¨¡å‹ä¸åº”ç”¨",
        "name_en": "Frontier AI Models & Applications"
    },
    "quant_crypto": {
        "name_zh": "é‡åŒ–é‡‘è (Crypto)",
        "name_en": "Quantitative Finance (Crypto)"
    }
}
TUTORIAL_DOMAIN = {
    "tutorials": "æ¯å‘¨æ•™ç¨‹ç²¾é€‰"
}

# --- 2. è¯­è¨€é€‰æ‹©å™¨ ---
lang = st.radio(
    "é€‰æ‹©è¯­è¨€ / Select Language",
    ["ç®€ä½“ä¸­æ–‡", "English"],
    horizontal=True,
    label_visibility="collapsed"
)

if lang == "ç®€ä½“ä¸­æ–‡":
    st.title("ğŸ¤– ç§äºº AI æ€»ç¼–è¾‘")
    st.caption("ç”± AI æ¯æ—¥ä¸ºæˆ‘è¯„åˆ†ç²¾é€‰çš„ç ”ç©¶è®ºæ–‡")
else:
    st.title("ğŸ¤– Personal AI Editor")
    st.caption("Daily 'Must-Read' papers, scored and curated by AI.")

# --- 3. æ ‡ç­¾é¡µè®¾è®¡ ---
tab_daily, tab_weekly = st.tabs([
    "ğŸ“… " + ("æ¯æ—¥ç²¾é€‰" if lang == "ç®€ä½“ä¸­æ–‡" else "Daily Picks"), 
    "ğŸ† " + ("æ¯å‘¨æ•™ç¨‹" if lang == "ç®€ä½“ä¸­æ–‡" else "Weekly Tutorials")
])

# --------------------------------------------------------------------------
# (V17.1) å…³é”®ä¿®æ”¹ï¼šé‡å†™æ¯æ—¥ç²¾é€‰æ ‡ç­¾é¡µ
# --------------------------------------------------------------------------
with tab_daily:
    if lang == "ç®€ä½“ä¸­æ–‡":
        selected_date = st.date_input("é€‰æ‹©ä¸€ä¸ªæ—¥æœŸ", date.today() - timedelta(days=1))
    else:
        selected_date = st.date_input("Select a date", date.today() - timedelta(days=1))
    
    st.divider()
    
    num_columns = 3 # å®Œç¾åŒ¹é… 3 ä¸ªè¶…çº§æ ¸å¿ƒ
    domain_keys = list(YOUR_DOMAINS_OF_INTEREST.keys())
    cols = st.columns(num_columns)
    
    # (V17.1) ä¿®æ”¹ï¼šç›´æ¥éå† 3 ä¸ªæ ¸å¿ƒå¹¶åˆ†é…åˆ° 3 åˆ—
    for i, domain_key in enumerate(domain_keys):
        with cols[i]:
            domain_config = YOUR_DOMAINS_OF_INTEREST[domain_key]
            domain_name = domain_config["name_zh"] if lang == "ç®€ä½“ä¸­æ–‡" else domain_config["name_en"]
            st.subheader(domain_name, divider="rainbow")
            
            file_path = os.path.join(ARCHIVE_DIR, domain_key, f"{selected_date.isoformat()}.json")
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    # (V17) å…³é”®ä¿®æ”¹ï¼šè¯»å–è®ºæ–‡åˆ—è¡¨
                    picks_list = json.load(f) 
                
                if picks_list and isinstance(picks_list, list):
                    
                    # (V17) å…³é”®ä¿®æ”¹ï¼šå¾ªç¯æ¸²æŸ“åˆ—è¡¨ä¸­çš„æ¯ä¸€ç¯‡è®ºæ–‡
                    for j, pick in enumerate(picks_list):
                        if not isinstance(pick, dict): continue 
                        
                        st.markdown(f"**{j+1}. [{pick.get('title', 'No Title')}]({pick.get('url', '#')})**")
                        authors_label = "ä½œè€…" if lang == "ç®€ä½“ä¸­æ–‡" else "Authors"
                        st.caption(f"**{authors_label}:** {pick.get('authors', 'N/A')}")
                        
                        # (V17) æ–°å¢ï¼šæ˜¾ç¤º AI è¯„åˆ†è¡¨
                        scores = pick.get('scores')
                        if scores and isinstance(scores, dict):
                            score_expander_label = "AI è¯„åˆ†å¡ (1-5åˆ†)" if lang == "ç®€ä½“ä¸­æ–‡" else "AI Scorecard (1-5)"
                            with st.expander(score_expander_label, expanded=False):
                                score_cols = st.columns(4)
                                score_cols[0].metric(label="åˆ›æ–°æ€§ (Novelty)", value=scores.get('Novelty', 'N/A'))
                                score_cols[1].metric(label="ä¸¥è°¨æ€§ (Rigor)", value=scores.get('Rigor', 'N/A'))
                                score_cols[2].metric(label="å½±å“åŠ› (Impact)", value=scores.get('Impact', 'N/A'))
                                score_cols[3].metric(label="æ¸…æ™°åº¦ (Clarity)", value=scores.get('Clarity', 'N/A'))

                        # AI æ¨èç†ç”±
                        if lang == "ç®€ä½“ä¸­æ–‡":
                            reason, reason_label = pick.get('reason_zh', 'N/A'), "AI ç¼–è¾‘æ¨èç†ç”±"
                        else:
                            reason, reason_label = pick.get('reason_en', 'N/A'), "AI Editor's Justification"
                        st.info(f"**ğŸ¤– {reason_label}:** {reason}")
                        
                        # æ‘˜è¦
                        expander_label = "æŸ¥çœ‹æ‘˜è¦" if lang == "ç®€ä½“ä¸­æ–‡" else "View Abstract"
                        with st.expander(expander_label):
                            st.write(pick.get('summary', 'N/A'))
                        
                        pdf_label = "ä¸‹è½½ PDF â”" if lang == "ç®€ä½“ä¸­æ–‡" else "Download PDF â”"
                        st.link_button(pdf_label, pick.get('pdf_url', '#'))
                        
                        if j < len(picks_list) - 1:
                            st.divider()

                else:
                    no_pick_text = "ä»Šæ—¥ AI ç¼–è¾‘æœªå‘ç°å€¼å¾—ä¸€è¯»çš„è®ºæ–‡ã€‚" if lang == "ç®€ä½“ä¸­æ–‡" else "The AI Editor found no 'must-reads' today."
                    st.write(no_pick_text)
                    
            except FileNotFoundError:
                st.write("å°šæ— æ•°æ®ã€‚" if lang == "ç®€ä½“ä¸­æ–‡" else "No data yet.")
            except json.JSONDecodeError:
                st.error("JSON æ–‡ä»¶æŸåæˆ–æ ¼å¼é”™è¯¯ã€‚")

# --------------------------------------------------------------------------
# (V17) æ¯å‘¨æ•™ç¨‹æ ‡ç­¾é¡µ (ä¿æŒ V12/V16 çš„é€»è¾‘ä¸å˜)
# (å®ƒå·²ç»æ”¯æŒåˆ—è¡¨æ¸²æŸ“ï¼Œæ‰€ä»¥æ— éœ€ä¿®æ”¹)
# --------------------------------------------------------------------------
with tab_weekly:
    today = date.today()
    year = today.isocalendar()[0]
    week_number = today.isocalendar()[1]
    
    week_options = {}
    if lang == "ç®€ä½“ä¸­æ–‡":
        week_options[f"{year}-W{week_number:02d}"] = f"{year}-W{week_number:02d} (æœ¬å‘¨)"
        week_options[f"{year}-W{week_number-1:02d}"] = f"{year}-W{week_number-1:02d} (ä¸Šå‘¨)"
    else:
        week_options[f"{year}-W{week_number:02d}"] = f"{year}-W{week_number:02d} (This Week)"
        week_options[f"{year}-W{week_number-1:02d}"] = f"{year}-W{week_number-1:02d} (Last Week)"
        
    week_str_display = st.selectbox("é€‰æ‹©å‘¨" if lang == "ç®€ä½“ä¸­æ–‡" else "Select week", options=week_options.values())
    week_str = [k for k, v in week_options.items() if v == week_str_display][0]

    st.divider()
    
    st.header(TUTORIAL_DOMAIN["tutorials"], divider="rainbow")
    file_path = os.path.join(ARCHIVE_DIR, "tutorials", f"{week_str}.json")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            picks_data = json.load(f)

        # (V12 ä¿®å¤) æ£€æŸ¥æ•°æ®ç±»å‹ï¼Œç¡®ä¿ picks_list å§‹ç»ˆæ˜¯åˆ—è¡¨
        picks_list = None
        if isinstance(picks_data, list):
            picks_list = picks_data
        elif isinstance(picks_data, dict):
            picks_list = [picks_data] # å°†æ—§çš„å•ä¸ªå¯¹è±¡åŒ…è£…æˆåˆ—è¡¨

        if picks_list:
            for i, pick in enumerate(picks_list):
                if isinstance(pick, dict):
                    st.markdown(f"**{i+1}. [{pick.get('title', 'No Title')}]({pick.get('url', '#')})**")
                    
                    authors_label = "ä½œè€…" if lang == "ç®€ä½“ä¸­æ–‡" else "Authors"
                    st.caption(f"**{authors_label}:** {pick.get('authors', 'N/A')}")
                    
                    # (V16/V17 å…¼å®¹) æ•™ç¨‹ç†ç”±
                    if lang == "ç®€ä½“ä¸­æ–‡":
                        core_value = pick.get('core_value_zh', None) 
                        reason, reason_label = pick.get('reason_zh', 'N/A'), "AI ç¼–è¾‘æ¨èç†ç”±"
                    else:
                        core_value = pick.get('core_value_en', None)
                        reason, reason_label = pick.get('reason_en', 'N/A'), "AI Editor's Justification"
                    
                    if core_value: 
                        st.success(f"**ğŸ’¡æ ¸å¿ƒä»·å€¼ï¼ˆAIä¸€å¥è¯æ€»ç»“ï¼‰ï¼š** {core_value}")

                    expander_title = reason_label + (" (ç‚¹å‡»å±•å¼€)" if core_value else "") 
                    with st.expander(expander_title):
                        st.info(f"**ğŸ†{reason_label}:** {reason}")
                    
                    expander_label = "æŸ¥çœ‹æ‘˜è¦" if lang == "ç®€ä½“ä¸­æ–‡" else "View Abstract"
                    with st.expander(expander_label):
                        st.write(pick.get('summary', 'No summary available.'))
                    pdf_label = "ä¸‹è½½ PDF â”" if lang == "ç®€ä½“ä¸­æ–‡" else "Download PDF â”"
                    st.link_button(pdf_label, pick.get('pdf_url', '#'))
                    
                    if i < len(picks_list) - 1: 
                        st.divider()
                else:
                    st.error("æ•°æ®æ ¼å¼é”™è¯¯ï¼špick ä¸æ˜¯ä¸€ä¸ªå­—å…¸ã€‚")
        else:
            no_pick_text = "æœ¬å‘¨ AI ç¼–è¾‘æœªå‘ç°å€¼å¾—ä¸€è¯»çš„æ•™ç¨‹ã€‚" if lang == "ç®€ä½“ä¸­æ–‡" else "The AI Editor found no 'must-read' tutorials this week."
            st.write(no_pick_text)
    except FileNotFoundError:
        st.write("å°šæ— æœ¬å‘¨æ•°æ®ã€‚" if lang == "ç®€ä½“ä¸­æ–‡" else "No data yet for this week.")
    except json.JSONDecodeError:
        st.error("æ— æ³•è§£æ JSON æ–‡ä»¶ï¼Œæ–‡ä»¶å¯èƒ½å·²æŸåã€‚")
