import streamlit as st
import json
import os
from datetime import date, timedelta

# --- 1. é…ç½® ---
ARCHIVE_DIR = "archive"

st.set_page_config(page_title="ç§äºº AI æ€»ç¼–è¾‘", layout="wide")

# (V11) å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨ 10 æ ¸é…ç½®
YOUR_DOMAINS_OF_INTEREST = {
    "stat_ml_foundations": {
        "name_zh": "ç»Ÿè®¡/MLåŸºç¡€ç†è®º",
        "name_en": "Statistical ML Foundations"
    },
    "causal_theory": {
        "name_zh": "å› æœæ¨æ–­/å¯è§£é‡Šæ€§",
        "name_en": "Causal Inference & XAI"
    },
    "deep_model_theory": {
        "name_zh": "æ·±åº¦æ¨¡å‹ç†è®ºä¸ä¼˜åŒ–",
        "name_en": "Deep Model Theory & Optimization"
    },
    "advanced_rl": {
        "name_zh": "é«˜çº§å¼ºåŒ–å­¦ä¹ ",
        "name_en": "Advanced Reinforcement Learning"
    },
    "llm_ds": {
        "name_zh": "å¤§æ¨¡å‹ä¸æ•°æ®ç§‘å­¦",
        "name_en": "LLM & Data Science"
    },
    "dl_architecture": {
        "name_zh": "å‰æ²¿æ¶æ„ä¸åº”ç”¨",
        "name_en": "DL Architectures & Applications"
    },
    "quant_crypto": {
        "name_zh": "é‡åŒ–é‡‘è (Crypto)",
        "name_en": "Quantitative Finance (Crypto)"
    },
    "high_dim_stats": {
        "name_zh": "é«˜ç»´ç»Ÿè®¡ä¸æ³›åŒ–",
        "name_en": "High-Dimensional Stats & Guarantees"
    },
    "representation_learning": {
        "name_zh": "è¡¨ç¤ºå­¦ä¹ ä¸åº¦é‡",
        "name_en": "Representation & Metric Learning"
    },
    "efficient_ai": {
        "name_zh": "é«˜æ•ˆ/è¾¹ç¼˜è®¡ç®— AI",
        "name_en": "Efficient & Edge AI"
    }
}
TUTORIAL_DOMAIN = {
    "tutorials": "æ¯å‘¨æ•™ç¨‹ç²¾é€‰"
}

# --- 2. è¯­è¨€é€‰æ‹©å™¨ ---
lang = st.radio(
    "é€‰æ‹©è¯­è¨€ / Select Language",
    ["ç®€ä½“ä¸­æ–‡", "English"],
    horizontal=True,
    label_visibility="collapsed"
)

if lang == "ç®€ä½“ä¸­æ–‡":
    st.title("ğŸ¤– ç§äºº AI æ€»ç¼–è¾‘")
    st.caption("ç”± AI æ¯æ—¥ä¸ºæˆ‘ç²¾é€‰çš„åšå£«ç ”ç©¶å¿…è¯»è®ºæ–‡")
else:
    st.title("ğŸ¤– Personal AI Editor")
    st.caption("Daily 'Must-Read' papers for my PhD research, curated by AI.")

# --- 3. æ ‡ç­¾é¡µè®¾è®¡ ---
tab_daily, tab_weekly = st.tabs([
    "ğŸ“… " + ("æ¯æ—¥ç²¾é€‰ (10æ ¸)" if lang == "ç®€ä½“ä¸­æ–‡" else "Daily Picks (10-Core)"), 
    "ğŸ† " + ("æ¯å‘¨æ•™ç¨‹ (ä¼˜é€‰ 2)" if lang == "ç®€ä½“ä¸­æ–‡" else "Weekly Tutorials (Top 2)")
])

# --- (V11) æ¯æ—¥ç²¾é€‰æ ‡ç­¾é¡µ (10 æ ¸åŠ¨æ€å¸ƒå±€) ---
with tab_daily:
    if lang == "ç®€ä½“ä¸­æ–‡":
        selected_date = st.date_input("é€‰æ‹©ä¸€ä¸ªæ—¥æœŸ", date.today() - timedelta(days=1))
    else:
        selected_date = st.date_input("Select a date", date.today() - timedelta(days=1))
    
    st.divider()
    
    # åŠ¨æ€ç”Ÿæˆåˆ—ä»¥æ˜¾ç¤ºæ‰€æœ‰é¢†åŸŸ
    num_columns = 3 # æ¯è¡Œæ˜¾ç¤º 3 ä¸ª
    domain_keys = list(YOUR_DOMAINS_OF_INTEREST.keys())
    cols = st.columns(num_columns)
    
    # å¾ªç¯éå†æ‰€æœ‰é¢†åŸŸï¼Œå¹¶å°†å®ƒä»¬åˆ†é…åˆ°åˆ—ä¸­
    for i, domain_key in enumerate(domain_keys):
        with cols[i % num_columns]: # ä½¿ç”¨å–ä½™ (%) åŠ¨æ€åˆ†é…
            
            domain_config = YOUR_DOMAINS_OF_INTEREST[domain_key]
            domain_name = domain_config["name_zh"] if lang == "ç®€ä½“ä¸­æ–‡" else domain_config["name_en"]
            st.subheader(domain_name, divider="rainbow")
            
            file_path = os.path.join(ARCHIVE_DIR, domain_key, f"{selected_date.isoformat()}.json")
            
            # æ¸²æŸ“é€»è¾‘ (ç”¨äºå•ä¸ª pick)
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    pick = json.load(f) # æ¯æ—¥ç²¾é€‰ä»ç„¶æ˜¯å•ä¸ªå¯¹è±¡
                
                if pick:
                    st.markdown(f"**[{pick['title']}]({pick['url']})**")
                    authors_label = "ä½œè€…" if lang == "ç®€ä½“ä¸­æ–‡" else "Authors"
                    st.caption(f"**{authors_label}:** {pick['authors']}")
                    
                    if lang == "ç®€ä½“ä¸­æ–‡":
                        reason, reason_label = pick.get('reason_zh', 'N/A'), "AI ç¼–è¾‘æ¨èç†ç”±"
                    else:
                        reason, reason_label = pick.get('reason_en', 'N/A'), "AI Editor's Justification"
                    st.info(f"**ğŸ¤– {reason_label}:** {reason}")
                    
                    expander_label = "æŸ¥çœ‹æ‘˜è¦" if lang == "ç®€ä½“ä¸­æ–‡" else "View Abstract"
                    with st.expander(expander_label):
                        st.write(pick['summary'])
                    pdf_label = "ä¸‹è½½ PDF â”" if lang == "ç®€ä½“ä¸­æ–‡" else "Download PDF â”"
                    st.link_button(pdf_label, pick['pdf_url'])
                else:
                    no_pick_text = "ä»Šæ—¥ AI ç¼–è¾‘æœªå‘ç°å€¼å¾—ä¸€è¯»çš„è®ºæ–‡ã€‚" if lang == "ç®€ä½“ä¸­æ–‡" else "The AI Editor found no 'must-reads' today."
                    st.write(no_pick_text)
            except FileNotFoundError:
                st.write("å°šæ— æ•°æ®ã€‚" if lang == "ç®€ä½“ä¸­æ–‡" else "No data yet.")

# --- (V11) æ¯å‘¨æ•™ç¨‹æ ‡ç­¾é¡µ (å¾ªç¯æ¸²æŸ“ 2 ç¯‡) ---
with tab_weekly:
    today = date.today()
    year = today.isocalendar()[0]
    week_number = today.isocalendar()[1]
    
    week_options = {}
    if lang == "ç®€ä½“ä¸­æ–‡":
        week_options[f"{year}-W{week_number:02d}"] = f"{year}-W{week_number:02d} (æœ¬å‘¨)"
        week_options[f"{year}-W{week_number-1:02d}"] = f"{year}-W{week_number-1:02d} (ä¸Šå‘¨)"
    else:
        week_options[f"{year}-W{week_number:02d}"] = f"{year}-W{week_number:02d} (This Week)"
        week_options[f"{year}-W{week_number-1:02d}"] = f"{year}-W{week_number-1:02d} (Last Week)"
        
    week_str_display = st.selectbox("é€‰æ‹©å‘¨" if lang == "ç®€ä½“ä¸­æ–‡" else "Select week", options=week_options.values())
    week_str = [k for k, v in week_options.items() if v == week_str_display][0]

    st.divider()
    
    st.header(TUTORIAL_DOMAIN["tutorials"], divider="rainbow")
    file_path = os.path.join(ARCHIVE_DIR, "tutorials", f"{week_str}.json")
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            picks_list = json.load(f) # <--- å…³é”®ä¿®æ”¹ï¼šè¯»å–åˆ—è¡¨
        
        if picks_list: # <--- å…³é”®ä¿®æ”¹ï¼šæ£€æŸ¥åˆ—è¡¨æ˜¯å¦éç©º
            
            # (V11) å¾ªç¯æ¸²æŸ“åˆ—è¡¨ä¸­çš„æ¯ä¸€ç¯‡æ•™ç¨‹
            for i, pick in enumerate(picks_list):
                
                st.markdown(f"**{i+1}. [{pick['title']}]({pick['url']})**")
                authors_label = "ä½œè€…" if lang == "ç®€ä½“ä¸­æ–‡" else "Authors"
                st.caption(f"**{authors_label}:** {pick['authors']}")
                
                if lang == "ç®€ä½“ä¸­æ–‡":
                    reason, reason_label = pick.get('reason_zh', 'N/A'), "AI ç¼–è¾‘æ¨èç†ç”±"
                else:
                    reason, reason_label = pick.get('reason_en', 'N/A'), "AI Editor's Justification"
                st.info(f"**ğŸ† {reason_label}:** {reason}")
                
                expander_label = "æŸ¥çœ‹æ‘˜è¦" if lang == "ç®€ä½“ä¸­æ–‡" else "View Abstract"
                with st.expander(expander_label):
                    st.write(pick['summary'])
                pdf_label = "ä¸‹è½½ PDF â”" if lang == "ç®€ä½“ä¸­æ–‡" else "Download PDF â”"
                st.link_button(pdf_label, pick['pdf_url'])
                
                if i < len(picks_list) - 1: # å¦‚æœä¸æ˜¯æœ€åä¸€ç¯‡ï¼Œæ·»åŠ åˆ†éš”çº¿
                    st.divider()

        else:
            no_pick_text = "æœ¬å‘¨ AI ç¼–è¾‘æœªå‘ç°å€¼å¾—ä¸€è¯»çš„æ•™ç¨‹ã€‚" if lang == "ç®€ä½“ä¸­æ–‡" else "The AI Editor found no 'must-read' tutorials this week."
            st.write(no_pick_text)
    except FileNotFoundError:
        st.write("å°šæ— æœ¬å‘¨æ•°æ®ã€‚" if lang == "ç®€ä½“ä¸­æ–‡" else "No data yet for this week.")
