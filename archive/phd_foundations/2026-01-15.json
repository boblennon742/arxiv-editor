[
    {
        "id": "http://arxiv.org/abs/2601.10701v1",
        "title": "Communication-Efficient and Privacy-Adaptable Mechanism -- a Federated Learning Scheme with Convergence Analysis",
        "summary": "Federated learning enables multiple parties to jointly train learning models without sharing their own underlying data, offering a practical pathway to privacy-preserving collaboration under data-governance constraints. Continued study of federated learning is essential to address key challenges in it, including communication efficiency and privacy protection between parties. A recent line of work introduced a novel approach called the Communication-Efficient and Privacy-Adaptable Mechanism (CEPAM), which achieves both objectives simultaneously. CEPAM leverages the rejection-sampled universal quantizer (RSUQ), a randomized vector quantizer whose quantization error is equivalent to a prescribed noise, which can be tuned to customize privacy protection between parties. In this work, we theoretically analyze the privacy guarantees and convergence properties of CEPAM. Moreover, we assess CEPAM's utility performance through experimental evaluations, including convergence profiles compared with other baselines, and accuracy-privacy trade-offs between different parties.",
        "authors": "Chun Hei Michael Shiu, Chih Wei Ling",
        "url": "http://arxiv.org/abs/2601.10701v1",
        "pdf_url": "https://arxiv.org/pdf/2601.10701v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该论文对联邦学习中的通信效率和隐私保护机制进行了理论分析，提供了收敛性分析和隐私保证，完美符合对统计保证和理论严谨性的要求。"
    },
    {
        "id": "http://arxiv.org/abs/2601.10641v1",
        "title": "Adjusted Similarity Measures and a Violation of Expectations",
        "summary": "Adjusted similarity measures, such as Cohen's kappa for inter-rater reliability and the adjusted Rand index used to compare clustering algorithms, are a vital tool for comparing discrete labellings. These measures are intended to have the property of 0 expectation under a null distribution and maximum value 1 under maximal similarity to aid in interpretation. Measures are frequently adjusted with respect to the permutation distribution for historic and analytic reasons. There is currently renewed interest in considering other null models more appropriate for context, such as clustering ensembles permitting a random number of identified clusters. The purpose of this work is two -- fold: (1) to generalize the study of the adjustment operator to general null models and to a more general procedure which includes statistical standardization as a special case and (2) to identify sufficient conditions for the adjustment operator to produce the intended properties, where sufficient conditions are related to whether and how observed data are incorporated into null distributions. We demonstrate how violations of the sufficient conditions may lead to substantial breakdown, such as by producing a non-positive measure under traditional adjustment rather than one with mean 0, or by producing a measure which is deterministically 0 under statistical standardization.",
        "authors": "William L. Lippitt, Edward J. Bedrick, Nichole E. Carlson",
        "url": "http://arxiv.org/abs/2601.10641v1",
        "pdf_url": "https://arxiv.org/pdf/2601.10641v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 3,
            "Clarity": 4
        },
        "reason_zh": "这篇论文深入探讨了调整相似性度量的理论基础，泛化了调整算子并识别了产生预期属性的充分条件，具有很强的统计学理论严谨性。"
    },
    {
        "id": "http://arxiv.org/abs/2601.10623v1",
        "title": "Fair Regression under Demographic Parity: A Unified Framework",
        "summary": "We propose a unified framework for fair regression tasks formulated as risk minimization problems subject to a demographic parity constraint. Unlike many existing approaches that are limited to specific loss functions or rely on challenging non-convex optimization, our framework is applicable to a broad spectrum of regression tasks. Examples include linear regression with squared loss, binary classification with cross-entropy loss, quantile regression with pinball loss, and robust regression with Huber loss. We derive a novel characterization of the fair risk minimizer, which yields a computationally efficient estimation procedure for general loss functions. Theoretically, we establish the asymptotic consistency of the proposed estimator and derive its convergence rates under mild assumptions. We illustrate the method's versatility through detailed discussions of several common loss functions. Numerical results demonstrate that our approach effectively minimizes risk while satisfying fairness constraints across various regression settings.",
        "authors": "Yongzhen Feng, Weiwei Wang, Raymond K. W. Wong, Xianyang Zhang",
        "url": "http://arxiv.org/abs/2601.10623v1",
        "pdf_url": "https://arxiv.org/pdf/2601.10623v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 5
        },
        "reason_zh": "论文提出了一个用于公平回归任务的统一框架，并建立了所提出估计器的渐近一致性和收敛速率，提供了强大的统计保证和清晰的理论推导。"
    },
    {
        "id": "http://arxiv.org/abs/2601.10600v1",
        "title": "Procedural Fairness in Multi-Agent Bandits",
        "summary": "In the context of multi-agent multi-armed bandits (MA-MAB), fairness is often reduced to outcomes: maximizing welfare, reducing inequality, or balancing utilities. However, evidence in psychology, economics, and Rawlsian theory suggests that fairness is also about process and who gets a say in the decisions being made. We introduce a new fairness objective, procedural fairness, which provides equal decision-making power for all agents, lies in the core, and provides for proportionality in outcomes. Empirical results confirm that fairness notions based on optimizing for outcomes sacrifice equal voice and representation, while the sacrifice in outcome-based fairness objectives (like equality and utilitarianism) is minimal under procedurally fair policies. We further prove that different fairness notions prioritize fundamentally different and incompatible values, highlighting that fairness requires explicit normative choices. This paper argues that procedural legitimacy deserves greater focus as a fairness objective, and provides a framework for putting procedural fairness into practice.",
        "authors": "Joshua Caiata, Carter Blair, Kate Larson",
        "url": "http://arxiv.org/abs/2601.10600v1",
        "pdf_url": "https://arxiv.org/pdf/2601.10600v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 4,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该论文在多智能体多臂老虎机中引入了程序公平性这一新颖的公平性目标，并从理论上探讨了其与结果公平性的不同价值取向，具有因果逻辑和规范性选择的理论深度。"
    },
    {
        "id": "http://arxiv.org/abs/2601.10591v1",
        "title": "ProbFM: Probabilistic Time Series Foundation Model with Uncertainty Decomposition",
        "summary": "Time Series Foundation Models (TSFMs) have emerged as a promising approach for zero-shot financial forecasting, demonstrating strong transferability and data efficiency gains. However, their adoption in financial applications is hindered by fundamental limitations in uncertainty quantification: current approaches either rely on restrictive distributional assumptions, conflate different sources of uncertainty, or lack principled calibration mechanisms. While recent TSFMs employ sophisticated techniques such as mixture models, Student's t-distributions, or conformal prediction, they fail to address the core challenge of providing theoretically-grounded uncertainty decomposition. For the very first time, we present a novel transformer-based probabilistic framework, ProbFM (probabilistic foundation model), that leverages Deep Evidential Regression (DER) to provide principled uncertainty quantification with explicit epistemic-aleatoric decomposition. Unlike existing approaches that pre-specify distributional forms or require sampling-based inference, ProbFM learns optimal uncertainty representations through higher-order evidence learning while maintaining single-pass computational efficiency. To rigorously evaluate the core DER uncertainty quantification approach independent of architectural complexity, we conduct an extensive controlled comparison study using a consistent LSTM architecture across five probabilistic methods: DER, Gaussian NLL, Student's-t NLL, Quantile Loss, and Conformal Prediction. Evaluation on cryptocurrency return forecasting demonstrates that DER maintains competitive forecasting accuracy while providing explicit epistemic-aleatoric uncertainty decomposition. This work establishes both an extensible framework for principled uncertainty quantification in foundation models and empirical evidence for DER's effectiveness in financial applications.",
        "authors": "Arundeep Chinta, Lucas Vinh Tran, Jay Katukuri",
        "url": "http://arxiv.org/abs/2601.10591v1",
        "pdf_url": "https://arxiv.org/pdf/2601.10591v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "首次提出了具有理论基础的不确定性分解概率时间序列基础模型，通过高阶证据学习提供显式的认知-偶然不确定性分解，完美契合对理论基础和统计保证的偏好。"
    },
    {
        "id": "http://arxiv.org/abs/2601.10590v1",
        "title": "From aggressive to conservative early stopping in Bayesian group sequential designs",
        "summary": "Group sequential designs (GSDs) are widely used in confirmatory trials to allow interim monitoring while preserving control of the type I error rate. In the frequentist framework, O'Brien-Fleming-type stopping boundaries dominate practice because they impose highly conservative early stopping while allowing more liberal decisions as information accumulates. Bayesian GSDs, in contrast, are most often implemented using fixed posterior probability thresholds applied uniformly at all analyses. While such designs can be calibrated to control the overall type I error rate, they do not penalise early analyses and can therefore lead to substantially more aggressive early stopping. Such behaviour can risk premature conclusions and inflation of treatment effect estimates, raising concerns for confirmatory trials. We introduce two practically implementable refinements that restore conservative early stopping in Bayesian GSDs. The first introduces a two-phase structure for posterior probability thresholds, applying more stringent criteria in the early phase of the trial and relaxing them later to preserve power. The second replaces posterior probability monitoring at interim looks with predictive probability criteria, which naturally account for uncertainty in future data and therefore suppress premature stopping. Both strategies require only one additional tuning parameter and can be efficiently calibrated. In the HYPRESS setting, both approaches achieve higher power than the conventional Bayesian design while producing alpha-spending profiles closely aligned with O'Brien-Fleming-type behaviour at early looks. These refinements provide a principled and tractable way to align Bayesian GSDs with accepted frequentist practice and regulatory expectations, supporting their robust application in confirmatory trials.",
        "authors": "Zhangyi He, Feng Yu, Suzie Cro, Laurent Billot",
        "url": "http://arxiv.org/abs/2601.10590v1",
        "pdf_url": "https://arxiv.org/pdf/2601.10590v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 5
        },
        "reason_zh": "这篇论文针对贝叶斯序贯设计提出了保守早期停止的原理性改进，通过两阶段阈值和预测概率准则，提供了严格的I类错误率控制和与频数方法的一致性，理论严谨且具有实践意义。"
    },
    {
        "id": "http://arxiv.org/abs/2601.10541v1",
        "title": "Mixtures of Transparent Local Models",
        "summary": "The predominance of machine learning models in many spheres of human activity has led to a growing demand for their transparency. The transparency of models makes it possible to discern some factors, such as security or non-discrimination. In this paper, we propose a mixture of transparent local models as an alternative solution for designing interpretable (or transparent) models. Our approach is designed for the situations where a simple and transparent function is suitable for modeling the label of instances in some localities/regions of the input space, but may change abruptly as we move from one locality to another. Consequently, the proposed algorithm is to learn both the transparent labeling function and the locality of the input space where the labeling function achieves a small risk in its assigned locality. By using a new multi-predictor (and multi-locality) loss function, we established rigorous PAC-Bayesian risk bounds for the case of binary linear classification problem and that of linear regression. In both cases, synthetic data sets were used to illustrate how the learning algorithms work. The results obtained from real data sets highlight the competitiveness of our approach compared to other existing methods as well as certain opaque models. Keywords: PAC-Bayes, risk bounds, local models, transparent models, mixtures of local transparent models.",
        "authors": "Niffa Cheick Oumar Diaby, Thierry Duchesne, Mario Marchand",
        "url": "http://arxiv.org/abs/2601.10541v1",
        "pdf_url": "https://arxiv.org/pdf/2601.10541v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "论文提出了一个统一的网络回归框架NPR，并建立了在弱条件下的估计器一致性和渐近正态性，以及有效的假设检验，理论严谨，提供了强大的统计保证。"
    },
    {
        "id": "http://arxiv.org/abs/2601.10524v1",
        "title": "Diagnosing Generalization Failures in Fine-Tuned LLMs: A Cross-Architectural Study on Phishing Detection",
        "summary": "The practice of fine-tuning Large Language Models (LLMs) has achieved state-of-the-art performance on specialized tasks, yet diagnosing why these models become brittle and fail to generalize remains a critical open problem. To address this, we introduce and apply a multi-layered diagnostic framework to a cross-architectural study. We fine-tune Llama 3.1 8B, Gemma 2 9B, and Mistral models on a high-stakes phishing detection task and use SHAP analysis and mechanistic interpretability to uncover the root causes of their generalization failures. Our investigation reveals three critical findings: (1) Generalization is driven by a powerful synergy between architecture and data diversity. The Gemma 2 9B model achieves state-of-the-art performance (>91\\% F1), but only when trained on a stylistically diverse ``generalist'' dataset. (2) Generalization is highly architecture-dependent. We diagnose a specific failure mode in Llama 3.1 8B, which performs well on a narrow domain but cannot integrate diverse data, leading to a significant performance drop. (3) Some architectures are inherently more generalizable. The Mistral model proves to be a consistent and resilient performer across multiple training paradigms. By pinpointing the flawed heuristics responsible for these failures, our work provides a concrete methodology for diagnosing and understanding generalization failures, underscoring that reliable AI requires deep validation of the interplay between architecture, data, and training strategy.",
        "authors": "Frank Bobe, Gregory D. Vetaw, Chase Pavlick, Darshan Bryner, Matthew Cook, Jose Salas-Vernis",
        "url": "http://arxiv.org/abs/2601.10524v1",
        "pdf_url": "https://arxiv.org/pdf/2601.10524v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 3,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该研究通过SHAP分析和机制可解释性诊断LLM泛化失败的根本原因，虽然侧重诊断而非新理论，但其严谨的分析方法和对LLM行为的深入理解符合对数学逻辑应用于AI系统的兴趣。"
    },
    {
        "id": "http://arxiv.org/abs/2601.10334v1",
        "title": "An analytic theory of convolutional neural network inverse problems solvers",
        "summary": "Supervised convolutional neural networks (CNNs) are widely used to solve imaging inverse problems, achieving state-of-the-art performance in numerous applications. However, despite their empirical success, these methods are poorly understood from a theoretical perspective and often treated as black boxes. To bridge this gap, we analyze trained neural networks through the lens of the Minimum Mean Square Error (MMSE) estimator, incorporating functional constraints that capture two fundamental inductive biases of CNNs: translation equivariance and locality via finite receptive fields. Under the empirical training distribution, we derive an analytic, interpretable, and tractable formula for this constrained variant, termed Local-Equivariant MMSE (LE-MMSE). Through extensive numerical experiments across various inverse problems (denoising, inpainting, deconvolution), datasets (FFHQ, CIFAR-10, FashionMNIST), and architectures (U-Net, ResNet, PatchMLP), we demonstrate that our theory matches the neural networks outputs (PSNR $\\gtrsim25$dB). Furthermore, we provide insights into the differences between \\emph{physics-aware} and \\emph{physics-agnostic} estimators, the impact of high-density regions in the training (patch) distribution, and the influence of other factors (dataset size, patch size, etc).",
        "authors": "Minh Hai Nguyen, Quoc Bao Do, Edouard Pauwels, Pierre Weiss",
        "url": "http://arxiv.org/abs/2601.10334v1",
        "pdf_url": "https://arxiv.org/pdf/2601.10334v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该论文针对卷积神经网络逆问题求解器，从最小均方误差（MMSE）估计器的角度推导了分析性理论，提供了可解释且可处理的公式，填补了理论理解的空白，理论基础极其强大。"
    },
    {
        "id": "http://arxiv.org/abs/2601.10252v1",
        "title": "Asymptotic Theory of Tail Dependence Measures for Checkerboard Copula and the Validity of Multiplier Bootstrap",
        "summary": "Nonparametric estimation and inference for lower and upper tail copulas under unknown marginal distributions are considered. To mitigate the inherent discreteness and boundary irregularities of the empirical tail copula, a checkerboard smoothed tail copula estimator based on local bilinear interpolation is introduced. Almost sure uniform consistency and weak convergence of the centered and scaled empirical checkerboard tail copula process are established in the space of bounded functions. The resulting Gaussian limit differs from its known-marginal counterpart and incorporates additional correction terms that account for first-order stochastic errors arising from marginal estimation. Since the limiting covariance structure depends on the unknown tail copula and its partial derivatives, direct asymptotic inference is generally infeasible. To address this challenge, a direct multiplier bootstrap procedure tailored to the checkerboard tail copula is developed. By combining multiplier reweighting with checkerboard smoothing, the bootstrap preserves the extremal dependence structure of the data and consistently captures both joint tail variability and the effects of marginal estimation. Conditional weak convergence of the bootstrap process to the same Gaussian limit as the original estimator is established, yielding asymptotically valid inference for smooth functionals of the tail copula, including the lower and upper tail dependence coefficient. The proposed approach provides a fully feasible framework for confidence regions and hypothesis testing in tail dependence analysis without requiring explicit estimation of the limiting covariance structure. A simulation study illustrates the finite-sample performance of the proposed estimator and demonstrates the accuracy and reliability of the bootstrap confidence intervals under various dependence structures and tuning parameter choices.",
        "authors": "Mayukh Choudhury, Debraj Das, Sujit Ghosh",
        "url": "http://arxiv.org/abs/2601.10252v1",
        "pdf_url": "https://arxiv.org/pdf/2601.10252v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 3,
            "Clarity": 5
        },
        "reason_zh": "这是一篇纯粹的理论统计学论文，为尾部依赖测度的非参数估计和推断建立了几乎必然一致性、弱收敛性和乘子自举的渐近有效性，理论严谨性极高，数学推导清晰。"
    },
    {
        "id": "http://arxiv.org/abs/2601.10137v1",
        "title": "Step-by-Step Causality: Transparent Causal Discovery with Multi-Agent Tree-Query and Adversarial Confidence Estimation",
        "summary": "Causal discovery aims to recover ``what causes what'', but classical constraint-based methods (e.g., PC, FCI) suffer from error propagation, and recent LLM-based causal oracles often behave as opaque, confidence-free black boxes. This paper introduces Tree-Query, a tree-structured, multi-expert LLM framework that reduces pairwise causal discovery to a short sequence of queries about backdoor paths, (in)dependence, latent confounding, and causal direction, yielding interpretable judgments with robustness-aware confidence scores. Theoretical guarantees are provided for asymptotic identifiability of four pairwise relations. On data-free benchmarks derived from Mooij et al. and UCI causal graphs, Tree-Query improves structural metrics over direct LLM baselines, and a diet--weight case study illustrates confounder screening and stable, high-confidence causal conclusions. Tree-Query thus offers a principled way to obtain data-free causal priors from LLMs that can complement downstream data-driven causal discovery. Code is available at https://anonymous.4open.science/r/Repo-9B3E-4F96.",
        "authors": "Ziyi Ding, Chenfei Ye-Hao, Zheyuan Wang, Xiao-Ping Zhang",
        "url": "http://arxiv.org/abs/2601.10137v1",
        "pdf_url": "https://arxiv.org/pdf/2601.10137v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "论文提出了基于LLM的透明因果发现框架Tree-Query，并提供了四种成对关系渐近可识别性的理论保证，结合了因果逻辑和数学严谨性，是因果推断领域的优秀理论工作。"
    },
    {
        "id": "http://arxiv.org/abs/2601.10098v1",
        "title": "InfoSculpt: Sculpting the Latent Space for Generalized Category Discovery",
        "summary": "Generalized Category Discovery (GCD) aims to classify instances from both known and novel categories within a large-scale unlabeled dataset, a critical yet challenging task for real-world, open-world applications. However, existing methods often rely on pseudo-labeling, or two-stage clustering, which lack a principled mechanism to explicitly disentangle essential, category-defining signals from instance-specific noise. In this paper, we address this fundamental limitation by re-framing GCD from an information-theoretic perspective, grounded in the Information Bottleneck (IB) principle. We introduce InfoSculpt, a novel framework that systematically sculpts the representation space by minimizing a dual Conditional Mutual Information (CMI) objective. InfoSculpt uniquely combines a Category-Level CMI on labeled data to learn compact and discriminative representations for known classes, and a complementary Instance-Level CMI on all data to distill invariant features by compressing augmentation-induced noise. These two objectives work synergistically at different scales to produce a disentangled and robust latent space where categorical information is preserved while noisy, instance-specific details are discarded. Extensive experiments on 8 benchmarks demonstrate that InfoSculpt validating the effectiveness of our information-theoretic approach.",
        "authors": "Wenwen Liao, Hang Ruan, Jianbo Yu, Yuansong Wang, Qingchao Jiang, Xiaofeng Yang",
        "url": "http://arxiv.org/abs/2601.10098v1",
        "pdf_url": "https://arxiv.org/pdf/2601.10098v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该论文从信息论角度重新构建了广义类别发现问题，基于信息瓶颈原理，通过最小化双条件互信息目标来解耦表示空间，理论基础强大，数学推导严谨。"
    },
    {
        "id": "http://arxiv.org/abs/2601.09979v1",
        "title": "In-Context Operator Learning on the Space of Probability Measures",
        "summary": "We introduce \\emph{in-context operator learning on probability measure spaces} for optimal transport (OT). The goal is to learn a single solution operator that maps a pair of distributions to the OT map, using only few-shot samples from each distribution as a prompt and \\emph{without} gradient updates at inference. We parameterize the solution operator and develop scaling-law theory in two regimes. In the \\emph{nonparametric} setting, when tasks concentrate on a low-intrinsic-dimension manifold of source--target pairs, we establish generalization bounds that quantify how in-context accuracy scales with prompt size, intrinsic task dimension, and model capacity. In the \\emph{parametric} setting (e.g., Gaussian families), we give an explicit architecture that recovers the exact OT map in context and provide finite-sample excess-risk bounds. Our numerical experiments on synthetic transports and generative-modeling benchmarks validate the framework.",
        "authors": "Frank Cole, Dixi Wang, Yineng Chen, Yulong Lu, Rongjie Lai",
        "url": "http://arxiv.org/abs/2601.09979v1",
        "pdf_url": "https://arxiv.org/pdf/2601.09979v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 5
        },
        "reason_zh": "该论文提出了概率测度空间上的上下文算子学习，并发展了缩放律理论、泛化界和有限样本超额风险界，完美符合对强大理论基础和清晰数学推导的最高要求。"
    }
]