[
    {
        "id": "http://arxiv.org/abs/2511.13421v1",
        "title": "Larger Datasets Can Be Repeated More: A Theoretical Analysis of Multi-Epoch Scaling in Linear Regression",
        "summary": "While data scaling laws of large language models (LLMs) have been widely examined in the one-pass regime with massive corpora, their form under limited data and repeated epochs remains largely unexplored. This paper presents a theoretical analysis of how a common workaround, training for multiple epochs on the same dataset, reshapes the data scaling laws in linear regression. Concretely, we ask: to match the performance of training on a dataset of size $N$ for $K$ epochs, how much larger must a dataset be if the model is trained for only one pass? We quantify this using the \\textit{effective reuse rate} of the data, $E(K, N)$, which we define as the multiplicative factor by which the dataset must grow under one-pass training to achieve the same test loss as $K$-epoch training. Our analysis precisely characterizes the scaling behavior of $E(K, N)$ for SGD in linear regression under either strong convexity or Zipf-distributed data: (1) When $K$ is small, we prove that $E(K, N) \\approx K$, indicating that every new epoch yields a linear gain; (2) As $K$ increases, $E(K, N)$ plateaus at a problem-dependent value that grows with $N$ ($Θ(\\log N)$ for the strongly-convex case), implying that larger datasets can be repeated more times before the marginal benefit vanishes. These theoretical findings point out a neglected factor in a recent empirical study (Muennighoff et al. (2023)), which claimed that training LLMs for up to $4$ epochs results in negligible loss differences compared to using fresh data at each step, \\textit{i.e.}, $E(K, N) \\approx K$ for $K \\le 4$ in our notation. Supported by further empirical validation with LLMs, our results reveal that the maximum $K$ value for which $E(K, N) \\approx K$ in fact depends on the data size and distribution, and underscore the need to explicitly model both factors in future studies of scaling laws with data reuse.",
        "authors": "Tingkai Yan, Haodong Wen, Binghui Li, Kairong Luo, Wenguang Chen, Kaifeng Lyu",
        "url": "http://arxiv.org/abs/2511.13421v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13421v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 5,
            "Clarity": 4
        },
        "reason_zh": "这篇论文以数理统计博士生的高度严谨性，对多epoch训练下的LLM数据扩展定律进行了开创性的理论分析。它引入了“有效重用率”这一新概念，并提供了严格的数学证明，揭示了数据集大小和分布如何影响数据复用的效益。这直接解决了LLM训练中一个核心的实际应用瓶颈——数据效率与计算成本，为理解和优化未来大型模型的训练策略提供了深远的理论指导。其方法具有显著的理论创新性和严谨性，完美契合您对前沿算法和架构的关注。"
    },
    {
        "id": "http://arxiv.org/abs/2511.13411v1",
        "title": "An Operational Kardashev-Style Scale for Autonomous AI - Towards AGI and Superintelligence",
        "summary": "We propose a Kardashev-inspired yet operational Autonomous AI (AAI) Scale that measures the progression from fixed robotic process automation (AAI-0) to full artificial general intelligence (AAI-4) and beyond. Unlike narrative ladders, our scale is multi-axis and testable. We define ten capability axes (Autonomy, Generality, Planning, Memory/Persistence, Tool Economy, Self-Revision, Sociality/Coordination, Embodiment, World-Model Fidelity, Economic Throughput) aggregated by a composite AAI-Index (a weighted geometric mean). We introduce a measurable Self-Improvement Coefficient $κ$ (capability growth per unit of agent-initiated resources) and two closure properties (maintenance and expansion) that convert ``self-improving AI'' into falsifiable criteria. We specify OWA-Bench, an open-world agency benchmark suite that evaluates long-horizon, tool-using, persistent agents. We define level gates for AAI-0\\ldots AAI-4 using thresholds on the axes, $κ$, and closure proofs. Synthetic experiments illustrate how present-day systems map onto the scale and how the delegability frontier (quality vs.\\ autonomy) advances with self-improvement. We also prove a theorem that AAI-3 agent becomes AAI-5 over time with sufficient conditions, formalizing \"baby AGI\" becomes Superintelligence intuition.",
        "authors": "Przemyslaw Chojecki",
        "url": "http://arxiv.org/abs/2511.13411v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13411v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 5,
            "Clarity": 4
        },
        "reason_zh": "该研究提出了一个新颖且可操作的Kardashev式自主AI（AAI）分级量表，旨在衡量AI从固定RPA到通用人工智能（AGI）乃至超级智能的演进。它通过多轴能力定义、可测量的“自我改进系数”和闭包属性，为理解和量化AI的进步提供了严格的理论框架，甚至证明了AAI-3代理在特定条件下可演变为AAI-5。这篇论文不仅具有极高的理论创新性，而且对定义AI的未来发展路径和衡量其能力边界具有里程碑式的实践影响力，深刻符合您对前沿算法和架构的哲学思考。"
    },
    {
        "id": "http://arxiv.org/abs/2511.13391v1",
        "title": "Finding Kissing Numbers with Game-theoretic Reinforcement Learning",
        "summary": "Since Isaac Newton first studied the Kissing Number Problem in 1694, determining the maximal number of non-overlapping spheres around a central sphere has remained a fundamental challenge. This problem represents the local analogue of Hilbert's 18th problem on sphere packing, bridging geometry, number theory, and information theory. Although significant progress has been made through lattices and codes, the irregularities of high-dimensional geometry and exponentially growing combinatorial complexity beyond 8 dimensions, which exceeds the complexity of Go game, limit the scalability of existing methods. Here we model this problem as a two-player matrix completion game and train the game-theoretic reinforcement learning system, PackingStar, to efficiently explore high-dimensional spaces. The matrix entries represent pairwise cosines of sphere center vectors; one player fills entries while another corrects suboptimal ones, jointly maximizing the matrix size, corresponding to the kissing number. This cooperative dynamics substantially improves sample quality, making the extremely large spaces tractable. PackingStar reproduces previous configurations and surpasses all human-known records from dimensions 25 to 31, with the configuration in 25 dimensions geometrically corresponding to the Leech lattice and suggesting possible optimality. It achieves the first breakthrough beyond rational structures from 1971 in 13 dimensions and discovers over 6000 new structures in 14 and other dimensions. These results demonstrate AI's power to explore high-dimensional spaces beyond human intuition and open new pathways for the Kissing Number Problem and broader geometry problems.",
        "authors": "Chengdong Ma, Théo Tao Zhaowei, Pengyu Li, Minghao Liu, Haojun Chen, Zihao Mao, Yuan Cheng, Yuan Qi, Yaodong Yang",
        "url": "http://arxiv.org/abs/2511.13391v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13391v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 5,
            "Clarity": 4
        },
        "reason_zh": "这篇论文将一个自17世纪以来就存在的数学难题——“亲吻数问题”——创造性地建模为一个双人矩阵填充博弈，并利用博弈论强化学习系统（PackingStar）来解决。它不仅复现了现有结果，还在25到31维空间中超越了所有人类已知记录，甚至在13维空间中首次突破了1971年以来的理性结构限制。这种将前沿算法（博弈论强化学习）应用于基础数学问题，并取得重大理论突破的能力，展现了极高的理论创新性和严谨的数理统计方法，完全符合您作为数理统计博士生对前沿算法和理论创新的追求。"
    },
    {
        "id": "http://arxiv.org/abs/2511.13193v1",
        "title": "Cost-Effective Communication: An Auction-based Method for Language Agent Interaction",
        "summary": "Multi-agent systems (MAS) built on large language models (LLMs) often suffer from inefficient \"free-for-all\" communication, leading to exponential token costs and low signal-to-noise ratios that hinder their practical deployment. We challenge the notion that more communication is always beneficial, hypothesizing instead that the core issue is the absence of resource rationality. We argue that \"free\" communication, by ignoring the principle of scarcity, inherently breeds inefficiency and unnecessary expenses. To address this, we introduce the Dynamic Auction-based Language Agent (DALA), a novel framework that treats communication bandwidth as a scarce and tradable resource. Specifically, our DALA regards inter-agent communication as a centralized auction, where agents learn to bid for the opportunity to speak based on the predicted value density of their messages. Thus, our DALA intrinsically encourages agents to produce concise, informative messages while filtering out low-value communication. Extensive and comprehensive experiments demonstrate that our economically-driven DALA achieves new state-of-the-art performance across seven challenging reasoning benchmarks, including 84.32% on MMLU and a 91.21% pass@1 rate on HumanEval. Note that this is accomplished with remarkable efficiency, i.e., our DALA uses only 6.25 million tokens, a fraction of the resources consumed by current state-of-the-art methods on GSM8K. Further analysis reveals that our DALA cultivates the emergent skill of strategic silence, effectively adapting its communication strategies from verbosity to silence in a dynamical manner via resource constraints.",
        "authors": "Yijia Fan, Jusheng Zhang, Kaitong Cai, Jing Yang, Chengpei Tang, Jian Wang, Keze Wang",
        "url": "http://arxiv.org/abs/2511.13193v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13193v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 5,
            "Clarity": 4
        },
        "reason_zh": "该研究引入了DALA（动态拍卖式语言代理）框架，将多代理LLM系统中的通信带宽视为稀缺资源，并通过集中的拍卖机制进行管理。这种经济学驱动的创新方法，使代理能够基于消息的价值密度学习出价，从而实现高效、有策略的通信，显著降低了高达数倍的Token成本（数据效率），同时在多个基准测试中取得了最先进的性能。其理论严谨性体现在将博弈论和经济学原理应用于多代理LLM通信，有效解决了LLM应用中的关键瓶颈（数据效率和通信效率），兼具理论深度和实际影响力。"
    },
    {
        "id": "http://arxiv.org/abs/2511.13007v1",
        "title": "GEM: Generative Entropy-Guided Preference Modeling for Few-shot Alignment of LLMs",
        "summary": "Alignment of large language models (LLMs) with human preferences typically relies on supervised reward models or external judges that demand abundant annotations. However, in fields that rely on professional knowledge, such as medicine and law, such large-scale preference labels are often unachievable. In this paper, we propose a generative entropy-guided preference modeling approach named GEM for LLMs aligment at low-resource and domain-specific scenarios. Instead of training a discriminative reward model on preference data, we directly train the LLM to internalize a closed-loop optimization architecture that can extract and exploit the multi-dimensional, fine-grained cognitive signals implicit in human preferences. Specifically, our Cognitive Filtering module, based on entropy theory in decision making, first leverages Chain-of-Thought (CoT) prompting to generate diverse candidate reasoning chains (CoTs) from preference data. Subsequently, it introduces a token scoring mechanism to rank and weight the sampled CoTs, boosting the importance of high-confidence answers and strategically high-entropy tokens. Building on these filtered preferences, we fine-tune the LLM using a novel self-evaluated group advantage algorithm, SEGA, which effectively aggregates group-level cognitive signals and transforms the entropy-based scores into implicit rewards for policy optimization. In these ways, GEM empowers the LLM to rely on its own judgments and establishes an entropy-guided closed-loop cognitive optimization framework, enabling highly efficient few-shot alignment of LLMs. Experiments on general benchmarks and domain-specific tasks (such as mathematical reasoning and medical dialogues) demonstrate that our GEM achieves significant improvements with few-shot preference data.",
        "authors": "Yiyang Zhao, Huiyu Bai, Xuejiao Zhao",
        "url": "http://arxiv.org/abs/2511.13007v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13007v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 5,
            "Clarity": 4
        },
        "reason_zh": "该论文提出了GEM（生成式熵引导偏好建模）方法，用于LLM的少样本对齐，这在专业知识（如医学、法律）领域数据稀缺的背景下尤为重要。它创新性地通过LLM直接内化闭环优化架构，利用熵理论进行认知过滤，并采用自评估群组优势算法（SEGA）将熵分数转化为隐式奖励。这种方法具有极高的理论创新性和严谨性，从决策制定中的熵理论出发，解决了LLM对齐中的数据效率和可靠性瓶颈，显著提升了少样本场景下的对齐效果，完美符合您对算法、架构和实际应用瓶颈的关注。"
    }
]