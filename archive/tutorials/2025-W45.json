[
    {
        "id": "http://arxiv.org/abs/2511.02531v2",
        "title": "Causal Graph Neural Networks for Healthcare",
        "summary": "Healthcare artificial intelligence systems routinely fail when deployed across institutions, with documented performance drops and perpetuation of discriminatory patterns embedded in historical data. This brittleness stems, in part, from learning statistical associations rather than causal mechanisms. Causal graph neural networks address this triple crisis of distribution shift, discrimination, and inscrutability by combining graph-based representations of biomedical data with causal inference principles to learn invariant mechanisms rather than spurious correlations. This Review examines methodological foundations spanning structural causal models, disentangled causal representation learning, and techniques for interventional prediction and counterfactual reasoning on graphs. We analyse applications demonstrating clinical value across psychiatric diagnosis through brain network analysis, cancer subtyping via multi-omics causal integration, continuous physiological monitoring with mechanistic interpretation, and drug recommendation correcting prescription bias. These advances establish foundations for patient-specific Causal Digital Twins, enabling in silico clinical experimentation, with integration of large language models for hypothesis generation and causal graph neural networks for mechanistic validation. Substantial barriers remain, including computational requirements precluding real-time deployment, validation challenges demanding multi-modal evidence triangulation beyond cross-validation, and risks of causal-washing where methods employ causal terminology without rigorous evidentiary support. We propose tiered frameworks distinguishing causally-inspired architectures from causally-validated discoveries and identify critical research priorities making causal rather than purely associational claims.",
        "authors": "Munib Mesinovic, Max Buhlan, Tingting Zhu",
        "url": "http://arxiv.org/abs/2511.02531v2",
        "pdf_url": "http://arxiv.org/pdf/2511.02531v2",
        "reason_zh": "这篇综述完美契合您对“统计基础与保证”的兴趣，特别是“因果推断”和“模型泛化界限”的数学基础。它从AI系统在实际部署中遇到的“脆性”问题（如分布漂移、歧视模式）出发，强调了从统计关联转向“因果机制”学习的重要性，这直接对应了您提升AI系统鲁棒性和效果的目标。文章详细探讨了结构因果模型、解耦因果表示学习等“数学基础”，并将其应用于“因果图神经网络”这一“现代方法论”。同时，它还提及了LLM与因果图神经网络的结合，满足了您对“LLM在数据科学中的应用”的兴趣。作为一篇综述，它承诺深入浅出地解释方法论基础，并讨论了实际应用价值、存在的障碍和未来的研究重点，确保了“逻辑脉络清晰”、“文笔流畅”以及“可落地的知识”。它明确排除了“空中楼阁”式的理论，追求严谨性和实践性。",
        "reason_en": "This review perfectly aligns with your interest in 'Statistical Foundations and Guarantees,' especially the mathematical foundations of 'Causal Inference' and 'Model Generalization Bounds.' It addresses the 'brittleness' issues (e.g., distribution shift, discriminatory patterns) faced by AI systems in deployment, emphasizing the shift from statistical associations to learning 'causal mechanisms,' directly addressing your goal of enhancing AI system robustness and effectiveness. The paper elaborates on 'mathematical foundations' such as structural causal models and disentangled causal representation learning, applying them to 'Causal Graph Neural Networks' as a 'Modern Methodology.' It also mentions the integration of LLMs with causal graph neural networks, satisfying your interest in 'LLM applications in data science.' As a review, it promises in-depth explanations of methodological foundations, discusses practical value, existing barriers, and future research directions, ensuring 'clear logical flow,' 'fluent writing,' and 'actionable knowledge.' It explicitly moves away from 'ivory tower' theories, pursuing rigor and practicality."
    },
    {
        "id": "http://arxiv.org/abs/2511.01196v1",
        "title": "An Interdisciplinary and Cross-Task Review on Missing Data Imputation",
        "summary": "Missing data is a fundamental challenge in data science, significantly hindering analysis and decision-making across a wide range of disciplines, including healthcare, bioinformatics, social science, e-commerce, and industrial monitoring. Despite decades of research and numerous imputation methods, the literature remains fragmented across fields, creating a critical need for a comprehensive synthesis that connects statistical foundations with modern machine learning advances. This work systematically reviews core concepts-including missingness mechanisms, single versus multiple imputation, and different imputation goals-and examines problem characteristics across various domains. It provides a thorough categorization of imputation methods, spanning classical techniques (e.g., regression, the EM algorithm) to modern approaches like low-rank and high-rank matrix completion, deep learning models (autoencoders, GANs, diffusion models, graph neural networks), and large language models. Special attention is given to methods for complex data types, such as tensors, time series, streaming data, graph-structured data, categorical data, and multimodal data. Beyond methodology, we investigate the crucial integration of imputation with downstream tasks like classification, clustering, and anomaly detection, examining both sequential pipelines and joint optimization frameworks. The review also assesses theoretical guarantees, benchmarking resources, and evaluation metrics. Finally, we identify critical challenges and future directions, emphasizing model selection and hyperparameter optimization, the growing importance of privacy-preserving imputation via federated learning, and the pursuit of generalizable models that can adapt across domains and data types, thereby outlining a roadmap for future research.",
        "authors": "Jicong Fan",
        "url": "http://arxiv.org/abs/2511.01196v1",
        "pdf_url": "http://arxiv.org/pdf/2511.01196v1",
        "reason_zh": "这篇跨学科综述是您不可多得的资源，它系统性地连接了“统计基础”与“现代机器学习进展”，正中您研究方向的核心。它解决了数据科学中普遍存在的“缺失数据”这一“高维统计”挑战，并评估了各种方法的“理论保证”和“泛化性”。在“现代方法论”方面，它涵盖了从传统统计方法到深度学习模型（如自编码器、GAN、扩散模型、图神经网络）以及“大语言模型”在缺失数据归因中的应用，这与您对“深度学习优化”、“表示学习”及“LLM在数据科学中的应用”的兴趣高度吻合。该综述不仅阐明了不同归因方法的原理，还探讨了与下游任务的集成、私有保护归因（联邦学习），以及追求“可泛化模型”等前沿实践，体现了对“高效AI”和“鲁棒性”的关注。其“综合性”和对“理论保证”的评估，以及对“关键挑战和未来方向”的展望，使其成为一篇逻辑性强、可落地且能提供深入浅出知识的优质文献。",
        "reason_en": "This interdisciplinary review is an invaluable resource that systematically connects 'statistical foundations' with 'modern machine learning advances,' directly aligning with the core of your research. It addresses the pervasive challenge of 'missing data' in data science, a key issue in 'high-dimensional statistics,' and evaluates the 'theoretical guarantees' and 'generalizability' of various methods. Regarding 'Modern Methodologies,' it covers applications ranging from classical statistical techniques to deep learning models (e.g., autoencoders, GANs, diffusion models, graph neural networks) and 'Large Language Models' in missing data imputation, which perfectly matches your interests in 'deep learning optimization,' 'representation learning,' and 'LLM applications in data science.' This review not only clarifies the principles of different imputation methods but also explores their integration with downstream tasks, privacy-preserving imputation (federated learning), and the pursuit of 'generalizable models,' reflecting a focus on 'efficient AI' and 'robustness.' Its 'comprehensive nature,' assessment of 'theoretical guarantees,' and outline of 'critical challenges and future directions' make it a highly logical, practical, and in-depth tutorial."
    }
]