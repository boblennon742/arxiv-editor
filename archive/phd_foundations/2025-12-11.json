[
    {
        "id": "http://arxiv.org/abs/2512.10937v1",
        "title": "On Decision-Making Agents and Higher-Order Causal Processes",
        "summary": "We establish a precise correspondence between decision-making agents in partially observable Markov decision processes (POMDPs) and one-input process functions, the classical limit of higher-order quantum operations. In this identification an agent's policy and memory update combine into a process function w that interacts with a POMDP environment via the link product. This suggests a dual interpretation: in the physics view, the process function acts as the environment into which local operations (agent interventions) are inserted, whereas in the AI view it encodes the agent and the inserted functions represent environments. We extend this perspective to multi-agent systems by identifying observation-independent decentralized POMDPs as natural domains for multi-input process functions.",
        "authors": "Matt Wilson",
        "url": "http://arxiv.org/abs/2512.10937v1",
        "pdf_url": "https://arxiv.org/pdf/2512.10937v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 3,
            "Clarity": 4
        },
        "reason_zh": "这篇论文建立了部分可观测马尔可夫决策过程（POMDPs）中的决策智能体与高阶因果过程的精确对应关系。它将严谨的因果逻辑和数学理论应用于AI决策系统，特别是通过与量子操作的经典极限联系起来，理论基础极其强大，非常符合您对因果逻辑和数学严谨性的偏好。"
    },
    {
        "id": "http://arxiv.org/abs/2512.10873v1",
        "title": "Physics-informed Polynomial Chaos Expansion with Enhanced Constrained Optimization Solver and D-optimal Sampling",
        "summary": "Physics-informed polynomial chaos expansions (PC$^2$) provide an efficient physically constrained surrogate modeling framework by embedding governing equations and other physical constraints into the standard data-driven polynomial chaos expansions (PCE) and solving via the Karush-Kuhn-Tucker (KKT) conditions. This approach improves the physical interpretability of surrogate models while achieving high computational efficiency and accuracy. However, the performance and efficiency of PC$^2$ can still be degraded with high-dimensional parameter spaces, limited data availability, or unrepresentative training data. To address this problem, this study explores two complementary enhancements to the PC$^2$ framework. First, a numerically efficient constrained optimization solver, straightforward updating of Lagrange multipliers (SULM), is adopted as an alternative to the conventional KKT solver. The SULM method significantly reduces computational cost when solving physically constrained problems with high-dimensionality and derivative boundary conditions that require a large number of virtual points. Second, a D-optimal sampling strategy is utilized to select informative virtual points to improve the stability and achieve the balance of accuracy and efficiency of the PC$^2$. The proposed methods are integrated into the PC$^2$ framework and evaluated through numerical examples of representative physical systems governed by ordinary or partial differential equations. The results demonstrate that the enhanced PC$^2$ has better comprehensive capability than standard PC$^2$, and is well-suited for high-dimensional uncertainty quantification tasks.",
        "authors": "Qitian Lu, Himanshu Sharma, Michael D. Shields, Lukáš Novák",
        "url": "http://arxiv.org/abs/2512.10873v1",
        "pdf_url": "https://arxiv.org/pdf/2512.10873v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该研究提出了增强的物理信息多项式混沌展开（PC^2）框架，通过嵌入控制方程和物理约束，并结合KKT条件、高效优化求解器和D-最优采样策略，为高维不确定性量化提供了高效且物理可解释的数学框架。其对优化收敛性和统计保证的关注与您的研究方向高度契合。"
    },
    {
        "id": "http://arxiv.org/abs/2512.10849v1",
        "title": "Bayesian Symbolic Regression via Posterior Sampling",
        "summary": "Symbolic regression is a powerful tool for discovering governing equations directly from data, but its sensitivity to noise hinders its broader application. This paper introduces a Sequential Monte Carlo (SMC) framework for Bayesian symbolic regression that approximates the posterior distribution over symbolic expressions, enhancing robustness and enabling uncertainty quantification for symbolic regression in the presence of noise. Differing from traditional genetic programming approaches, the SMC-based algorithm combines probabilistic selection, adaptive tempering, and the use of normalized marginal likelihood to efficiently explore the search space of symbolic expressions, yielding parsimonious expressions with improved generalization. When compared to standard genetic programming baselines, the proposed method better deals with challenging, noisy benchmark datasets. The reduced tendency to overfit and enhanced ability to discover accurate and interpretable equations paves the way for more robust symbolic regression in scientific discovery and engineering design applications.",
        "authors": "Geoffrey F. Bomarito, Patrick E. Leser",
        "url": "http://arxiv.org/abs/2512.10849v1",
        "pdf_url": "https://arxiv.org/pdf/2512.10849v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "这篇论文引入了基于序贯蒙特卡洛（SMC）框架的贝叶斯符号回归，通过后验采样实现不确定性量化，显著增强了在噪声存在下的鲁棒性。其贝叶斯方法和不确定性量化是数理统计的强项，对科学发现和工程设计中的AI应用具有重要意义。"
    },
    {
        "id": "http://arxiv.org/abs/2512.10826v1",
        "title": "On the Convergence Analysis of an Inexact Preconditioned Stochastic Model-Based Algorithm",
        "summary": "This paper focuses on investigating an inexact stochastic model-based optimization algorithm that integrates preconditioning techniques for solving stochastic composite optimization problems. The proposed framework unifies and extends the fixed-metric stochastic model-based algorithm to its preconditioned and inexact variants. Convergence guarantees are established under mild assumptions for both weakly convex and convex settings, without requiring smoothness or global Lipschitz continuity of the objective function. By assuming a local Lipschitz condition, we derive nonasymptotic and asymptotic convergence rates measured by the gradient of the Moreau envelope. Furthermore, convergence rates in terms of the distance to the optimal solution set are obtained under an additional quadratic growth condition on the objective function. Numerical experiment results demonstrate the theoretical findings for the proposed algorithm.",
        "authors": "Chenglong Bao, Yancheng Yuan, Shulan Zhu",
        "url": "http://arxiv.org/abs/2512.10826v1",
        "pdf_url": "https://arxiv.org/pdf/2512.10826v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 3,
            "Clarity": 4
        },
        "reason_zh": "该研究深入探讨了一种不精确预处理随机模型优化算法的收敛性分析，为随机复合优化问题提供了弱凸和凸设置下的非渐近和渐近收敛保证，并利用Moreau包络的梯度进行度量。其对优化收敛性的严格数学推导是您关注的核心点。"
    },
    {
        "id": "http://arxiv.org/abs/2512.10735v1",
        "title": "LGAN: An Efficient High-Order Graph Neural Network via the Line Graph Aggregation",
        "summary": "Graph Neural Networks (GNNs) have emerged as a dominant paradigm for graph classification. Specifically, most existing GNNs mainly rely on the message passing strategy between neighbor nodes, where the expressivity is limited by the 1-dimensional Weisfeiler-Lehman (1-WL) test. Although a number of k-WL-based GNNs have been proposed to overcome this limitation, their computational cost increases rapidly with k, significantly restricting the practical applicability. Moreover, since the k-WL models mainly operate on node tuples, these k-WL-based GNNs cannot retain fine-grained node- or edge-level semantics required by attribution methods (e.g., Integrated Gradients), leading to the less interpretable problem. To overcome the above shortcomings, in this paper, we propose a novel Line Graph Aggregation Network (LGAN), that constructs a line graph from the induced subgraph centered at each node to perform the higher-order aggregation. We theoretically prove that the LGAN not only possesses the greater expressive power than the 2-WL under injective aggregation assumptions, but also has lower time complexity. Empirical evaluations on benchmarks demonstrate that the LGAN outperforms state-of-the-art k-WL-based GNNs, while offering better interpretability.",
        "authors": "Lin Du, Lu Bai, Jincheng Li, Lixin Cui, Hangyuan Du, Lichi Zhang, Yuting Chen, Zhao Li",
        "url": "http://arxiv.org/abs/2512.10735v1",
        "pdf_url": "https://arxiv.org/pdf/2512.10735v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "这篇论文提出了一种新颖的高阶图神经网络（GNN）LGAN，通过线图聚合实现。它理论上证明了LGAN比2-WL测试具有更强的表达能力和更低的计算复杂度，为GNN的理论基础和数学严谨性做出了重要贡献，直接应用于现代AI系统中的图数据处理。"
    },
    {
        "id": "http://arxiv.org/abs/2512.10720v1",
        "title": "Beyond the Black Box: Identifiable Interpretation and Control in Generative Models via Causal Minimality",
        "summary": "Deep generative models, while revolutionizing fields like image and text generation, largely operate as opaque black boxes, hindering human understanding, control, and alignment. While methods like sparse autoencoders (SAEs) show remarkable empirical success, they often lack theoretical guarantees, risking subjective insights. Our primary objective is to establish a principled foundation for interpretable generative models. We demonstrate that the principle of causal minimality -- favoring the simplest causal explanation -- can endow the latent representations of diffusion vision and autoregressive language models with clear causal interpretation and robust, component-wise identifiable control. We introduce a novel theoretical framework for hierarchical selection models, where higher-level concepts emerge from the constrained composition of lower-level variables, better capturing the complex dependencies in data generation. Under theoretically derived minimality conditions (manifesting as sparsity or compression constraints), we show that learned representations can be equivalent to the true latent variables of the data-generating process. Empirically, applying these constraints to leading generative models allows us to extract their innate hierarchical concept graphs, offering fresh insights into their internal knowledge organization. Furthermore, these causally grounded concepts serve as levers for fine-grained model steering, paving the way for transparent, reliable systems.",
        "authors": "Lingjing Kong, Shaoan Xie, Guangyi Chen, Yuewen Sun, Xiangchen Song, Eric P. Xing, Kun Zhang",
        "url": "http://arxiv.org/abs/2512.10720v1",
        "pdf_url": "https://arxiv.org/pdf/2512.10720v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该论文提出了基于“因果极小性”原则的生成模型可解释性框架，理论上证明了在特定条件下，学习到的潜在变量可等同于数据生成过程的真实潜在变量。它为AI可控性和理解生成模型内部机制提供了强大的因果逻辑和数学基础，是理论与AI结合的典范。"
    },
    {
        "id": "http://arxiv.org/abs/2512.10688v1",
        "title": "Rethinking Popularity Bias in Collaborative Filtering via Analytical Vector Decomposition",
        "summary": "Popularity bias fundamentally undermines the personalization capabilities of collaborative filtering (CF) models, causing them to disproportionately recommend popular items while neglecting users' genuine preferences for niche content. While existing approaches treat this as an external confounding factor, we reveal that popularity bias is an intrinsic geometric artifact of Bayesian Pairwise Ranking (BPR) optimization in CF models. Through rigorous mathematical analysis, we prove that BPR systematically organizes item embeddings along a dominant \"popularity direction\" where embedding magnitudes directly correlate with interaction frequency. This geometric distortion forces user embeddings to simultaneously handle two conflicting tasks-expressing genuine preference and calibrating against global popularity-trapping them in suboptimal configurations that favor popular items regardless of individual tastes. We propose Directional Decomposition and Correction (DDC), a universally applicable framework that surgically corrects this embedding geometry through asymmetric directional updates. DDC guides positive interactions along personalized preference directions while steering negative interactions away from the global popularity direction, disentangling preference from popularity at the geometric source. Extensive experiments across multiple BPR-based architectures demonstrate that DDC significantly outperforms state-of-the-art debiasing methods, reducing training loss to less than 5% of heavily-tuned baselines while achieving superior recommendation quality and fairness. Code is available in https://github.com/LingFeng-Liu-AI/DDC.",
        "authors": "Lingfeng Liu, Yixin Song, Dazhong Shen, Bing Yin, Hao Li, Yanyong Zhang, Chao Wang",
        "url": "http://arxiv.org/abs/2512.10688v1",
        "pdf_url": "https://arxiv.org/pdf/2512.10688v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "这篇论文通过严格的数学分析，揭示了协同过滤中流行度偏差的内在几何本质，并提出了基于不对称方向更新的方向分解和校正（DDC）框架。它从理论源头解决了AI推荐系统中的一个关键问题，具有强大的数学推导和理论基础。"
    },
    {
        "id": "http://arxiv.org/abs/2512.10654v1",
        "title": "Strong Global Convergence of the Consensus-Based Optimization Algorithm",
        "summary": "Consensus-based optimization (CBO) is a multi-agent metaheuristic derivative-free optimization algorithm that has proven to be capable of globally minimizing nonconvex nonsmooth functions across a diverse range of applications while being amenable to theoretical analysis. The method leverages an interplay between exploration of the energy landscape of the objective function through a system of interacting particles subject to stochasticity and exploitation of the particles' positions through the computation of a global consensus about the location of the minimizer based on the Laplace principle. In this paper, we prove strong mean square convergence of the practical numerical time-discrete CBO algorithm to the global minimizer for a rich class of objective functions. For CBO with both isotropic and anisotropic diffusion, our convergence result features conditions on the choice of the hyperparameters as well as explicit rates of convergence in the time discretization step size $Δt$ and the number of particles $N$. By interpreting the time-discrete algorithm at the continuous-time level through a system of stochastic differential equations (SDEs), our proof strategy combines traditional finite-time convergence theory for numerical methods applied to SDEs with careful considerations due to the fact that the CBO coefficients do not satisfy a global Lipschitz condition. To accomodate the latter, we adopt a recently proposed generalization of Sznitman's classical argument, which allows to discard an event of small probability, controllable through fine moment estimates for the particle systems.",
        "authors": "Sabrina Bonandin, Konstantin Riedl, Sara Veneruso",
        "url": "http://arxiv.org/abs/2512.10654v1",
        "pdf_url": "https://arxiv.org/pdf/2512.10654v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 3,
            "Clarity": 4
        },
        "reason_zh": "该研究证明了时间离散的共识优化（CBO）算法对非凸非光滑函数全局最小值的强均方收敛性，并提供了明确的收敛速率。其证明策略结合了SDE的有限时间收敛理论和Sznitman的经典论证，处理了非全局Lipschitz条件，理论严谨性极高，对AI优化算法的理解至关重要。"
    },
    {
        "id": "http://arxiv.org/abs/2512.10573v1",
        "title": "Is the Information Bottleneck Robust Enough? Towards Label-Noise Resistant Information Bottleneck Learning",
        "summary": "The Information Bottleneck (IB) principle facilitates effective representation learning by preserving label-relevant information while compressing irrelevant information. However, its strong reliance on accurate labels makes it inherently vulnerable to label noise, prevalent in real-world scenarios, resulting in significant performance degradation and overfitting. To address this issue, we propose LaT-IB, a novel Label-Noise ResistanT Information Bottleneck method which introduces a \"Minimal-Sufficient-Clean\" (MSC) criterion. Instantiated as a mutual information regularizer to retain task-relevant information while discarding noise, MSC addresses standard IB's vulnerability to noisy label supervision. To achieve this, LaT-IB employs a noise-aware latent disentanglement that decomposes the latent representation into components aligned with to the clean label space and the noise space. Theoretically, we first derive mutual information bounds for each component of our objective including prediction, compression, and disentanglement, and moreover prove that optimizing it encourages representations invariant to input noise and separates clean and noisy label information. Furthermore, we design a three-phase training framework: Warmup, Knowledge Injection and Robust Training, to progressively guide the model toward noise-resistant representations. Extensive experiments demonstrate that LaT-IB achieves superior robustness and efficiency under label noise, significantly enhancing robustness and applicability in real-world scenarios with label noise.",
        "authors": "Yi Huang, Qingyun Sun, Yisen Gao, Haonan Yuan, Xingcheng Fu, Jianxin Li",
        "url": "http://arxiv.org/abs/2512.10573v1",
        "pdf_url": "https://arxiv.org/pdf/2512.10573v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "这篇论文提出了抗标签噪声的信息瓶颈方法LaT-IB，理论上推导了互信息界限，并证明了其能鼓励对输入噪声不变的表示并分离干净和噪声标签信息。它将信息瓶颈原理与统计保证相结合，增强了AI系统在真实世界噪声数据下的鲁棒性，理论基础强大。"
    },
    {
        "id": "http://arxiv.org/abs/2512.10570v1",
        "title": "Flexible Deep Neural Networks for Partially Linear Survival Data",
        "summary": "We propose a flexible deep neural network (DNN) framework for modeling survival data within a partially linear regression structure. The approach preserves interpretability through a parametric linear component for covariates of primary interest, while a nonparametric DNN component captures complex time-covariate interactions among nuisance variables. We refer to the method as FLEXI-Haz, a flexible hazard model with a partially linear structure. In contrast to existing DNN approaches for partially linear Cox models, FLEXI-Haz does not rely on the proportional hazards assumption. We establish theoretical guarantees: the neural network component attains minimax-optimal convergence rates based on composite Holder classes, and the linear estimator is root-n consistent, asymptotically normal, and semiparametrically efficient. Extensive simulations and real-data analyses demonstrate that FLEXI-Haz provides accurate estimation of the linear effect, offering a principled and interpretable alternative to modern methods based on proportional hazards. Code for implementing FLEXI-Haz, as well as scripts for reproducing data analyses and simulations, is available at: https://github.com/AsafBanana/FLEXI-Haz",
        "authors": "Asaf Ben Arie, Malka Gorfine",
        "url": "http://arxiv.org/abs/2512.10570v1",
        "pdf_url": "https://arxiv.org/pdf/2512.10570v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该研究提出了用于部分线性生存数据的FLEXI-Haz深度神经网络框架，理论上保证了神经网络组件达到极小极大最优收敛率，线性估计器具有根-n一致性、渐近正态性和半参数效率。它将现代AI模型与经典统计学理论严谨结合，提供了强大的统计保证。"
    },
    {
        "id": "http://arxiv.org/abs/2512.10457v1",
        "title": "Hybrid Physics-ML Model for Forward Osmosis Flux with Complete Uncertainty Quantification",
        "summary": "Forward Osmosis (FO) is a promising low-energy membrane separation technology, but challenges in accurately modelling its water flux (Jw) persist due to complex internal mass transfer phenomena. Traditional mechanistic models struggle with empirical parameter variability, while purely data-driven models lack physical consistency and rigorous uncertainty quantification (UQ). This study introduces a novel Robust Hybrid Physics-ML framework employing Gaussian Process Regression (GPR) for highly accurate, uncertainty-aware Jw prediction. The core innovation lies in training the GPR on the residual error between the detailed, non-linear FO physical model prediction (Jw_physical) and the experimental water flux (Jw_actual). Crucially, we implement a full UQ methodology by decomposing the total predictive variance (sigma2_total) into model uncertainty (epistemic, from GPR's posterior variance) and input uncertainty (aleatoric, analytically propagated via the Delta method for multi-variate correlated inputs). Leveraging the inherent strength of GPR in low-data regimes, the model, trained on a meagre 120 data points, achieved a state-of-the-art Mean Absolute Percentage Error (MAPE) of 0.26% and an R2 of 0.999 on the independent test data, validating a truly robust and reliable surrogate model for advanced FO process optimization and digital twin development.",
        "authors": "Shiv Ratn, Shivang Rampriyan, Bahni Ray",
        "url": "http://arxiv.org/abs/2512.10457v1",
        "pdf_url": "https://arxiv.org/pdf/2512.10457v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "这篇论文提出了鲁棒的混合物理-ML模型，通过高斯过程回归（GPR）和Delta方法实现完整的、可分解的不确定性量化（包括认知不确定性和偶然不确定性）。它将物理模型与统计学习严谨结合，并提供全面的统计保证，对科学AI和数字孪生应用至关重要。"
    },
    {
        "id": "http://arxiv.org/abs/2512.10308v1",
        "title": "An Interpretable AI Tool for SAVR vs TAVR in Low to Intermediate Risk Patients with Severe Aortic Stenosis",
        "summary": "Background. Treatment selection for low to intermediate risk patients with severe aortic stenosis between surgical (SAVR) and transcatheter (TAVR) aortic valve replacement remains variable in clinical practice, driven by patient heterogeneity and institutional preferences. While existing models predict postprocedural risk, there is a lack of interpretable, individualized treatment recommendations that directly optimize long-term outcomes.   Methods. We introduce an interpretable prescriptive framework that integrates prognostic matching, counterfactual outcome modeling, and an Optimal Policy Tree (OPT) to recommend the treatment minimizing expected 5-year mortality. Using data from Hartford Hospital and St. Vincent's Hospital, we emulate randomization via prognostic matching and sample weighting and estimate counterfactual mortality under both SAVR and TAVR. The policy model, trained on these counterfactual predictions, partitions patients into clinically coherent subgroups and prescribes the treatment associated with lower estimated risk.   Findings. If the OPT prescriptions are applied, counterfactual evaluation showed an estimated reduction in 5-year mortality of 20.3\\% in Hartford and 13.8\\% in St. Vincent's relative to real-life prescriptions, showing promising generalizability to unseen data from a different institution. The learned decision boundaries aligned with real-world outcomes and clinical observations.   Interpretation. Our interpretable prescriptive framework is, to the best of our knowledge, the first to provide transparent, data-driven recommendations for TAVR versus SAVR that improve estimated long-term outcomes both in an internal and external cohort, while remaining clinically grounded and contributing toward a more systematic and evidence-based approach to precision medicine in structural heart disease.",
        "authors": "Vasiliki Stoumpou, Maciej Tysarowski, Talhat Azemi, Jawad Haider, Howard L. Haronian, Robert C. Hagberg, Dimitris Bertsimas",
        "url": "http://arxiv.org/abs/2512.10308v1",
        "pdf_url": "https://arxiv.org/pdf/2512.10308v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 5,
            "Clarity": 4
        },
        "reason_zh": "该研究提出了一个可解释的AI处方框架，整合了预后匹配、反事实结果建模和最优策略树，为临床决策提供了基于因果逻辑和统计保证的严谨方法。它直接解决了AI在医疗决策中的可解释性和因果推断问题，具有极高的理论价值和实践影响力。"
    },
    {
        "id": "http://arxiv.org/abs/2512.10305v1",
        "title": "InfoCom: Kilobyte-Scale Communication-Efficient Collaborative Perception with Information Bottleneck",
        "summary": "Precise environmental perception is critical for the reliability of autonomous driving systems. While collaborative perception mitigates the limitations of single-agent perception through information sharing, it encounters a fundamental communication-performance trade-off. Existing communication-efficient approaches typically assume MB-level data transmission per collaboration, which may fail due to practical network constraints. To address these issues, we propose InfoCom, an information-aware framework establishing the pioneering theoretical foundation for communication-efficient collaborative perception via extended Information Bottleneck principles. Departing from mainstream feature manipulation, InfoCom introduces a novel information purification paradigm that theoretically optimizes the extraction of minimal sufficient task-critical information under Information Bottleneck constraints. Its core innovations include: i) An Information-Aware Encoding condensing features into minimal messages while preserving perception-relevant information; ii) A Sparse Mask Generation identifying spatial cues with negligible communication cost; and iii) A Multi-Scale Decoding that progressively recovers perceptual information through mask-guided mechanisms rather than simple feature reconstruction. Comprehensive experiments across multiple datasets demonstrate that InfoCom achieves near-lossless perception while reducing communication overhead from megabyte to kilobyte-scale, representing 440-fold and 90-fold reductions per agent compared to Where2comm and ERMVP, respectively.",
        "authors": "Quanmin Wei, Penglin Dai, Wei Li, Bingyi Liu, Xiao Wu",
        "url": "http://arxiv.org/abs/2512.10305v1",
        "pdf_url": "https://arxiv.org/pdf/2512.10305v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "这篇论文基于扩展信息瓶颈原理，为通信高效的协作感知奠定了开创性的理论基础，提出了信息净化范式。它在信息论层面为现代AI系统（如自动驾驶中的协作感知）的通信效率提供了严谨的数学和信息论基础。"
    },
    {
        "id": "http://arxiv.org/abs/2512.10282v1",
        "title": "Neuronal Attention Circuit (NAC) for Representation Learning",
        "summary": "Attention improves representation learning over RNNs, but its discrete nature limits continuous-time (CT) modeling. We introduce Neuronal Attention Circuit (NAC), a novel, biologically plausible CT-Attention mechanism that reformulates attention logits computation as the solution to a linear first-order ODE with nonlinear interlinked gates derived from repurposing \\textit{C. elegans} Neuronal Circuit Policies (NCPs) wiring mechanism. NAC replaces dense projections with sparse sensory gates for key-query projections and a sparse backbone network with two heads for computing \\textit{content-target} and \\textit{learnable time-constant} gates, enabling efficient adaptive dynamics. NAC supports three attention logit computation modes: (i) explicit Euler integration, (ii) exact closed-form solution, and (iii) steady-state approximation. To improve memory intensity, we implemented a sparse Top-\\emph{K} pairwise concatenation scheme that selectively curates key-query interactions. We provide rigorous theoretical guarantees, including state stability, bounded approximation errors, and universal approximation. Empirically, we implemented NAC in diverse domains, including irregular time-series classification, lane-keeping for autonomous vehicles, and industrial prognostics. We observed that NAC matches or outperforms competing baselines in accuracy and occupies an intermediate position in runtime and memory efficiency compared with several CT baselines.",
        "authors": "Waleed Razzaq, Izis Kankaraway, Yun-Bo Zhao",
        "url": "http://arxiv.org/abs/2512.10282v1",
        "pdf_url": "https://arxiv.org/pdf/2512.10282v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该研究引入了基于ODE的连续时间注意力机制NAC，并提供了严格的理论保证，包括状态稳定性、有界近似误差和通用逼近能力。它将严谨的数学逻辑（微分方程）应用于现代AI的核心组件（注意力机制），具有深厚的理论价值。"
    },
    {
        "id": "http://arxiv.org/abs/2512.10258v1",
        "title": "R^2-HGP: A Double-Regularized Gaussian Process for Heterogeneous Transfer Learning",
        "summary": "Multi-output Gaussian process (MGP) models have attracted significant attention for their flexibility and uncertainty-quantification capabilities, and have been widely adopted in multi-source transfer learning scenarios due to their ability to capture inter-task correlations. However, they still face several challenges in transfer learning. First, the input spaces of the source and target domains are often heterogeneous, which makes direct knowledge transfer difficult. Second, potential prior knowledge and physical information are typically ignored during heterogeneous transfer, hampering the utilization of domain-specific insights and leading to unstable mappings. Third, inappropriate information sharing among target and sources can easily lead to negative transfer. Traditional models fail to address these issues in a unified way. To overcome these limitations, this paper proposes a Double-Regularized Heterogeneous Gaussian Process framework (R^2-HGP). Specifically, a trainable prior probability mapping model is first proposed to align the heterogeneous input domains. The resulting aligned inputs are treated as latent variables, upon which a multi-source transfer GP model is constructed and the entire structure is integrated into a novel conditional variational autoencoder (CVAE) based framework. Physical insights is further incorporated as a regularization term to ensure that the alignment results adhere to known physical knowledge. Next, within the multi-source transfer GP model, a sparsity penalty is imposed on the transfer coefficients, enabling the model to adaptively select the most informative source outputs and suppress negative transfer. Extensive simulations and real-world engineering case studies validate the effectiveness of our R^2-HGP, demonstrating consistent superiority over state-of-the-art benchmarks across diverse evaluation metrics.",
        "authors": "Duo Wang, Xinming Wang, Chao Wang, Xiaowei Yue, Jianguo Wu",
        "url": "http://arxiv.org/abs/2512.10258v1",
        "pdf_url": "https://arxiv.org/pdf/2512.10258v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "这篇论文提出了双正则化异构高斯过程（R^2-HGP）框架，结合了高斯过程、条件变分自编码器（CVAE）和物理知识正则化，以解决异构迁移学习中的挑战。它具有强大的统计建模和理论基础，为AI系统中的迁移学习提供了严谨的解决方案。"
    }
]