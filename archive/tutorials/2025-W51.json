[
    {
        "id": "http://arxiv.org/abs/2512.15678v1",
        "title": "Hybrid Set-Seeking Systems: Model-Free Feedback Optimization via Hybrid Inclusions",
        "summary": "This article aims to provide an accessible, tutorial-style introduction to hybrid extremum-seeking systems, which are model-free, feedback-optimization controllers that incorporate hybrid dynamics, meaning both continuous-time and discrete-time behaviors. Such systems arise when advanced control and optimization tools are needed to overcome the limitations of smooth feedback methods and to satisfy demanding transient and steady-state requirements in high-performance applications. They also appear when controllers must operate on plants that inherently exhibit hybrid behaviors, as is common in cyber-physical and autonomous systems that rely on digital sensing, computation, and actuation. To study hybrid extremum-seeking dynamics through control-theoretic methods, we first review the key concepts that support the development of perturbation theory for hybrid inclusions, forming the basis for averaging and singular perturbation analyses. We then show how these ideas apply to the design and evaluation of hybrid extremum-seeking algorithms for static and dynamic plants. Several examples are presented, including set-valued and switching algorithms under different switching regimes such as arbitrarily fast switching, dwell-time and average dwell-time constraints, and average activation time conditions. We also discuss state-based switching extremum seeking for obstacle-avoidance problems and gradient-Newton switching schemes. Additional topics include momentum-based and reset-type extremum seeking, intermittent updates, slowly varying parameters, hybrid filters, and safety-aware schemes that incorporate constraints. Across all these settings, we illustrate how perturbation-based methods traditionally used for extremum-seeking control naturally extend to hybrid systems when mild regularity assumptions are satisfied, and solutions are modeled on hybrid time domains.",
        "authors": "Jorge I. Poveda, Andrew R. Teel",
        "url": "http://arxiv.org/abs/2512.15678v1",
        "pdf_url": "https://arxiv.org/pdf/2512.15678v1",
        "type": "基础核心",
        "scores": {
            "Novelty": 3,
            "Rigor": 5,
            "Clarity": 5,
            "Utility": 5
        },
        "core_value_zh": "针对混合系统下无模型反馈优化的严谨教程，深入探讨摄动理论与混合包含。",
        "reason_zh": "这篇教程以“可访问的教程风格”介绍了混合极值寻优系统，并回顾了支持混合包含摄动理论的关键概念。它强调了数学严谨性，涵盖了高级控制与优化工具，非常适合博士生补全在凸优化、控制理论等领域的数学基础，且文笔流畅，逻辑清晰，是硬核资料的典范。"
    },
    {
        "id": "http://arxiv.org/abs/2512.15455v1",
        "title": "Randomized orthogonalization and Krylov subspace methods: principles and algorithms",
        "summary": "We present an overview of randomized orthogonalization techniques that construct a well-conditioned basis whose sketch is orthonormal. Randomized orthogonalization has recently emerged as a powerful paradigm for reducing the computational and communication cost of state-of-the-art orthogonalization procedures on parallel architectures, while preserving, and in some cases improving, their numerical stability. This approach can be employed within Krylov subspace methods to mitigate the cost of orthogonalization, yielding a randomized Arnoldi relation. We review the main variants of the randomized Gram--Schmidt and Householder QR algorithms, and discuss their application to Krylov methods for the solution of large-scale linear algebra problems, such as linear systems of equations, eigenvalue problems, the evaluation of matrix functions, and matrix equations.",
        "authors": "Jean-Guillaume de Damas, Laura Grigori, Igor Simunec, Edouard Timsit",
        "url": "http://arxiv.org/abs/2512.15455v1",
        "pdf_url": "https://arxiv.org/pdf/2512.15455v1",
        "type": "基础核心",
        "scores": {
            "Novelty": 3,
            "Rigor": 5,
            "Clarity": 5,
            "Utility": 5
        },
        "core_value_zh": "随机正交化与Krylov子空间方法的原理与算法综述，为矩阵分析提供硬核基础。",
        "reason_zh": "这篇文章全面概述了随机正交化技术和Krylov子空间方法，强调了其原理和算法，是矩阵分析和数值线性代数领域的经典且严谨的基础资料。对于需要深入理解大型线性代数问题求解方法的博士生来说，具有极高的实用价值和数学严谨性。"
    },
    {
        "id": "http://arxiv.org/abs/2512.12506v1",
        "title": "Explainable Artificial Intelligence for Economic Time Series: A Comprehensive Review and a Systematic Taxonomy of Methods and Concepts",
        "summary": "Explainable Artificial Intelligence (XAI) is increasingly required in computational economics, where machine-learning forecasters can outperform classical econometric models but remain difficult to audit and use for policy. This survey reviews and organizes the growing literature on XAI for economic time series, where autocorrelation, non-stationarity, seasonality, mixed frequencies, and regime shifts can make standard explanation techniques unreliable or economically implausible. We propose a taxonomy that classifies methods by (i) explanation mechanism: propagation-based approaches (e.g., Integrated Gradients, Layer-wise Relevance Propagation), perturbation and game-theoretic attribution (e.g., permutation importance, LIME, SHAP), and function-based global tools (e.g., Accumulated Local Effects); (ii) time-series compatibility, including preservation of temporal dependence, stability over time, and respect for data-generating constraints. We synthesize time-series-specific adaptations such as vector- and window-based formulations (e.g., Vector SHAP, WindowSHAP) that reduce lag fragmentation and computational cost while improving interpretability. We also connect explainability to causal inference and policy analysis through interventional attributions (Causal Shapley values) and constrained counterfactual reasoning. Finally, we discuss intrinsically interpretable architectures (notably attention-based transformers) and provide guidance for decision-grade applications such as nowcasting, stress testing, and regime monitoring, emphasizing attribution uncertainty and explanation dynamics as indicators of structural change.",
        "authors": "Agustín García-García, Pablo Hidalgo, Julio E. Sandubete",
        "url": "http://arxiv.org/abs/2512.12506v1",
        "pdf_url": "https://arxiv.org/pdf/2512.12506v1",
        "type": "基础核心",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Clarity": 5,
            "Utility": 5
        },
        "core_value_zh": "XAI在经济时间序列中的综合性回顾与系统分类，深度连接因果推断与政策分析。",
        "reason_zh": "这篇综述为经济时间序列中的可解释AI提供了一个全面的回顾和系统分类，特别强调了其与因果推断的连接，如因果Shapley值和反事实推理。对于数理统计博士生来说，它提供了理解XAI和因果推断在复杂数据背景下（如时间序列）的严谨概念框架和方法论基础，而非简单的科普。"
    },
    {
        "id": "http://arxiv.org/abs/2512.16301v1",
        "title": "Adaptation of Agentic AI",
        "summary": "Cutting-edge agentic AI systems are built on foundation models that can be adapted to plan, reason, and interact with external tools to perform increasingly complex and specialized tasks. As these systems grow in capability and scope, adaptation becomes a central mechanism for improving performance, reliability, and generalization. In this paper, we unify the rapidly expanding research landscape into a systematic framework that spans both agent adaptations and tool adaptations. We further decompose these into tool-execution-signaled and agent-output-signaled forms of agent adaptation, as well as agent-agnostic and agent-supervised forms of tool adaptation. We demonstrate that this framework helps clarify the design space of adaptation strategies in agentic AI, makes their trade-offs explicit, and provides practical guidance for selecting or switching among strategies during system design. We then review the representative approaches in each category, analyze their strengths and limitations, and highlight key open challenges and future opportunities. Overall, this paper aims to offer a conceptual foundation and practical roadmap for researchers and practitioners seeking to build more capable, efficient, and reliable agentic AI systems.",
        "authors": "Pengcheng Jiang, Jiacheng Lin, Zhiyi Shi, Zifeng Wang, Luxi He, Yichen Wu, Ming Zhong, Peiyang Song, Qizheng Zhang, Heng Wang, Xueqiang Xu, Hanwen Xu, Pengrui Han, Dylan Zhang, Jiashuo Sun, Chaoqi Yang, Kun Qian, Tian Wang, Changran Hu, Manling Li, Quanzheng Li, Hao Peng, Sheng Wang, Jingbo Shang, Chao Zhang, Jiaxuan You, Liyuan Liu, Pan Lu, Yu Zhang, Heng Ji, Yejin Choi, Dawn Song, Jimeng Sun, Jiawei Han",
        "url": "http://arxiv.org/abs/2512.16301v1",
        "pdf_url": "https://arxiv.org/pdf/2512.16301v1",
        "type": "基础核心",
        "scores": {
            "Novelty": 4,
            "Rigor": 4,
            "Clarity": 5,
            "Utility": 4
        },
        "core_value_zh": "统一Agentic AI适应性研究的系统框架与分类，指引其设计与发展。",
        "reason_zh": "尽管Agentic AI是前沿领域，但此文旨在将快速发展的研究统一为系统框架，并分解其适应性策略。这为数理统计博士生提供了理解Agentic AI核心机制的严谨概念基础，有助于构建对LLM理论机制的深层认知，而非仅仅停留在应用层面，是补全新兴领域知识拼图的硬核资料。"
    },
    {
        "id": "http://arxiv.org/abs/2512.13564v1",
        "title": "Memory in the Age of AI Agents",
        "summary": "Memory has emerged, and will continue to remain, a core capability of foundation model-based agents. As research on agent memory rapidly expands and attracts unprecedented attention, the field has also become increasingly fragmented. Existing works that fall under the umbrella of agent memory often differ substantially in their motivations, implementations, and evaluation protocols, while the proliferation of loosely defined memory terminologies has further obscured conceptual clarity. Traditional taxonomies such as long/short-term memory have proven insufficient to capture the diversity of contemporary agent memory systems. This work aims to provide an up-to-date landscape of current agent memory research. We begin by clearly delineating the scope of agent memory and distinguishing it from related concepts such as LLM memory, retrieval augmented generation (RAG), and context engineering. We then examine agent memory through the unified lenses of forms, functions, and dynamics. From the perspective of forms, we identify three dominant realizations of agent memory, namely token-level, parametric, and latent memory. From the perspective of functions, we propose a finer-grained taxonomy that distinguishes factual, experiential, and working memory. From the perspective of dynamics, we analyze how memory is formed, evolved, and retrieved over time. To support practical development, we compile a comprehensive summary of memory benchmarks and open-source frameworks. Beyond consolidation, we articulate a forward-looking perspective on emerging research frontiers, including memory automation, reinforcement learning integration, multimodal memory, multi-agent memory, and trustworthiness issues. We hope this survey serves not only as a reference for existing work, but also as a conceptual foundation for rethinking memory as a first-class primitive in the design of future agentic intelligence.",
        "authors": "Yuyang Hu, Shichun Liu, Yanwei Yue, Guibin Zhang, Boyang Liu, Fangyi Zhu, Jiahang Lin, Honglin Guo, Shihan Dou, Zhiheng Xi, Senjie Jin, Jiejun Tan, Yanbin Yin, Jiongnan Liu, Zeyu Zhang, Zhongxiang Sun, Yutao Zhu, Hao Sun, Boci Peng, Zhenrong Cheng, Xuanbo Fan, Jiaxin Guo, Xinlei Yu, Zhenhong Zhou, Zewen Hu, Jiahao Huo, Junhao Wang, Yuwei Niu, Yu Wang, Zhenfei Yin, Xiaobin Hu, Yue Liao, Qiankun Li, Kun Wang, Wangchunshu Zhou, Yixin Liu, Dawei Cheng, Qi Zhang, Tao Gui, Shirui Pan, Yan Zhang, Philip Torr, Zhicheng Dou, Ji-Rong Wen, Xuanjing Huang, Yu-Gang Jiang, Shuicheng Yan",
        "url": "http://arxiv.org/abs/2512.13564v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13564v1",
        "type": "基础核心",
        "scores": {
            "Novelty": 4,
            "Rigor": 4,
            "Clarity": 5,
            "Utility": 4
        },
        "core_value_zh": "代理AI记忆研究的全面综述与精细分类，厘清概念并指明未来方向。",
        "reason_zh": "这篇综述对AI代理的记忆研究进行了全面梳理，提出了更细致的分类法，并从形式、功能和动态三个维度进行分析。对于关注LLM理论机制的博士生而言，它提供了理解复杂AI系统核心组件——记忆——的严谨概念基础，有助于弥补该新兴领域知识的碎片化，是深入研究的重要起点。"
    },
    {
        "id": "http://arxiv.org/abs/2512.16917v1",
        "title": "Generative Adversarial Reasoner: Enhancing LLM Reasoning with Adversarial Reinforcement Learning",
        "summary": "Large language models (LLMs) with explicit reasoning capabilities excel at mathematical reasoning yet still commit process errors, such as incorrect calculations, brittle logic, and superficially plausible but invalid steps. In this paper, we introduce Generative Adversarial Reasoner, an on-policy joint training framework designed to enhance reasoning by co-evolving an LLM reasoner and an LLM-based discriminator through adversarial reinforcement learning. A compute-efficient review schedule partitions each reasoning chain into logically complete slices of comparable length, and the discriminator evaluates each slice's soundness with concise, structured justifications. Learning couples complementary signals: the LLM reasoner is rewarded for logically consistent steps that yield correct answers, while the discriminator earns rewards for correctly detecting errors or distinguishing traces in the reasoning process. This produces dense, well-calibrated, on-policy step-level rewards that supplement sparse exact-match signals, improving credit assignment, increasing sample efficiency, and enhancing overall reasoning quality of LLMs. Across various mathematical benchmarks, the method delivers consistent gains over strong baselines with standard RL post-training. Specifically, on AIME24, we improve DeepSeek-R1-Distill-Qwen-7B from 54.0 to 61.3 (+7.3) and DeepSeek-R1-Distill-Llama-8B from 43.7 to 53.7 (+10.0). The modular discriminator also enables flexible reward shaping for objectives such as teacher distillation, preference alignment, and mathematical proof-based reasoning.",
        "authors": "Qihao Liu, Luoxin Ye, Wufei Ma, Yu-Cheng Chou, Alan Yuille",
        "url": "http://arxiv.org/abs/2512.16917v1",
        "pdf_url": "https://arxiv.org/pdf/2512.16917v1",
        "type": "前沿深度",
        "scores": {
            "Novelty": 5,
            "Rigor": 4,
            "Clarity": 4,
            "Utility": 5
        },
        "core_value_zh": "通过对抗强化学习提升LLM推理能力的新型联合训练框架。",
        "reason_zh": "这篇论文提出了一种新颖的生成对抗推理器，通过对抗强化学习共同训练LLM推理器和判别器，以增强LLM的数学推理能力。它直接切入LLM理论机制和Offline RL领域，提供了高创新性的方法和显著的性能提升，对未来LLM推理研究具有重要的指导意义。"
    },
    {
        "id": "http://arxiv.org/abs/2512.16489v1",
        "title": "Advantages and limitations in the use of transfer learning for individual treatment effects in causal machine learning",
        "summary": "Generalizing causal knowledge across diverse environments is challenging, especially when estimates from large-scale datasets must be applied to smaller or systematically different contexts, where external validity is critical. Model-based estimators of individual treatment effects (ITE) from machine learning require large sample sizes, limiting their applicability in domains such as behavioral sciences with smaller datasets. We demonstrate how estimation of ITEs with Treatment Agnostic Representation Networks (TARNet; Shalit et al., 2017) can be improved by leveraging knowledge from source datasets and adapting it to new settings via transfer learning (TL-TARNet; Aloui et al., 2023). In simulations that vary source and sample sizes and consider both randomized and non-randomized intervention target settings, the transfer-learning extension TL-TARNet improves upon standard TARNet, reducing ITE error and attenuating bias when a large unbiased source is available and target samples are small. In an empirical application using the India Human Development Survey (IHDS-II), we estimate the effect of mothers' firewood collection time on children's weekly study time; transfer learning pulls the target mean ITEs toward the source ITE estimate, reducing bias in the estimates obtained without transfer. These results suggest that transfer learning for causal models can improve the estimation of ITE in small samples.",
        "authors": "Seyda Betul Aydin, Holger Brandt",
        "url": "http://arxiv.org/abs/2512.16489v1",
        "pdf_url": "https://arxiv.org/pdf/2512.16489v1",
        "type": "前沿深度",
        "scores": {
            "Novelty": 4,
            "Rigor": 4,
            "Clarity": 4,
            "Utility": 5
        },
        "core_value_zh": "探讨迁移学习在因果机器学习中个体治疗效果估计的优势与局限。",
        "reason_zh": "这篇论文深入探讨了迁移学习在因果机器学习中估计个体治疗效果（ITE）的优势与局限。它通过模拟和实际应用展示了TL-TARNet如何改善小样本下的ITE估计，直接契合了您对因果推断前沿研究的需求，能指引该领域的未来研究方向。"
    },
    {
        "id": "http://arxiv.org/abs/2512.16344v1",
        "title": "AI Needs Physics More Than Physics Needs AI",
        "summary": "Artificial intelligence (AI) is commonly depicted as transformative. Yet, after more than a decade of hype, its measurable impact remains modest outside a few high-profile scientific and commercial successes. The 2024 Nobel Prizes in Chemistry and Physics recognized AI's potential, but broader assessments indicate the impact to date is often more promotional than technical. We argue that while current AI may influence physics, physics has significantly more to offer this generation of AI. Current architectures - large language models, reasoning models, and agentic AI - can depend on trillions of meaningless parameters, suffer from distributional bias, lack uncertainty quantification, provide no mechanistic insights, and fail to capture even elementary scientific laws. We review critiques of these limits, highlight opportunities in quantum AI and analogue computing, and lay down a roadmap for the adoption of 'Big AI': a synthesis of theory-based rigour with the flexibility of machine learning.",
        "authors": "Peter Coveney, Roger Highfield",
        "url": "http://arxiv.org/abs/2512.16344v1",
        "pdf_url": "https://arxiv.org/pdf/2512.16344v1",
        "type": "前沿深度",
        "scores": {
            "Novelty": 5,
            "Rigor": 3,
            "Clarity": 4,
            "Utility": 5
        },
        "core_value_zh": "批判性审视当前AI局限，倡导结合物理学理论严谨性发展“大AI”的未来路线图。",
        "reason_zh": "这篇文章以宏大的视角审视了AI与物理学的关系，批判了当前LLM等AI架构的局限性，并提出了结合理论严谨性的“大AI”发展路线图。其视野开阔，对LLM理论机制的深层问题和量子AI的未来方向提供了深刻洞察，非常适合寻求未来研究方向的博士生。"
    },
    {
        "id": "http://arxiv.org/abs/2512.15286v1",
        "title": "Quantum Machine Learning for Cybersecurity: A Taxonomy and Future Directions",
        "summary": "The increasing number of cyber threats and rapidly evolving tactics, as well as the high volume of data in recent years, have caused classical machine learning, rules, and signature-based defence strategies to fail, rendering them unable to keep up. An alternative, Quantum Machine Learning (QML), has recently emerged, making use of computations based on quantum mechanics. It offers better encoding and processing of high-dimensional structures for certain problems. This survey provides a comprehensive overview of QML techniques relevant to the domain of security, such as Quantum Neural Networks (QNNs), Quantum Support Vector Machines (QSVMs), Variational Quantum Circuits (VQCs), and Quantum Generative Adversarial Networks (QGANs), and discusses the contributions of this paper in relation to existing research in the field and how it improves over them. It also maps these methods across supervised, unsupervised, and generative learning paradigms, and to core cybersecurity tasks, including intrusion and anomaly detection, malware and botnet classification, and encrypted-traffic analytics. It also discusses their application in the domain of cloud computing security, where QML can enhance secure and scalable operations. Many limitations of QML in the domain of cybersecurity have also been discussed, along with the directions for addressing them.",
        "authors": "Siva Sai, Ishika Goyal, Shubham Sharma, Sri Harshita Manuri, Vinay Chamola, Rajkumar Buyya",
        "url": "http://arxiv.org/abs/2512.15286v1",
        "pdf_url": "https://arxiv.org/pdf/2512.15286v1",
        "type": "前沿深度",
        "scores": {
            "Novelty": 4,
            "Rigor": 4,
            "Clarity": 4,
            "Utility": 5
        },
        "core_value_zh": "量子机器学习在网络安全领域的综合分类与未来发展方向。",
        "reason_zh": "这篇综述提供了量子机器学习（QML）在网络安全领域的全面概述，包括QNNs、QSVMs等关键技术，并探讨了其局限性和未来方向。它直接契合了您对量子AI前沿研究的需求，能帮助博士生系统了解该领域的最新进展和潜在研究机会。"
    },
    {
        "id": "http://arxiv.org/abs/2512.13979v1",
        "title": "ReflCtrl: Controlling LLM Reflection via Representation Engineering",
        "summary": "Large language models (LLMs) with Chain-of-Thought (CoT) reasoning have achieved strong performance across diverse tasks, including mathematics, coding, and general reasoning. A distinctive ability of these reasoning models is self-reflection: the ability to review and revise previous reasoning steps. While self-reflection enhances reasoning performance, it also increases inference cost. In this work, we study self-reflection through the lens of representation engineering. We segment the model's reasoning into steps, identify the steps corresponding to reflection, and extract a reflection direction in the latent space that governs this behavior. Using this direction, we propose a stepwise steering method that can control reflection frequency. We call our framework ReflCtrl. Our experiments show that (1) in many cases reflections are redundant, especially in stronger models (in our experiments, we can save up to 33.6 percent of reasoning tokens while preserving performance), and (2) the model's reflection behavior is highly correlated with an internal uncertainty signal, implying self-reflection may be controlled by the model's uncertainty.",
        "authors": "Ge Yan, Chung-En Sun, Tsui-Wei, Weng",
        "url": "http://arxiv.org/abs/2512.13979v1",
        "pdf_url": "https://arxiv.org/pdf/2512.13979v1",
        "type": "前沿深度",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Clarity": 4,
            "Utility": 5
        },
        "core_value_zh": "通过表征工程在潜在空间中控制LLM自反性，揭示其内部推理机制。",
        "reason_zh": "这篇论文从表征工程的角度深入研究了LLM的自反性，通过在潜在空间中识别和控制反射方向，揭示了LLM内部推理机制。其理论深度高，创新性强，直接回应了您对LLM理论机制的关注，为理解和优化LLM行为提供了新的研究路径。"
    }
]