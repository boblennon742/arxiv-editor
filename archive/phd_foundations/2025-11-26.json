[
    {
        "id": "http://arxiv.org/abs/2511.21646v1",
        "title": "Stochastic Optimal Control of Interacting Particle Systems in Hilbert Spaces and Applications",
        "summary": "Optimal control of interacting particles governed by stochastic evolution equations in Hilbert spaces is an open area of research. Such systems naturally arise in formulations where each particle is modeled by stochastic partial differential equations, path-dependent stochastic differential equations (such as stochastic delay differential equations or stochastic Volterra integral equations), or partially observed stochastic systems. The purpose of this manuscript is to build the foundations for a limiting theory as the number of particles tends to infinity. We prove the convergence of the value functions $u_n$ of finite particle systems to a function $\\mathcal{V}$, {which} is the unique {$L$}-viscosity solution of the corresponding mean-field Hamilton-Jacobi-Bellman equation {in the space of probability measures}, and we identify its lift with the value function $U$ of the so-called ``lifted'' limit optimal control problem. Under suitable additional assumptions, we show $C^{1,1}$-regularity of $U$, we prove that $\\mathcal{V}$ projects precisely onto the value functions $u_n$, and that optimal (resp. optimal feedback) controls of the particle system correspond to optimal (resp. optimal feedback) controls of the lifted control problem started at the corresponding initial condition. To the best of our knowledge, these are the first results of this kind for stochastic optimal control problems for interacting particle systems of stochastic evolution equations in Hilbert spaces. We apply the developed theory to problems arising in economics where the particles are modeled by stochastic delay differential equations and stochastic partial differential equations.",
        "authors": "Filippo de Feo, Fausto Gozzi, Andrzej Święch, Lukas Wessels",
        "url": "http://arxiv.org/abs/2511.21646v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21646v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "这篇论文为希尔伯特空间中随机演化方程控制的相互作用粒子系统建立了极限理论，并证明了价值函数的收敛性、HJB方程的粘性解唯一性以及最优控制的对应关系。其数学推导极其严谨，为复杂AI系统（如多智能体控制）提供了坚实的理论基础。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21603v1",
        "title": "Uniform inference for kernel instrumental variable regression",
        "summary": "Instrumental variable regression is a foundational tool for causal analysis across the social and biomedical sciences. Recent advances use kernel methods to estimate nonparametric causal relationships, with general data types, while retaining a simple closed-form expression. Empirical researchers ultimately need reliable inference on causal estimates; however, uniform confidence sets for the method remain unavailable. To fill this gap, we develop valid and sharp confidence sets for kernel instrumental variable regression, allowing general nonlinearities and data types. Computationally, our bootstrap procedure requires only a single run of the kernel instrumental variable regression estimator. Theoretically, it relies on the same key assumptions. Overall, we provide a practical procedure for inference that substantially increases the value of kernel methods for causal analysis.",
        "authors": "Marvin Lob, Rahul Singh, Suhas Vijaykumar",
        "url": "http://arxiv.org/abs/2511.21603v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21603v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该研究解决了核工具变量回归中缺乏一致置信集的问题，开发了有效且尖锐的统一置信集。其基于引导程序的推断方法依赖于关键理论假设，提供了严谨的统计推断，对因果分析的核方法具有重要价值。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21595v1",
        "title": "On the Degrees of Freedom of some Lasso procedures",
        "summary": "The effective degrees of freedom of penalized regression models quantify the actual amount of information used to generate predictions, playing a pivotal role in model evaluation and selection. Although a closed-form estimator is available for the Lasso penalty, adaptive extensions of widely used penalized approaches, including the Adaptive Lasso and Adaptive Group Lasso, have remained without analogous theoretical characterization. This paper presents the first unbiased estimator of the effective degrees of freedom for these methods, along with their main theoretical properties, for both orthogonal and non-orthogonal designs, derived within Stein's unbiased risk estimation framework. The resulting expressions feature inflation terms influenced by the regularization parameter, coefficient signs, and least-squares estimates. These advances enable more accurate model selection criteria and unbiased prediction error estimates, illustrated through synthetic and real data. These contributions offer a rigorous theoretical foundation for understanding model complexity in adaptive regression, bridging a critical gap between theory and practice.",
        "authors": "Mauro Bernardi, Antonio Canale, Marco Stefanucci",
        "url": "http://arxiv.org/abs/2511.21595v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21595v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "论文首次为自适应Lasso和自适应组Lasso等惩罚回归方法提供了有效自由度的无偏估计器，并在Stein无偏风险估计框架内推导了其理论性质。这填补了理论与实践之间的关键空白，为理解模型复杂性提供了严格的理论基础。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21534v1",
        "title": "A Sensitivity Analysis Framework for Causal Inference Under Interference",
        "summary": "In many applications of causal inference, the treatment received by one unit may influence the outcome of another, a phenomenon referred to as interference. Although there are several frameworks for conducting causal inference in the presence of interference, practitioners often lack the data necessary to adjust for its effects. In this paper, we propose a weighting-based sensitivity analysis framework that can be used to assess the systematic bias arising from ignoring interference. Unlike most of the existing literature, we allow for the presence of unmeasured confounding, and show that the combination of interference and unmeasured confounding is a notable challenge to causal inference. We also study a third factor contributing to systematic bias: lack of transportability. Our framework enables practitioners to assess the impact of these three issues simultaneously through several easily interpretable sensitivity parameters that can reflect a wide range of intuitions about the data.",
        "authors": "Matvey Ortyashov, AmirEmad Ghassami",
        "url": "http://arxiv.org/abs/2511.21534v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21534v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "这篇论文提出了一个基于权重的敏感性分析框架，用于评估干预、未测量混淆和不可迁移性对因果推断的系统偏差。其方法允许同时评估这三个因素的影响，并提供了可解释的敏感性参数，具有强大的因果逻辑和统计方法论。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21526v1",
        "title": "Phase Transition for Stochastic Block Model with more than $\\sqrt{n}$ Communities (II)",
        "summary": "A fundamental theoretical question in network analysis is to determine under which conditions community recovery is possible in polynomial time in the Stochastic Block Model (SBM). When the number $K$ of communities remains smaller than $\\sqrt{n}$ --where $n$ denotes the number of nodes--, non-trivial community recovery is possible in polynomial time above, and only above, the Kesten--Stigum (KS) threshold, originally postulated using arguments from statistical physics.   When $K \\geq \\sqrt{n}$, Chin, Mossel, Sohn, and Wein recently proved that, in the \\emph{sparse regime}, community recovery in polynomial time is achievable below the KS threshold by counting non-backtracking paths. This finding led them to postulate a new threshold for the many-communities regime $K \\geq \\sqrt{n}$. Subsequently, Carpentier, Giraud, and Verzelen established the failure of low-degree polynomials below this new threshold across all density regimes, and demonstrated successful recovery above the threshold in certain moderately sparse settings. While these results provide strong evidence that, in the many community setting, the computational barrier lies at the threshold proposed in~Chin et al., the question of achieving recovery above this threshold still remains open in most density regimes.   The present work is a follow-up to~Carpentier et al., in which we prove Conjecture~1.4 stated therein by: \\\\ 1- Constructing a family of motifs satisfying specific structural properties; and\\\\ 2- Proving that community recovery is possible above the proposed threshold by counting such motifs.\\\\ Our results complete the picture of the computational barrier for community recovery in the SBM with $K \\geq \\sqrt{n}$ communities. They also indicate that, in moderately sparse regimes, the optimal algorithms appear to be fundamentally different from spectral methods.",
        "authors": "Alexandra Carpentier, Christophe Giraud, Nicolas Verzelen",
        "url": "http://arxiv.org/abs/2511.21526v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21526v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "作为对Stochastic Block Model (SBM) 相变研究的后续工作，该论文证明了当社区数量 $K \\geq \\sqrt{n}$ 时，社区恢复的计算障碍。通过构建特定结构特性的motif并证明通过计数这些motif可以实现恢复，为网络分析提供了深刻的理论洞察和严格的数学证明。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21399v1",
        "title": "Training Introspective Behavior: Fine-Tuning Induces Reliable Internal State Detection in a 7B Model",
        "summary": "Lindsey (2025) investigates introspective awareness in language models through four experiments, finding that models can sometimes detect and identify injected activation patterns -- but unreliably (~20% success in the best model). We focus on the first of these experiments -- self-report of injected \"thoughts\" -- and ask whether this capability can be directly trained rather than waiting for emergence. Through fine-tuning on transient single-token injections, we transform a 7B parameter model from near-complete failure (0.4% accuracy, 6.7% false positive rate) to reliable detection (85% accuracy on held-out concepts at α=40, 0% false positives). Our model detects fleeting \"thoughts\" injected at a single token position, retains that information, and reports the semantic content across subsequent generation steps. On this task, our trained model satisfies three of Lindsey's criteria: accuracy (correct identification), grounding (0/60 false positives), and internality (detection precedes verbalization). Generalization to unseen concept vectors (7.5pp gap) demonstrates the model learns a transferable skill rather than memorizing specific vectors, though this does not establish metacognitive representation in Lindsey's sense. These results address an open question raised by Lindsey: whether \"training for introspection would help eliminate cross-model differences.\" We show that at least one component of introspective behavior can be directly induced, offering a pathway to built-in AI transparency.",
        "authors": "Joshua Fonseca Rivera",
        "url": "http://arxiv.org/abs/2511.21399v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21399v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "论文提出了浅层通用多项式网络 (SUPNs)，并证明了它们以与最佳多项式近似相同的速率收敛，并推导了准最优SUPN参数的显式公式。这为函数逼近提供了严谨的理论基础，并展示了其在参数效率和近似误差方面的优势。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21280v1",
        "title": "Improvement of Collision Avoidance in Cut-In Maneuvers Using Time-to-Collision Metrics",
        "summary": "This paper proposes a new strategy for collision avoidance system leveraging Time-to-Collision (TTC) metrics for handling cut-in scenarios, which are particularly challenging for autonomous vehicles (AVs). By integrating a deep learning with TTC calculations, the system predicts potential collisions and determines appropriate evasive actions compared to traditional TTC -based approaches.",
        "authors": "Jamal Raiyn",
        "url": "http://arxiv.org/abs/2511.21280v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21280v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该研究提出了一个局部经验贝叶斯框架，用于解决A/B测试中跨实验和时间异质性问题。通过理论分析，证明了该策略在降低方差和避免偏差方面的优势，为数据驱动的决策制定提供了可靠的统计保证。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21245v1",
        "title": "FIELDS: Face reconstruction with accurate Inference of Expression using Learning with Direct Supervision",
        "summary": "Facial expressions convey the bulk of emotional information in human communication, yet existing 3D face reconstruction methods often miss subtle affective details due to reliance on 2D supervision and lack of 3D ground truth. We propose FIELDS (Face reconstruction with accurate Inference of Expression using Learning with Direct Supervision) to address these limitations by extending self-supervised 2D image consistency cues with direct 3D expression parameter supervision and an auxiliary emotion recognition branch. Our encoder is guided by authentic expression parameters from spontaneous 4D facial scans, while an intensity-aware emotion loss encourages the 3D expression parameters to capture genuine emotion content without exaggeration. This dual-supervision strategy bridges the 2D/3D domain gap and mitigates expression-intensity bias, yielding high-fidelity 3D reconstructions that preserve subtle emotional cues. From a single image, FIELDS produces emotion-rich face models with highly realistic expressions, significantly improving in-the-wild facial expression recognition performance without sacrificing naturalness.",
        "authors": "Chen Ling, Henglin Shi, Hedvig Kjellström",
        "url": "http://arxiv.org/abs/2511.21245v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21245v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "这篇论文推导了数据驱动的Koopman MPC在存在近似误差时渐近稳定的条件，并证明了递归可行性和渐近稳定性。其理论证明严谨，将数据驱动模型与控制理论的稳定性保证相结合，对现代AI系统中的鲁棒控制至关重要。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21219v1",
        "title": "Conditional Generative Modeling of Stochastic LTI Systems: A Behavioral Approach",
        "summary": "This paper presents a data-driven model for Linear Time-Invariant (LTI) stochastic systems by sampling from the conditional probability distribution of future outputs given past input-outputs and future inputs. It operates in a fully behavioral manner, relying solely on the current trajectory and pre-collected input-output data, without requiring explicit identification of system parameters. We refer to this model as a behavioral Conditional Generative Model (CGM). We prove the convergence of the distribution of samples generated by the CGM as the size of the trajectory library increases, with an explicit characterization of the convergence rate. Furthermore, we demonstrate that the gap between the asymptotic distribution of the proposed CGM and the true posterior distribution obtained by Kalman filter, which leverages the knowledge of all system parameters and all historical data, decreases exponentially with respect to the length of past samples. Finally, we integrate this generative model into predictive controllers for stochastic LTI systems. Numerical results verify the derived bounds and demonstrate the effectiveness of the controller equipped with the proposed behavioral CGM.",
        "authors": "Jiayun Li, Yilin Mo",
        "url": "http://arxiv.org/abs/2511.21219v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21219v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "论文提出了一个行为化的条件生成模型 (CGM)，用于随机LTI系统，并证明了样本分布的收敛性及其与卡尔曼滤波器后验分布之间差距的指数级减小。这是随机系统建模的开创性工作，具有非常强的数学严谨性和理论证明。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21122v1",
        "title": "Which Layer Causes Distribution Deviation? Entropy-Guided Adaptive Pruning for Diffusion and Flow Models",
        "summary": "Large-scale vision generative models, including diffusion and flow models, have demonstrated remarkable performance in visual generation tasks. However, transferring these pre-trained models to downstream tasks often results in significant parameter redundancy. In this paper, we propose EntPruner, an entropy-guided automatic progressive pruning framework for diffusion and flow models. First, we introduce entropy-guided pruning, a block-level importance assessment strategy specifically designed for generative models. Unlike discriminative models, generative models require preserving the diversity and condition-fidelity of the output distribution. As the importance of each module can vary significantly across downstream tasks, EntPruner prioritizes pruning of less important blocks using data-dependent Conditional Entropy Deviation (CED) as a guiding metric. CED quantifies how much the distribution diverges from the learned conditional data distribution after removing a block. Second, we propose a zero-shot adaptive pruning framework to automatically determine when and how much to prune during training. This dynamic strategy avoids the pitfalls of one-shot pruning, mitigating mode collapse, and preserving model performance. Extensive experiments on DiT and SiT models demonstrate the effectiveness of EntPruner, achieving up to 2.22$\\times$ inference speedup while maintaining competitive generation quality on ImageNet and three downstream datasets.",
        "authors": "Changlin Li, Jiawei Zhang, Zeyi Shi, Zongxin Yang, Zhihui Li, Xiaojun Chang",
        "url": "http://arxiv.org/abs/2511.21122v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21122v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该研究将因果图学习问题表述为带有组l0-正则化的凸混合整数规划，并提供了图恢复的一致性保证、优化与统计误差界限的联系以及早期停止准则。其方法在优化和统计上都具有严格保证，是因果图发现领域的重大进展。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21114v1",
        "title": "Deformation-aware Temporal Generation for Early Prediction of Alzheimers Disease",
        "summary": "Alzheimer's disease (AD), a degenerative brain condition, can benefit from early prediction to slow its progression. As the disease progresses, patients typically undergo brain atrophy. Current prediction methods for Alzheimers disease largely involve analyzing morphological changes in brain images through manual feature extraction. This paper proposes a novel method, the Deformation-Aware Temporal Generative Network (DATGN), to automate the learning of morphological changes in brain images about disease progression for early prediction. Given the common occurrence of missing data in the temporal sequences of MRI images, DATGN initially interpolates incomplete sequences. Subsequently, a bidirectional temporal deformation-aware module guides the network in generating future MRI images that adhere to the disease's progression, facilitating early prediction of Alzheimer's disease. DATGN was tested for the generation of temporal sequences of future MRI images using the ADNI dataset, and the experimental results are competitive in terms of PSNR and MMSE image quality metrics. Furthermore, when DATGN-generated synthetic data was integrated into the SVM vs. CNN vs. 3DCNN-based classification methods, significant improvements were achieved from 6. 21\\% to 16\\% in AD vs. NC classification accuracy and from 7. 34\\% to 21. 25\\% in AD vs. MCI vs. NC classification accuracy. The qualitative visualization results indicate that DATGN produces MRI images consistent with the brain atrophy trend in Alzheimer's disease, enabling early disease prediction.",
        "authors": "Xin Honga, Jie Lin, Minghui Wang",
        "url": "http://arxiv.org/abs/2511.21114v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21114v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "这篇论文深入探讨了带有DNN的偏线性模型中的非凸惩罚LAD估计，并建立了估计量的一致性、收敛速度和渐近正态性。其理论分析引入了无限维变分分析和非光滑分析，展现了极高的数学和统计严谨性。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21097v1",
        "title": "CLRecogEye : Curriculum Learning towards exploiting convolution features for Dynamic Iris Recognition",
        "summary": "Iris authentication algorithms have achieved impressive recognition performance, making them highly promising for real-world applications such as border control, citizen identification, and both criminal investigations and commercial systems. However, their robustness is still challenged by variations in rotation, scale, specular reflections, and defocus blur. In addition, most existing approaches rely on straightforward point-to-point comparisons, typically using cosine or L2 distance, without effectively leveraging the spatio-spatial-temporal structure of iris patterns. To address these limitations, we propose a novel and generalized matching pipeline that learns rich spatio-spatial-temporal representations of iris features. Our approach first splits each iris image along one dimension, generating a sequence of sub-images that serve as input to a 3D-CNN, enabling the network to capture both spatial and spatio-spatial-temporal cues. To further enhance the modeling of spatio-spatial-temporal feature dynamics, we train the model in curriculum manner. This design allows the network to embed temporal dependencies directly into the feature space, improving discriminability in the deep metric domain. The framework is trained end-to-end with triplet and ArcFace loss in a curriculum manner, enforcing highly discriminative embeddings despite challenges like rotation, scale, reflections, and blur. This design yields a robust and generalizable solution for iris authentication.Github code: https://github.com/GeetanjaliGTZ/CLRecogEye",
        "authors": "Geetanjali Sharma, Gaurav Jaswal, Aditya Nigam, Raghavendra Ramachandra",
        "url": "http://arxiv.org/abs/2511.21097v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21097v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "论文对扩散语言模型 (DLMs) 的并行解码进行了信息论分析，证明了高置信度token的固有低效性，并提出了“比特到轮次”原理。其理论分析和实验验证为理解和优化现代LLM的生成效率提供了深刻的数学洞察。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21064v1",
        "title": "OVOD-Agent: A Markov-Bandit Framework for Proactive Visual Reasoning and Self-Evolving Detection",
        "summary": "Open-Vocabulary Object Detection (OVOD) aims to enable detectors to generalize across categories by leveraging semantic information. Although existing methods are pretrained on large vision-language datasets, their inference is still limited to fixed category names, creating a gap between multimodal training and unimodal inference. Previous work has shown that improving textual representation can significantly enhance OVOD performance, indicating that the textual space is still underexplored. To this end, we propose OVOD-Agent, which transforms passive category matching into proactive visual reasoning and self-evolving detection. Inspired by the Chain-of-Thought (CoT) paradigm, OVOD-Agent extends the textual optimization process into an interpretable Visual-CoT with explicit actions. OVOD's lightweight nature makes LLM-based management unsuitable; instead, we model visual context transitions as a Weakly Markovian Decision Process (w-MDP) over eight state spaces, which naturally represents the agent's state, memory, and interaction dynamics. A Bandit module generates exploration signals under limited supervision, helping the agent focus on uncertain regions and adapt its detection policy. We further integrate Markov transition matrices with Bandit trajectories for self-supervised Reward Model (RM) optimization, forming a closed loop from Bandit exploration to RM learning. Experiments on COCO and LVIS show that OVOD-Agent provides consistent improvements across OVOD backbones, particularly on rare categories, confirming the effectiveness of the proposed framework.",
        "authors": "Chujie Wang, Jianyu Lu, Zhiyuan Luo, Xi Chen, Chu He",
        "url": "http://arxiv.org/abs/2511.21064v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21064v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该研究提出了一个用于高维噪声数据集中流形相似性和对齐性的统计推断框架。通过分析样本协方差的谱并利用随机矩阵理论，开发了尺度不变距离、一致估计量和统计检验，并建立了渐近性质，具有极强的统计和数学严谨性。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21056v1",
        "title": "A Unified Understanding of Offline Data Selection and Online Self-refining Generation for Post-training LLMs",
        "summary": "Offline data selection and online self-refining generation, which enhance the data quality, are crucial steps in adapting large language models (LLMs) to specific downstream tasks. We tackle offline data selection and online self-refining generations through an optimization perspective. Specifically, bilevel data selection is used for offline data selection with respect to the validation dataset, and we treat online self-refining generation as a model adaptation step of selecting the model trained on current responses that best fits the validation data. Our framework offers a unified understanding of offline data selection and self-refining generation by assigning a learned data weight to each question and response, either explicitly or implicitly. For the first time, we theoretically demonstrate the effectiveness of the bilevel data selection framework and demonstrate its performance gains over unfiltered direct mixing baselines. By combining offline data with validation-weighted online generations, our method enhances fine-tuning performance. Experiments on quality enhancement and safety-aware LLM fine-tuning validate its effectiveness.",
        "authors": "Quan Xiao, Tianyi Chen",
        "url": "http://arxiv.org/abs/2511.21056v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21056v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "论文提出了一种新颖的随机算法G-Net，用于构建高精度随机二值神经网络。其核心贡献在于通过测度集中原理提供了理论保证，确保二值模型能保持浮点模型的精度，为二值神经网络的理论基础和实际应用开辟了新方向。"
    },
    {
        "id": "http://arxiv.org/abs/2511.20960v1",
        "title": "Geometric Calibration and Neutral Zones for Uncertainty-Aware Multi-Class Classification",
        "summary": "Modern artificial intelligence systems make critical decisions yet often fail silently when uncertain. We develop a geometric framework for post-hoc calibration of neural network probability outputs, treating probability vectors as points on the $(c-1)$-dimensional probability simplex equipped with the Fisher--Rao metric. Our approach yields Additive Log-Ratio (ALR) calibration maps that reduce exactly to Platt scaling for binary problems (Proposition~1) while extending naturally to multi-class settings -- providing a principled generalization that existing methods lack. Complementing calibration, we define geometric reliability scores based on Fisher--Rao distance and construct neutral zones for principled deferral of uncertain predictions.   Theoretical contributions include: (i) consistency of the calibration estimator at rate $O_p(n^{-1/2})$ via M-estimation theory (Theorem~1), and (ii) tight concentration bounds for reliability scores with explicit sub-Gaussian parameters enabling sample size calculations for validation set design (Theorem~2). We conjecture Neyman--Pearson optimality of our neutral zone construction based on connections to Bhattacharyya coefficients. Empirical validation on Adeno-Associated Virus classification demonstrates that the two-stage framework (calibration followed by reliability-based deferral) captures 72.5\\% of errors while deferring 34.5\\% of samples. Notably, this operational gain is achievable with any well-calibrated probability output; the contribution of geometric calibration lies in its theoretical foundations rather than empirical superiority over simpler alternatives. This work bridges information geometry and statistical learning, offering formal guarantees relevant to applications requiring rigorous validation.",
        "authors": "Soumojit Das, Nairanjana Dasgupta, Prashanta Dutta",
        "url": "http://arxiv.org/abs/2511.20960v1",
        "pdf_url": "https://arxiv.org/pdf/2511.20960v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "这篇论文开发了一个用于多类别分类中不确定性感知几何校准和中立区的框架。其理论贡献包括ALR校准图与Platt缩放的联系、M-估计理论下估计量的一致性、可靠性分数的集中界限以及与信息几何和统计学习的桥接，提供了严谨的统计和数学保证。"
    }
]