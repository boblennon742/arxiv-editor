[
    {
        "id": "http://arxiv.org/abs/2512.20469v1",
        "title": "Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale",
        "summary": "AI agents are emerging as a practical way to run multi-step scientific workflows that interleave reasoning with tool use and verification, pointing to a shift from isolated AI-assisted steps toward \\emph{agentic science at scale}. This shift is increasingly feasible, as scientific tools and models can be invoked through stable interfaces and verified with recorded execution traces, and increasingly necessary, as AI accelerates scientific output and stresses the peer-review and publication pipeline, raising the bar for traceability and credible evaluation.   However, scaling agentic science remains difficult: workflows are hard to observe and reproduce; many tools and laboratory systems are not agent-ready; execution is hard to trace and govern; and prototype AI Scientist systems are often bespoke, limiting reuse and systematic improvement from real workflow signals.   We argue that scaling agentic science requires an infrastructure-and-ecosystem approach, instantiated in Bohrium+SciMaster. Bohrium acts as a managed, traceable hub for AI4S assets -- akin to a HuggingFace of AI for Science -- that turns diverse scientific data, software, compute, and laboratory systems into agent-ready capabilities. SciMaster orchestrates these capabilities into long-horizon scientific workflows, on which scientific agents can be composed and executed. Between infrastructure and orchestration, a \\emph{scientific intelligence substrate} organizes reusable models, knowledge, and components into executable building blocks for workflow reasoning and action, enabling composition, auditability, and improvement through use.   We demonstrate this stack with eleven representative master agents in real workflows, achieving orders-of-magnitude reductions in end-to-end scientific cycle time and generating execution-grounded signals from real workloads at multi-million scale.",
        "authors": "Linfeng Zhang, Siheng Chen, Yuzhu Cai, Jingyi Chai, Junhan Chang, Kun Chen, Zhi X. Chen, Zhaohan Ding, Yuwen Du, Yuanpeng Gao, Yuan Gao, Jing Gao, Zhifeng Gao, Qiangqiang Gu, Yanhui Hong, Yuan Huang, Xi Fang, Xiaohong Ji, Guolin Ke, Zixing Lei, Xinyu Li, Yongge Li, Ruoxue Liao, Hang Lin, Xiaolu Lin, Yuxiang Liu, Xinzijian Liu, Zexi Liu, Jintan Lu, Tingjia Miao, Haohui Que, Weijie Sun, Yanfeng Wang, Bingyang Wu, Tianju Xue, Rui Ye, Jinzhe Zeng, Duo Zhang, Jiahui Zhang, Linfeng Zhang, Tianhan Zhang, Wenchang Zhang, Yuzhi Zhang, Zezhong Zhang, Hang Zheng, Hui Zhou, Tong Zhu, Xinyu Zhu, Qingguo Zhou, Weinan E",
        "url": "http://arxiv.org/abs/2512.20469v1",
        "pdf_url": "https://arxiv.org/pdf/2512.20469v1",
        "type": "前沿深度",
        "scores": {
            "Novelty": 5,
            "Rigor": 3,
            "Clarity": 4,
            "Utility": 5
        },
        "core_value_zh": "提出了一个用于规模化智能体科学的基础设施和生态系统，为AI驱动的科学发现指明了方向。",
        "reason_zh": "这篇论文提出了一个宏大的愿景和基础设施，旨在将AI智能体应用于多步骤科学工作流，实现“规模化智能体科学”。它探讨了AI4S资产的管理、工作流编排以及科学智能基底的构建，对于理解未来AI如何加速科学研究、提高可追溯性和可信评估具有重要的指导意义。对于关注LLM理论机制和未来研究方向的博士生而言，它提供了开阔的视野和潜在的研究方向。"
    },
    {
        "id": "http://arxiv.org/abs/2512.20328v1",
        "title": "Toward Explaining Large Language Models in Software Engineering Tasks",
        "summary": "Recent progress in Large Language Models (LLMs) has substantially advanced the automation of software engineering (SE) tasks, enabling complex activities such as code generation and code summarization. However, the black-box nature of LLMs remains a major barrier to their adoption in high-stakes and safety-critical domains, where explainability and transparency are vital for trust, accountability, and effective human supervision. Despite increasing interest in explainable AI for software engineering, existing methods lack domain-specific explanations aligned with how practitioners reason about SE artifacts. To address this gap, we introduce FeatureSHAP, the first fully automated, model-agnostic explainability framework tailored to software engineering tasks. Based on Shapley values, FeatureSHAP attributes model outputs to high-level input features through systematic input perturbation and task-specific similarity comparisons, while remaining compatible with both open-source and proprietary LLMs. We evaluate FeatureSHAP on two bi-modal SE tasks: code generation and code summarization. The results show that FeatureSHAP assigns less importance to irrelevant input features and produces explanations with higher fidelity than baseline methods. A practitioner survey involving 37 participants shows that FeatureSHAP helps practitioners better interpret model outputs and make more informed decisions. Collectively, FeatureSHAP represents a meaningful step toward practical explainable AI in software engineering. FeatureSHAP is available at https://github.com/deviserlab/FeatureSHAP.",
        "authors": "Antonio Vitale, Khai-Nguyen Nguyen, Denys Poshyvanyk, Rocco Oliveto, Simone Scalabrino, Antonio Mastropaolo",
        "url": "http://arxiv.org/abs/2512.20328v1",
        "pdf_url": "https://arxiv.org/pdf/2512.20328v1",
        "type": "前沿深度",
        "scores": {
            "Novelty": 4,
            "Rigor": 3,
            "Clarity": 4,
            "Utility": 4
        },
        "core_value_zh": "提出了一个针对软件工程任务的、模型无关的LLM可解释性框架，提升了LLM在关键领域的透明度和信任度。",
        "reason_zh": "LLM的黑盒性质是其在高风险领域应用的主要障碍。这篇论文提出了FeatureSHAP框架，旨在为LLM在软件工程任务中的输出提供领域特定的解释。理解LLM的理论机制和行为是博士生关注的重点，而可解释性是实现这一目标的关键途径之一。这篇论文通过实证研究展示了其有效性，具有很强的实用性和研究价值，有助于探索LLM的内在工作机制。"
    },
    {
        "id": "http://arxiv.org/abs/2512.20164v1",
        "title": "AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications",
        "summary": "Large Language Models (LLMs) excel at text comprehension and generation, making them ideal for automated tasks like code review and content moderation. However, our research identifies a vulnerability: LLMs can be manipulated by \"adversarial instructions\" hidden in input data, such as resumes or code, causing them to deviate from their intended task. Notably, while defenses may exist for mature domains such as code review, they are often absent in other common applications such as resume screening and peer review. This paper introduces a benchmark to assess this vulnerability in resume screening, revealing attack success rates exceeding 80% for certain attack types. We evaluate two defense mechanisms: prompt-based defenses achieve 10.1% attack reduction with 12.5% false rejection increase, while our proposed FIDS (Foreign Instruction Detection through Separation) using LoRA adaptation achieves 15.4% attack reduction with 10.4% false rejection increase. The combined approach provides 26.3% attack reduction, demonstrating that training-time defenses outperform inference-time mitigations in both security and utility preservation.",
        "authors": "Honglin Mu, Jinghao Liu, Kaiyang Wan, Rui Xing, Xiuying Chen, Timothy Baldwin, Wanxiang Che",
        "url": "http://arxiv.org/abs/2512.20164v1",
        "pdf_url": "https://arxiv.org/pdf/2512.20164v1",
        "type": "前沿深度",
        "scores": {
            "Novelty": 4,
            "Rigor": 3,
            "Clarity": 4,
            "Utility": 4
        },
        "core_value_zh": "揭示了LLM在专业应用中（如简历筛选）存在的对抗性漏洞，并提出了防御机制，强调了LLM鲁棒性的重要性。",
        "reason_zh": "这篇论文探讨了LLM在核心领域之外的对抗性漏洞，特别是通过“对抗性指令”进行操纵的风险。LLM的鲁棒性和安全性是当前和未来研究的重大前沿。对于关注LLM理论机制的博士生来说，理解其局限性和潜在风险至关重要，这能指引未来在模型安全、对抗性训练等方向的研究，是LLM可靠性研究的重要组成部分。"
    },
    {
        "id": "http://arxiv.org/abs/2512.19937v1",
        "title": "Interpolative Decoding: Exploring the Spectrum of Personality Traits in LLMs",
        "summary": "Recent research has explored using very large language models (LLMs) as proxies for humans in tasks such as simulation, surveys, and studies. While LLMs do not possess a human psychology, they often can emulate human behaviors with sufficiently high fidelity to drive simulations to test human behavioral hypotheses, exhibiting more nuance and range than the rule-based agents often employed in behavioral economics. One key area of interest is the effect of personality on decision making, but the requirement that a prompt must be created for every tested personality profile introduces experimental overhead and degrades replicability. To address this issue, we leverage interpolative decoding, representing each dimension of personality as a pair of opposed prompts and employing an interpolation parameter to simulate behavior along the dimension. We show that interpolative decoding reliably modulates scores along each of the Big Five dimensions. We then show how interpolative decoding causes LLMs to mimic human decision-making behavior in economic games, replicating results from human psychological research. Finally, we present preliminary results of our efforts to ``twin'' individual human players in a collaborative game through systematic search for points in interpolation space that cause the system to replicate actions taken by the human subject.",
        "authors": "Eric Yeh, John Cadigan, Ran Chen, Dick Crouch, Melinda Gervasio, Dayne Freitag",
        "url": "http://arxiv.org/abs/2512.19937v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19937v1",
        "type": "前沿深度",
        "scores": {
            "Novelty": 4,
            "Rigor": 3,
            "Clarity": 4,
            "Utility": 4
        },
        "core_value_zh": "提出了一种通过插值解码来模拟LLM人格特质的方法，为LLM行为控制和模拟提供了新颖途径。",
        "reason_zh": "这篇论文探索了如何通过“插值解码”来模拟LLM的个性特质，并成功复现了人类在经济博弈中的决策行为。这为理解LLM的复杂行为模式、如何对其进行精细控制以及将其应用于社会科学模拟提供了新的研究视角，与“LLM理论机制”的探索方向高度相关，尤其是在LLM行为建模和控制方面。"
    },
    {
        "id": "http://arxiv.org/abs/2512.18567v1",
        "title": "AI Code in the Wild: Measuring Security Risks and Ecosystem Shifts of AI-Generated Code in Modern Software",
        "summary": "Large language models (LLMs) for code generation are becoming integral to modern software development, but their real-world prevalence and security impact remain poorly understood.   We present the first large-scale empirical study of AI-generated code (AIGCode) in the wild. We build a high-precision detection pipeline and a representative benchmark to distinguish AIGCode from human-written code, and apply them to (i) development commits from the top 1,000 GitHub repositories (2022-2025) and (ii) 7,000+ recent CVE-linked code changes. This lets us label commits, files, and functions along a human/AI axis and trace how AIGCode moves through projects and vulnerability life cycles.   Our measurements show three ecological patterns. First, AIGCode is already a substantial fraction of new code, but adoption is structured: AI concentrates in glue code, tests, refactoring, documentation, and other boilerplate, while core logic and security-critical configurations remain mostly human-written. Second, adoption has security consequences: some CWE families are overrepresented in AI-tagged code, and near-identical insecure templates recur across unrelated projects, suggesting \"AI-induced vulnerabilities\" propagated by shared models rather than shared maintainers. Third, in human-AI edit chains, AI introduces high-throughput changes while humans act as security gatekeepers; when review is shallow, AI-introduced defects persist longer, remain exposed on network-accessible surfaces, and spread to more files and repositories.   We will open-source the complete dataset and release analysis artifacts and fine-grained documentation of our methodology and findings.",
        "authors": "Bin Wang, Wenjie Yu, Yilu Zhong, Hao Yu, Keke Lian, Chaohua Lu, Hongfang Zheng, Dong Zhang, Hui Li",
        "url": "http://arxiv.org/abs/2512.18567v1",
        "pdf_url": "https://arxiv.org/pdf/2512.18567v1",
        "type": "前沿深度",
        "scores": {
            "Novelty": 4,
            "Rigor": 3,
            "Clarity": 4,
            "Utility": 4
        },
        "core_value_zh": "首次大规模实证研究了AI生成代码在现实世界中的普及率、安全风险和生态系统影响，揭示了“AI诱导漏洞”的传播机制。",
        "reason_zh": "这篇论文通过大规模实证研究，量化了AI生成代码在现代软件开发中的影响，并识别了由LLM引入的新的安全风险模式。这不仅揭示了LLM在实际应用中的深远影响，也为未来LLM安全、软件工程与AI交叉领域的研究提供了重要的数据和洞察，具有开阔的视野和指引作用，特别是对LLM的社会和技术生态影响的理解。"
    },
    {
        "id": "http://arxiv.org/abs/2512.21127v1",
        "title": "A Real-World Evaluation of LLM Medication Safety Reviews in NHS Primary Care",
        "summary": "Large language models (LLMs) often match or exceed clinician-level performance on medical benchmarks, yet very few are evaluated on real clinical data or examined beyond headline metrics. We present, to our knowledge, the first evaluation of an LLM-based medication safety review system on real NHS primary care data, with detailed characterisation of key failure behaviours across varying levels of clinical complexity. In a retrospective study using a population-scale EHR spanning 2,125,549 adults in NHS Cheshire and Merseyside, we strategically sampled patients to capture a broad range of clinical complexity and medication safety risk, yielding 277 patients after data-quality exclusions. An expert clinician reviewed these patients and graded system-identified issues and proposed interventions. Our primary LLM system showed strong performance in recognising when a clinical issue is present (sensitivity 100\\% [95\\% CI 98.2--100], specificity 83.1\\% [95\\% CI 72.7--90.1]), yet correctly identified all issues and interventions in only 46.9\\% [95\\% CI 41.1--52.8] of patients. Failure analysis reveals that, in this setting, the dominant failure mechanism is contextual reasoning rather than missing medication knowledge, with five primary patterns: overconfidence in uncertainty, applying standard guidelines without adjusting for patient context, misunderstanding how healthcare is delivered in practice, factual errors, and process blindness. These patterns persisted across patient complexity and demographic strata, and across a range of state-of-the-art models and configurations. We provide 45 detailed vignettes that comprehensively cover all identified failure cases. This work highlights shortcomings that must be addressed before LLM-based clinical AI can be safely deployed. It also begs larger-scale, prospective evaluations and deeper study of LLM behaviours in clinical contexts.",
        "authors": "Oliver Normand, Esther Borsi, Mitch Fruin, Lauren E Walker, Jamie Heagerty, Chris C. Holmes, Anthony J Avery, Iain E Buchan, Harry Coppock",
        "url": "http://arxiv.org/abs/2512.21127v1",
        "pdf_url": "https://arxiv.org/pdf/2512.21127v1",
        "type": "前沿深度",
        "scores": {
            "Novelty": 4,
            "Rigor": 3,
            "Clarity": 4,
            "Utility": 4
        },
        "core_value_zh": "对LLM在真实医疗场景中的药物安全审查进行了首次评估，详细分析了其失败模式，为LLM安全部署提供了关键见解。",
        "reason_zh": "这篇论文对LLM在真实临床数据上的表现进行了深入评估，并详细剖析了其失败行为模式，如上下文推理不足、过度自信等。这些发现对于理解LLM的实际局限性、改进其鲁棒性和安全性至关重要，直接指向了未来LLM在关键领域安全部署的研究方向，是连接LLM理论与实际应用之间鸿沟的重要研究。"
    },
    {
        "id": "http://arxiv.org/abs/2512.19614v1",
        "title": "Scenario Reduction for the Two-Stage Stochastic Unit Commitment Problem",
        "summary": "The two-stage stochastic unit commitment problem has become an important tool to support decision-making under uncertainty in power systems. Representing the uncertainty by a large number of scenarios guarantees accurate results but challenges the solution process. One way to overcome this is by using scenario reduction methods, which aim at finding a distribution supported on fewer scenarios, but leading to similar optimal first-stage decisions. In this paper, we recap the classical scenario reduction theory based on the distance of probability distributions and the optimal mass transportation problem. We then review and compare various formulations of the underlying cost function of the latter used in the literature. Using the Forward Selection Algorithm, we show that a specific formulation of the cost function can be proven to select the best possible scenario from a given sample on the first draw with respect to the Relative Approximation Error. We demonstrate this result and compare the quality of the approximation as well as the computational performance of the different cost functions using a modified version of the IEEE RTS 24-Bus System. In many cases, we find that the optimal solution of the two-stage stochastic unit commitment problem with 200 scenarios can be approximated with around 2% scenarios when using this cost function.",
        "authors": "Yannick Werner, Juan Miguel Morales, Salvador Pineda, Line Roald, Sonja Wogrin",
        "url": "http://arxiv.org/abs/2512.19614v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19614v1",
        "type": "基础核心",
        "scores": {
            "Novelty": 2,
            "Rigor": 4,
            "Clarity": 4,
            "Utility": 4
        },
        "core_value_zh": "回顾了基于概率分布距离和最优质量传输问题的经典场景削减理论，并比较了不同成本函数的公式，对随机优化基础有深入理解。",
        "reason_zh": "这篇论文回顾了随机优化中场景削减的经典理论，特别是基于概率分布距离和最优质量传输问题的方法。它具有很强的数学严谨性，深入探讨了成本函数的不同公式，并进行了实证比较。这对于补全博士生在凸优化、高等概率论/随机过程等核心基础课程中关于随机规划和优化算法的知识拼图非常有帮助，是硬核的数学理论资料。"
    },
    {
        "id": "http://arxiv.org/abs/2512.20685v1",
        "title": "Diffusion Models in Simulation-Based Inference: A Tutorial Review",
        "summary": "Diffusion models have recently emerged as powerful learners for simulation-based inference (SBI), enabling fast and accurate estimation of latent parameters from simulated and real data. Their score-based formulation offers a flexible way to learn conditional or joint distributions over parameters and observations, thereby providing a versatile solution to various modeling problems. In this tutorial review, we synthesize recent developments on diffusion models for SBI, covering design choices for training, inference, and evaluation. We highlight opportunities created by various concepts such as guidance, score composition, flow matching, consistency models, and joint modeling. Furthermore, we discuss how efficiency and statistical accuracy are affected by noise schedules, parameterizations, and samplers. Finally, we illustrate these concepts with case studies across parameter dimensionalities, simulation budgets, and model types, and outline open questions for future research.",
        "authors": "Jonas Arruda, Niels Bracher, Ullrich Köthe, Jan Hasenauer, Stefan T. Radev",
        "url": "http://arxiv.org/abs/2512.20685v1",
        "pdf_url": "https://arxiv.org/pdf/2512.20685v1",
        "type": "基础核心",
        "scores": {
            "Novelty": 4,
            "Rigor": 4,
            "Clarity": 5,
            "Utility": 5
        },
        "core_value_zh": "作为一篇教程综述，系统性地介绍了扩散模型在模拟贝叶斯推断（SBI）中的应用，涵盖了其设计选择、训练、推理和评估，是理解现代生成模型基础的硬核资料。",
        "reason_zh": "扩散模型是当前生成模型领域的前沿，而模拟贝叶斯推断（SBI）是统计推断的重要方向。这篇“教程综述”深入讲解了扩散模型在SBI中的原理、设计和实现细节，包括其分数基公式、条件/联合分布学习等。它以严谨的数学视角梳理了这一复杂领域，对于博士生理解高等概率论（随机过程）、贝叶斯推断以及现代统计建模的最新基础具有极高的价值，是补全博士数学拼图的硬核资料。"
    },
    {
        "id": "http://arxiv.org/abs/2512.19410v1",
        "title": "Research Program: Theory of Learning in Dynamical Systems",
        "summary": "Modern learning systems increasingly interact with data that evolve over time and depend on hidden internal state. We ask a basic question: when is such a dynamical system learnable from observations alone? This paper proposes a research program for understanding learnability in dynamical systems through the lens of next-token prediction. We argue that learnability in dynamical systems should be studied as a finite-sample question, and be based on the properties of the underlying dynamics rather than the statistical properties of the resulting sequence. To this end, we give a formulation of learnability for stochastic processes induced by dynamical systems, focusing on guarantees that hold uniformly at every time step after a finite burn-in period. This leads to a notion of dynamic learnability which captures how the structure of a system, such as stability, mixing, observability, and spectral properties, governs the number of observations required before reliable prediction becomes possible. We illustrate the framework in the case of linear dynamical systems, showing that accurate prediction can be achieved after finite observation without system identification, by leveraging improper methods based on spectral filtering. We survey the relationship between learning in dynamical systems and classical PAC, online, and universal prediction theories, and suggest directions for studying nonlinear and controlled systems.",
        "authors": "Elad Hazan, Shai Shalev Shwartz, Nathan Srebro",
        "url": "http://arxiv.org/abs/2512.19410v1",
        "pdf_url": "https://arxiv.org/pdf/2512.19410v1",
        "type": "基础核心",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Clarity": 4,
            "Utility": 5
        },
        "core_value_zh": "提出了一个关于动态系统中学习理论的研究纲领，深入探讨了系统可学习性的数学基础，涉及稳定性、混合性、可观测性、谱性质等。",
        "reason_zh": "这篇论文提出了一个关于动态系统中学习理论的宏大研究纲领，从数学上严谨地探讨了系统可学习性的基本问题，并引入了稳定性、混合性、可观测性、谱性质等核心概念。它将“下一词预测”与动态系统理论结合，对LLM理论机制的深层理解提供了数学基础。其高度的理论深度和数学严谨性，使其成为博士生补全高等概率论/随机过程、矩阵分析（谱性质）等数学拼图的“硬核资料”，具有极高的理论价值。"
    },
    {
        "id": "http://arxiv.org/abs/2512.18826v1",
        "title": "Hyperbolic Graph Embeddings: a Survey and an Evaluation on Anomaly Detection",
        "summary": "This survey reviews hyperbolic graph embedding models, and evaluate them on anomaly detection, highlighting their advantages over Euclidean methods in capturing complex structures. Evaluating models like \\textit{HGCAE}, \\textit{\\(\\mathcal{P}\\)-VAE}, and \\textit{HGCN} demonstrates high performance, with \\textit{\\(\\mathcal{P}\\)-VAE} achieving an F1-score of 94\\% on the \\textit{Elliptic} dataset and \\textit{HGCAE} scoring 80\\% on \\textit{Cora}. In contrast, Euclidean methods like \\textit{DOMINANT} and \\textit{GraphSage} struggle with complex data. The study emphasizes the potential of hyperbolic spaces for improving anomaly detection, and provides an open-source library to foster further research in this field.",
        "authors": "Souhail Abdelmouaiz Sadat, Mohamed Yacine Touahria Miliani, Khadidja Hab El Hames, Hamida Seba, Mohammed Haddad",
        "url": "http://arxiv.org/abs/2512.18826v1",
        "pdf_url": "https://arxiv.org/pdf/2512.18826v1",
        "type": "基础核心",
        "scores": {
            "Novelty": 4,
            "Rigor": 4,
            "Clarity": 4,
            "Utility": 4
        },
        "core_value_zh": "综述了双曲图嵌入模型，并评估其在异常检测中的应用，强调了双曲空间在捕捉复杂结构方面的数学优势。",
        "reason_zh": "这篇综述论文深入探讨了双曲图嵌入这一前沿且具有数学严谨性的领域。它比较了双曲方法与欧几里得方法在处理复杂数据结构时的优势，涉及了非欧几何空间中的数据表示。对于统计学博士生而言，理解高维数据表示的数学基础，特别是如何利用不同几何空间（如双曲空间）的特性，是补全其在高维统计和图理论方面数学拼图的重要资料。虽然是综述，但其对数学概念和模型原理的阐述具有基础性，适合作为进阶学习的硬核资料。"
    }
]