[
    {
        "id": "http://arxiv.org/abs/2511.13411v1",
        "title": "An Operational Kardashev-Style Scale for Autonomous AI - Towards AGI and Superintelligence",
        "summary": "We propose a Kardashev-inspired yet operational Autonomous AI (AAI) Scale that measures the progression from fixed robotic process automation (AAI-0) to full artificial general intelligence (AAI-4) and beyond. Unlike narrative ladders, our scale is multi-axis and testable. We define ten capability axes (Autonomy, Generality, Planning, Memory/Persistence, Tool Economy, Self-Revision, Sociality/Coordination, Embodiment, World-Model Fidelity, Economic Throughput) aggregated by a composite AAI-Index (a weighted geometric mean). We introduce a measurable Self-Improvement Coefficient $κ$ (capability growth per unit of agent-initiated resources) and two closure properties (maintenance and expansion) that convert ``self-improving AI'' into falsifiable criteria. We specify OWA-Bench, an open-world agency benchmark suite that evaluates long-horizon, tool-using, persistent agents. We define level gates for AAI-0\\ldots AAI-4 using thresholds on the axes, $κ$, and closure proofs. Synthetic experiments illustrate how present-day systems map onto the scale and how the delegability frontier (quality vs.\\ autonomy) advances with self-improvement. We also prove a theorem that AAI-3 agent becomes AAI-5 over time with sufficient conditions, formalizing \"baby AGI\" becomes Superintelligence intuition.",
        "authors": "Przemyslaw Chojecki",
        "url": "http://arxiv.org/abs/2511.13411v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13411v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 5,
            "Clarity": 4
        },
        "reason_zh": "这篇论文提出了一个基于卡尔达肖夫标度的可操作性自治AI (AAI) 量表，用于衡量从固定RPA到通用人工智能(AGI)的进展。它定义了十个能力轴、可测量的自我改进系数和封闭性属性，并将“自我改进AI”转化为可证伪的标准。该工作为AGI的衡量和指导提供了高度创新且严谨的理论框架，具有深远的实践影响力。"
    },
    {
        "id": "http://arxiv.org/abs/2511.13391v1",
        "title": "Finding Kissing Numbers with Game-theoretic Reinforcement Learning",
        "summary": "Since Isaac Newton first studied the Kissing Number Problem in 1694, determining the maximal number of non-overlapping spheres around a central sphere has remained a fundamental challenge. This problem represents the local analogue of Hilbert's 18th problem on sphere packing, bridging geometry, number theory, and information theory. Although significant progress has been made through lattices and codes, the irregularities of high-dimensional geometry and exponentially growing combinatorial complexity beyond 8 dimensions, which exceeds the complexity of Go game, limit the scalability of existing methods. Here we model this problem as a two-player matrix completion game and train the game-theoretic reinforcement learning system, PackingStar, to efficiently explore high-dimensional spaces. The matrix entries represent pairwise cosines of sphere center vectors; one player fills entries while another corrects suboptimal ones, jointly maximizing the matrix size, corresponding to the kissing number. This cooperative dynamics substantially improves sample quality, making the extremely large spaces tractable. PackingStar reproduces previous configurations and surpasses all human-known records from dimensions 25 to 31, with the configuration in 25 dimensions geometrically corresponding to the Leech lattice and suggesting possible optimality. It achieves the first breakthrough beyond rational structures from 1971 in 13 dimensions and discovers over 6000 new structures in 14 and other dimensions. These results demonstrate AI's power to explore high-dimensional spaces beyond human intuition and open new pathways for the Kissing Number Problem and broader geometry problems.",
        "authors": "Chengdong Ma, Théo Tao Zhaowei, Pengyu Li, Minghao Liu, Haojun Chen, Zihao Mao, Yuan Cheng, Yuan Qi, Yaodong Yang",
        "url": "http://arxiv.org/abs/2511.13391v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13391v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 5,
            "Clarity": 4
        },
        "reason_zh": "该论文将“亲吻数问题”建模为一个两人矩阵完成博弈，并训练博弈论强化学习系统PackingStar来探索高维空间。PackingStar在25到31维度的亲吻数上超越了所有人类已知记录，并在13维度实现了自1971年以来的首次突破。这项工作在数学问题上展现了AI探索高维空间的能力，具有极高的理论创新性和实践影响力。"
    },
    {
        "id": "http://arxiv.org/abs/2511.13193v1",
        "title": "Cost-Effective Communication: An Auction-based Method for Language Agent Interaction",
        "summary": "Multi-agent systems (MAS) built on large language models (LLMs) often suffer from inefficient \"free-for-all\" communication, leading to exponential token costs and low signal-to-noise ratios that hinder their practical deployment. We challenge the notion that more communication is always beneficial, hypothesizing instead that the core issue is the absence of resource rationality. We argue that \"free\" communication, by ignoring the principle of scarcity, inherently breeds inefficiency and unnecessary expenses. To address this, we introduce the Dynamic Auction-based Language Agent (DALA), a novel framework that treats communication bandwidth as a scarce and tradable resource. Specifically, our DALA regards inter-agent communication as a centralized auction, where agents learn to bid for the opportunity to speak based on the predicted value density of their messages. Thus, our DALA intrinsically encourages agents to produce concise, informative messages while filtering out low-value communication. Extensive and comprehensive experiments demonstrate that our economically-driven DALA achieves new state-of-the-art performance across seven challenging reasoning benchmarks, including 84.32% on MMLU and a 91.21% pass@1 rate on HumanEval. Note that this is accomplished with remarkable efficiency, i.e., our DALA uses only 6.25 million tokens, a fraction of the resources consumed by current state-of-the-art methods on GSM8K. Further analysis reveals that our DALA cultivates the emergent skill of strategic silence, effectively adapting its communication strategies from verbosity to silence in a dynamical manner via resource constraints.",
        "authors": "Yijia Fan, Jusheng Zhang, Kaitong Cai, Jing Yang, Chengpei Tang, Jian Wang, Keze Wang",
        "url": "http://arxiv.org/abs/2511.13193v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13193v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 5,
            "Clarity": 4
        },
        "reason_zh": "这篇论文提出了Dynamic Auction-based Language Agent (DALA) 框架，将多智能体系统中的通信带宽视为稀缺资源进行拍卖。DALA通过经济学原理鼓励智能体生成简洁、信息丰富的消息，有效过滤低价值通信。它在保持高性能的同时显著提升了效率，解决了LLM智能体通信中的关键瓶颈，理论创新性和实际效果都非常突出。"
    },
    {
        "id": "http://arxiv.org/abs/2511.13186v1",
        "title": "DiffFP: Learning Behaviors from Scratch via Diffusion-based Fictitious Play",
        "summary": "Self-play reinforcement learning has demonstrated significant success in learning complex strategic and interactive behaviors in competitive multi-agent games. However, achieving such behaviors in continuous decision spaces remains challenging. Ensuring adaptability and generalization in self-play settings is critical for achieving competitive performance in dynamic multi-agent environments. These challenges often cause methods to converge slowly or fail to converge at all to a Nash equilibrium, making agents vulnerable to strategic exploitation by unseen opponents. To address these challenges, we propose DiffFP, a fictitious play (FP) framework that estimates the best response to unseen opponents while learning a robust and multimodal behavioral policy. Specifically, we approximate the best response using a diffusion policy that leverages generative modeling to learn adaptive and diverse strategies. Through empirical evaluation, we demonstrate that the proposed FP framework converges towards $ε$-Nash equilibria in continuous- space zero-sum games. We validate our method on complex multi-agent environments, including racing and multi-particle zero-sum games. Simulation results show that the learned policies are robust against diverse opponents and outperform baseline reinforcement learning policies. Our approach achieves up to 3$\\times$ faster convergence and 30$\\times$ higher success rates on average against RL-based baselines, demonstrating its robustness to opponent strategies and stability across training iterations",
        "authors": "Akash Karthikeyan, Yash Vardhan Pant",
        "url": "http://arxiv.org/abs/2511.13186v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13186v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 5,
            "Clarity": 4
        },
        "reason_zh": "该论文提出了DiffFP，一个基于扩散模型的虚拟博弈框架，用于在连续决策空间中从头开始学习多智能体博弈行为。它通过扩散策略近似最优响应，学习鲁棒且多模态的行为策略，并理论上证明了其收敛到ε-纳什均衡。这项工作解决了多智能体强化学习中的一个基本瓶颈，具有极高的理论严谨性和实践影响力。"
    },
    {
        "id": "http://arxiv.org/abs/2511.13106v1",
        "title": "Low-Level Dataset Distillation for Medical Image Enhancement",
        "summary": "Medical image enhancement is clinically valuable, but existing methods require large-scale datasets to learn complex pixel-level mappings. However, the substantial training and storage costs associated with these datasets hinder their practical deployment. While dataset distillation (DD) can alleviate these burdens, existing methods mainly target high-level tasks, where multiple samples share the same label. This many-to-one mapping allows distilled data to capture shared semantics and achieve information compression. In contrast, low-level tasks involve a many-to-many mapping that requires pixel-level fidelity, making low-level DD an underdetermined problem, as a small distilled dataset cannot fully constrain the dense pixel-level mappings. To address this, we propose the first low-level DD method for medical image enhancement. We first leverage anatomical similarities across patients to construct the shared anatomical prior based on a representative patient, which serves as the initialization for the distilled data of different patients. This prior is then personalized for each patient using a Structure-Preserving Personalized Generation (SPG) module, which integrates patient-specific anatomical information into the distilled dataset while preserving pixel-level fidelity. For different low-level tasks, the distilled data is used to construct task-specific high- and low-quality training pairs. Patient-specific knowledge is injected into the distilled data by aligning the gradients computed from networks trained on the distilled pairs with those from the corresponding patient's raw data. Notably, downstream users cannot access raw patient data. Instead, only a distilled dataset containing abstract training information is shared, which excludes patient-specific details and thus preserves privacy.",
        "authors": "Fengzhi Xu, Ziyuan Yang, Mengyu Sun, Joey Tianyi Zhou, Yi Zhang",
        "url": "http://arxiv.org/abs/2511.13106v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13106v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 5,
            "Clarity": 4
        },
        "reason_zh": "这篇论文首次提出了针对医学图像增强的低级别数据集蒸馏方法。它利用患者解剖学相似性构建共享解剖学先验，并通过一个结构保持的个性化生成模块进行个性化。该方法在保证像素级保真度的同时，显著降低了训练和存储成本，并保护了患者隐私，解决了医学图像处理中的数据效率和隐私关键瓶颈，具有高度的创新性和严谨性。"
    },
    {
        "id": "http://arxiv.org/abs/2511.13007v1",
        "title": "GEM: Generative Entropy-Guided Preference Modeling for Few-shot Alignment of LLMs",
        "summary": "Alignment of large language models (LLMs) with human preferences typically relies on supervised reward models or external judges that demand abundant annotations. However, in fields that rely on professional knowledge, such as medicine and law, such large-scale preference labels are often unachievable. In this paper, we propose a generative entropy-guided preference modeling approach named GEM for LLMs aligment at low-resource and domain-specific scenarios. Instead of training a discriminative reward model on preference data, we directly train the LLM to internalize a closed-loop optimization architecture that can extract and exploit the multi-dimensional, fine-grained cognitive signals implicit in human preferences. Specifically, our Cognitive Filtering module, based on entropy theory in decision making, first leverages Chain-of-Thought (CoT) prompting to generate diverse candidate reasoning chains (CoTs) from preference data. Subsequently, it introduces a token scoring mechanism to rank and weight the sampled CoTs, boosting the importance of high-confidence answers and strategically high-entropy tokens. Building on these filtered preferences, we fine-tune the LLM using a novel self-evaluated group advantage algorithm, SEGA, which effectively aggregates group-level cognitive signals and transforms the entropy-based scores into implicit rewards for policy optimization. In these ways, GEM empowers the LLM to rely on its own judgments and establishes an entropy-guided closed-loop cognitive optimization framework, enabling highly efficient few-shot alignment of LLMs. Experiments on general benchmarks and domain-specific tasks (such as mathematical reasoning and medical dialogues) demonstrate that our GEM achieves significant improvements with few-shot preference data.",
        "authors": "Yiyang Zhao, Huiyu Bai, Xuejiao Zhao",
        "url": "http://arxiv.org/abs/2511.13007v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13007v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 5,
            "Clarity": 4
        },
        "reason_zh": "该论文提出了GEM（Generative Entropy-Guided Preference Modeling），一种用于LLM少样本对齐的生成式熵引导偏好建模方法。它通过基于熵理论的认知过滤模块和自评估群组优势算法SEGA，使LLM在低资源和特定领域场景中实现高效的少样本对齐。该方法解决了LLM对齐中对大量标注的依赖问题，具有极高的理论创新性和实践影响力。"
    },
    {
        "id": "http://arxiv.org/abs/2511.13937v1",
        "title": "Complex-Weighted Convolutional Networks: Provable Expressiveness via Complex Diffusion",
        "summary": "Graph Neural Networks (GNNs) have achieved remarkable success across diverse applications, yet they remain limited by oversmoothing and poor performance on heterophilic graphs. To address these challenges, we introduce a novel framework that equips graphs with a complex-weighted structure, assigning each edge a complex number to drive a diffusion process that extends random walks into the complex domain. We prove that this diffusion is highly expressive: with appropriately chosen complex weights, any node-classification task can be solved in the steady state of a complex random walk. Building on this insight, we propose the Complex-Weighted Convolutional Network (CWCN), which learns suitable complex-weighted structures directly from data while enriching diffusion with learnable matrices and nonlinear activations. CWCN is simple to implement, requires no additional hyperparameters beyond those of standard GNNs, and achieves competitive performance on benchmark datasets. Our results demonstrate that complex-weighted diffusion provides a principled and general mechanism for enhancing GNN expressiveness, opening new avenues for models that are both theoretically grounded and practically effective.",
        "authors": "Cristina López Amado, Tassilo Schwarz, Yu Tian, Renaud Lambiotte",
        "url": "http://arxiv.org/abs/2511.13937v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13937v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该论文引入了一种新颖的框架，为图配备了复数加权结构，并通过复数扩散过程扩展了随机游走。作者证明了这种扩散具有高度表达性，并在其基础上提出了Complex-Weighted Convolutional Network (CWCN)。该方法通过新颖的数学概念增强GNN的表达能力，解决了过平滑和在异配图上性能不佳的问题，具有强大的理论创新性和严谨性。"
    },
    {
        "id": "http://arxiv.org/abs/2511.14807v1",
        "title": "Fully Differentiable dMRI Streamline Propagation in PyTorch",
        "summary": "Diffusion MRI (dMRI) provides a distinctive means to probe the microstructural architecture of living tissue, facilitating applications such as brain connectivity analysis, modeling across multiple conditions, and the estimation of macrostructural features. Tractography, which emerged in the final years of the 20th century and accelerated in the early 21st century, is a technique for visualizing white matter pathways in the brain using dMRI. Most diffusion tractography methods rely on procedural streamline propagators or global energy minimization methods. Although recent advancements in deep learning have enabled tasks that were previously challenging, existing tractography approaches are often non-differentiable, limiting their integration in end-to-end learning frameworks. While progress has been made in representing streamlines in differentiable frameworks, no existing method offers fully differentiable propagation. In this work, we propose a fully differentiable solution that retains numerical fidelity with a leading streamline algorithm. The key is that our PyTorch-engineered streamline propagator has no components that block gradient flow, making it fully differentiable. We show that our method matches standard propagators while remaining differentiable. By translating streamline propagation into a differentiable PyTorch framework, we enable deeper integration of tractography into deep learning workflows, laying the foundation for a new category of macrostructural reasoning that is not only computationally robust but also scientifically rigorous.",
        "authors": "Jongyeon Yoon, Elyssa M. McMaster, Michael E. Kim, Gaurav Rudravaram, Kurt G. Schilling, Bennett A. Landman, Daniel Moyer",
        "url": "http://arxiv.org/abs/2511.14807v1",
        "pdf_url": "https://arxiv.org/pdf/2511.14807v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "这篇论文提出了首个完全可微分的dMRI流线传播解决方案，保持了数值保真度且没有阻碍梯度流的组件，为深度学习工作流中的宏观结构推理奠定了基础。这项工作解决了传统神经示踪方法不可微分的局限性，实现了端到端学习框架的集成，具有很高的理论和算法创新性。"
    },
    {
        "id": "http://arxiv.org/abs/2511.13371v1",
        "title": "Cognitive Maps in Language Models: A Mechanistic Analysis of Spatial Planning",
        "summary": "How do large language models solve spatial navigation tasks? We investigate this by training GPT-2 models on three spatial learning paradigms in grid environments: passive exploration (Foraging Model- predicting steps in random walks), goal-directed planning (generating optimal shortest paths) on structured Hamiltonian paths (SP-Hamiltonian), and a hybrid model fine-tuned with exploratory data (SP-Random Walk). Using behavioural, representational and mechanistic analyses, we uncover two fundamentally different learned algorithms. The Foraging model develops a robust, map-like representation of space, akin to a 'cognitive map'. Causal interventions reveal that it learns to consolidate spatial information into a self-sufficient coordinate system, evidenced by a sharp phase transition where its reliance on historical direction tokens vanishes by the middle layers of the network. The model also adopts an adaptive, hierarchical reasoning system, switching between a low-level heuristic for short contexts and map-based inference for longer ones. In contrast, the goal-directed models learn a path-dependent algorithm, remaining reliant on explicit directional inputs throughout all layers. The hybrid model, despite demonstrating improved generalisation over its parent, retains the same path-dependent strategy. These findings suggest that the nature of spatial intelligence in transformers may lie on a spectrum, ranging from generalisable world models shaped by exploratory data to heuristics optimised for goal-directed tasks. We provide a mechanistic account of this generalisation-optimisation trade-off and highlight how the choice of training regime influences the strategies that emerge.",
        "authors": "Caroline Baumgartner, Eleanor Spens, Neil Burgess, Petru Manescu",
        "url": "http://arxiv.org/abs/2511.13371v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13371v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该论文对语言模型中的空间规划进行了机制分析，发现了两种根本不同的学习算法（地图式与路径依赖式），并揭示了前馈模型中“认知地图”的出现。这项研究提供了对Transformer中空间智能的深层理解，具有高度的理论创新性，并对如何影响模型的学习策略提供了深刻见解。"
    },
    {
        "id": "http://arxiv.org/abs/2511.13244v1",
        "title": "Seek and You Shall Fold",
        "summary": "Accurate protein structures are essential for understanding biological function, yet incorporating experimental data into protein generative models remains a major challenge. Most predictors of experimental observables are non-differentiable, making them incompatible with gradient-based conditional sampling. This is especially limiting in nuclear magnetic resonance, where rich data such as chemical shifts are hard to directly integrate into generative modeling. We introduce a framework for non-differentiable guidance of protein generative models, coupling a continuous diffusion-based generator with any black-box objective via a tailored genetic algorithm. We demonstrate its effectiveness across three modalities: pairwise distance constraints, nuclear Overhauser effect restraints, and for the first time chemical shifts. These results establish chemical shift guided structure generation as feasible, expose key weaknesses in current predictors, and showcase a general strategy for incorporating diverse experimental signals. Our work points toward automated, data-conditioned protein modeling beyond the limits of differentiability.",
        "authors": "Nadav Bojan Sellam, Meital Bojan, Paul Schanda, Alex Bronstein",
        "url": "http://arxiv.org/abs/2511.13244v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13244v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该论文提出了一种非可微分指导蛋白质生成模型的新框架，通过定制的遗传算法将连续扩散生成器与任何黑盒目标耦合。这项工作首次实现了化学位移引导的结构生成，并为结合多种实验信号的自动化、数据条件蛋白质建模开辟了新途径，具有高度的创新性和严谨性。"
    }
]