[
    {
        "id": "http://arxiv.org/abs/2511.21675v1",
        "title": "On Evolution-Based Models for Experimentation Under Interference",
        "summary": "Causal effect estimation in networked systems is central to data-driven decision making. In such settings, interventions on one unit can spill over to others, and in complex physical or social systems, the interaction pathways driving these interference structures remain largely unobserved. We argue that for identifying population-level causal effects, it is not necessary to recover the exact network structure; instead, it suffices to characterize how those interactions contribute to the evolution of outcomes. Building on this principle, we study an evolution-based approach that investigates how outcomes change across observation rounds in response to interventions, hence compensating for missing network information. Using an exposure-mapping perspective, we give an axiomatic characterization of when the empirical distribution of outcomes follows a low-dimensional recursive equation, and identify minimal structural conditions under which such evolution mappings exist. We frame this as a distributional counterpart to difference-in-differences. Rather than assuming parallel paths for individual units, it exploits parallel evolution patterns across treatment scenarios to estimate counterfactual trajectories. A key insight is that treatment randomization plays a role beyond eliminating latent confounding; it induces an implicit sampling from hidden interference channels, enabling consistent learning about heterogeneous spillover effects. We highlight causal message passing as an instantiation of this method in dense networks while extending to more general interference structures, including influencer networks where a small set of units drives most spillovers. Finally, we discuss the limits of this approach, showing that strong temporal trends or endogenous interference can undermine identification.",
        "authors": "Sadegh Shirani, Mohsen Bayati",
        "url": "http://arxiv.org/abs/2511.21675v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21675v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该论文深入探讨了网络系统中的因果效应估计，提出了基于演化的新方法，并进行了公理化表征和理论分析，非常符合您对因果逻辑和理论严谨性的偏好。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21666v1",
        "title": "Uncertainty Quantification for Visual Object Pose Estimation",
        "summary": "Quantifying the uncertainty of an object's pose estimate is essential for robust control and planning. Although pose estimation is a well-studied robotics problem, attaching statistically rigorous uncertainty is not well understood without strict distributional assumptions. We develop distribution-free pose uncertainty bounds about a given pose estimate in the monocular setting. Our pose uncertainty only requires high probability noise bounds on pixel detections of 2D semantic keypoints on a known object. This noise model induces an implicit, non-convex set of pose uncertainty constraints. Our key contribution is SLUE (S-Lemma Uncertainty Estimation), a convex program to reduce this set to a single ellipsoidal uncertainty bound that is guaranteed to contain the true object pose with high probability. SLUE solves a relaxation of the minimum volume bounding ellipsoid problem inspired by the celebrated S-lemma. It requires no initial guess of the bound's shape or size and is guaranteed to contain the true object pose with high probability. For tighter uncertainty bounds at the same confidence, we extend SLUE to a sum-of-squares relaxation hierarchy which is guaranteed to converge to the minimum volume ellipsoidal uncertainty bound for a given set of keypoint constraints. We show this pose uncertainty bound can easily be projected to independent translation and axis-angle orientation bounds. We evaluate SLUE on two pose estimation datasets and a real-world drone tracking scenario. Compared to prior work, SLUE generates substantially smaller translation bounds and competitive orientation bounds. We release code at https://github.com/MIT-SPARK/PoseUncertaintySets.",
        "authors": "Lorenzo Shaikewitz, Charis Georgiou, Luca Carlone",
        "url": "http://arxiv.org/abs/2511.21666v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21666v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "针对视觉物体姿态估计的“不确定性量化”，提出了基于S-lemma的凸优化方法，并提供了收敛性保证，理论严谨性高，符合您对统计保证和清晰数学推导的要求。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21646v1",
        "title": "Stochastic Optimal Control of Interacting Particle Systems in Hilbert Spaces and Applications",
        "summary": "Optimal control of interacting particles governed by stochastic evolution equations in Hilbert spaces is an open area of research. Such systems naturally arise in formulations where each particle is modeled by stochastic partial differential equations, path-dependent stochastic differential equations (such as stochastic delay differential equations or stochastic Volterra integral equations), or partially observed stochastic systems. The purpose of this manuscript is to build the foundations for a limiting theory as the number of particles tends to infinity. We prove the convergence of the value functions $u_n$ of finite particle systems to a function $\\mathcal{V}$, {which} is the unique {$L$}-viscosity solution of the corresponding mean-field Hamilton-Jacobi-Bellman equation {in the space of probability measures}, and we identify its lift with the value function $U$ of the so-called ``lifted'' limit optimal control problem. Under suitable additional assumptions, we show $C^{1,1}$-regularity of $U$, we prove that $\\mathcal{V}$ projects precisely onto the value functions $u_n$, and that optimal (resp. optimal feedback) controls of the particle system correspond to optimal (resp. optimal feedback) controls of the lifted control problem started at the corresponding initial condition. To the best of our knowledge, these are the first results of this kind for stochastic optimal control problems for interacting particle systems of stochastic evolution equations in Hilbert spaces. We apply the developed theory to problems arising in economics where the particles are modeled by stochastic delay differential equations and stochastic partial differential equations.",
        "authors": "Filippo de Feo, Fausto Gozzi, Andrzej Święch, Lukas Wessels",
        "url": "http://arxiv.org/abs/2511.21646v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21646v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 3,
            "Clarity": 4
        },
        "reason_zh": "该论文研究希尔伯特空间中相互作用粒子系统的随机最优控制，涉及HJB方程、粘性解、收敛性等深层数学理论，是纯粹数学严谨性的典范，与您的研究方向高度契合。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21613v1",
        "title": "Beyond URLs: Metadata Diversity and Position for Efficient LLM Pretraining",
        "summary": "Incorporating metadata in Large Language Models (LLMs) pretraining has recently emerged as a promising approach to accelerate training. However prior work highlighted only one useful signal-URLs, leaving open the question of whether other forms of metadata could yield greater benefits. In this study, we investigate a wider range of metadata types and find other types of metadata, such as fine-grained indicators of document quality that can also accelerate pretraining when prepended. We identify a common feature among effective metadata: they encode information at a finer granularity. We further introduce metadata appending as a means of improving training efficiency, where predicting an appropriate metadata as auxiliary task can help speed up pretraining. In addition, learnable meta-tokens trained with masked loss can recover part of the speedup by inducing quality-aware latent structure. Using probing, we analyze latent representations to understand how metadata shapes learning. Together, these results yield practical guidelines for integrating metadata to improve both the efficiency and effectiveness of LLM pretraining.",
        "authors": "Dongyang Fan, Diba Hashemi, Sai Praneeth Karimireddy, Martin Jaggi",
        "url": "http://arxiv.org/abs/2511.21613v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21613v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "针对核工具变量回归的统一推断，提出了有效且尖锐的置信区间构建方法，并有坚实的理论支撑，是因果分析和统计推断领域的优秀工作。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21595v1",
        "title": "On the Degrees of Freedom of some Lasso procedures",
        "summary": "The effective degrees of freedom of penalized regression models quantify the actual amount of information used to generate predictions, playing a pivotal role in model evaluation and selection. Although a closed-form estimator is available for the Lasso penalty, adaptive extensions of widely used penalized approaches, including the Adaptive Lasso and Adaptive Group Lasso, have remained without analogous theoretical characterization. This paper presents the first unbiased estimator of the effective degrees of freedom for these methods, along with their main theoretical properties, for both orthogonal and non-orthogonal designs, derived within Stein's unbiased risk estimation framework. The resulting expressions feature inflation terms influenced by the regularization parameter, coefficient signs, and least-squares estimates. These advances enable more accurate model selection criteria and unbiased prediction error estimates, illustrated through synthetic and real data. These contributions offer a rigorous theoretical foundation for understanding model complexity in adaptive regression, bridging a critical gap between theory and practice.",
        "authors": "Mauro Bernardi, Antonio Canale, Marco Stefanucci",
        "url": "http://arxiv.org/abs/2511.21595v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21595v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "深入研究了Lasso及其变体的有效自由度，提出了无偏估计量，并基于Stein的无偏风险估计框架进行了理论推导，对模型选择和理解模型复杂度有重要意义，理论严谨性极高。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21534v1",
        "title": "A Sensitivity Analysis Framework for Causal Inference Under Interference",
        "summary": "In many applications of causal inference, the treatment received by one unit may influence the outcome of another, a phenomenon referred to as interference. Although there are several frameworks for conducting causal inference in the presence of interference, practitioners often lack the data necessary to adjust for its effects. In this paper, we propose a weighting-based sensitivity analysis framework that can be used to assess the systematic bias arising from ignoring interference. Unlike most of the existing literature, we allow for the presence of unmeasured confounding, and show that the combination of interference and unmeasured confounding is a notable challenge to causal inference. We also study a third factor contributing to systematic bias: lack of transportability. Our framework enables practitioners to assess the impact of these three issues simultaneously through several easily interpretable sensitivity parameters that can reflect a wide range of intuitions about the data.",
        "authors": "Matvey Ortyashov, AmirEmad Ghassami",
        "url": "http://arxiv.org/abs/2511.21534v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21534v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "针对存在干扰和未测量混淆的因果推断，提出了基于权重的敏感性分析框架，引入了易于解释的敏感性参数，理论严谨且具有重要实践意义。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21526v1",
        "title": "Phase Transition for Stochastic Block Model with more than $\\sqrt{n}$ Communities (II)",
        "summary": "A fundamental theoretical question in network analysis is to determine under which conditions community recovery is possible in polynomial time in the Stochastic Block Model (SBM). When the number $K$ of communities remains smaller than $\\sqrt{n}$ --where $n$ denotes the number of nodes--, non-trivial community recovery is possible in polynomial time above, and only above, the Kesten--Stigum (KS) threshold, originally postulated using arguments from statistical physics.   When $K \\geq \\sqrt{n}$, Chin, Mossel, Sohn, and Wein recently proved that, in the \\emph{sparse regime}, community recovery in polynomial time is achievable below the KS threshold by counting non-backtracking paths. This finding led them to postulate a new threshold for the many-communities regime $K \\geq \\sqrt{n}$. Subsequently, Carpentier, Giraud, and Verzelen established the failure of low-degree polynomials below this new threshold across all density regimes, and demonstrated successful recovery above the threshold in certain moderately sparse settings. While these results provide strong evidence that, in the many community setting, the computational barrier lies at the threshold proposed in~Chin et al., the question of achieving recovery above this threshold still remains open in most density regimes.   The present work is a follow-up to~Carpentier et al., in which we prove Conjecture~1.4 stated therein by: \\\\ 1- Constructing a family of motifs satisfying specific structural properties; and\\\\ 2- Proving that community recovery is possible above the proposed threshold by counting such motifs.\\\\ Our results complete the picture of the computational barrier for community recovery in the SBM with $K \\geq \\sqrt{n}$ communities. They also indicate that, in moderately sparse regimes, the optimal algorithms appear to be fundamentally different from spectral methods.",
        "authors": "Alexandra Carpentier, Christophe Giraud, Nicolas Verzelen",
        "url": "http://arxiv.org/abs/2511.21526v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21526v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 3,
            "Clarity": 4
        },
        "reason_zh": "该论文是随机块模型中社区恢复相变问题的续篇，是网络分析的理论前沿，涉及严格的数学证明和算法分析，理论严谨性极高。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21514v1",
        "title": "Mechanistic Interpretability for Transformer-based Time Series Classification",
        "summary": "Transformer-based models have become state-of-the-art tools in various machine learning tasks, including time series classification, yet their complexity makes understanding their internal decision-making challenging. Existing explainability methods often focus on input-output attributions, leaving the internal mechanisms largely opaque. This paper addresses this gap by adapting various Mechanistic Interpretability techniques; activation patching, attention saliency, and sparse autoencoders, from NLP to transformer architectures designed explicitly for time series classification. We systematically probe the internal causal roles of individual attention heads and timesteps, revealing causal structures within these models. Through experimentation on a benchmark time series dataset, we construct causal graphs illustrating how information propagates internally, highlighting key attention heads and temporal positions driving correct classifications. Additionally, we demonstrate the potential of sparse autoencoders for uncovering interpretable latent features. Our findings provide both methodological contributions to transformer interpretability and novel insights into the functional mechanics underlying transformer performance in time series classification tasks.",
        "authors": "Matīss Kalnāre, Sofoklis Kitharidis, Thomas Bäck, Niki van Stein",
        "url": "http://arxiv.org/abs/2511.21514v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21514v1",
        "scores": {
            "Novelty": 3,
            "Rigor": 5,
            "Impact": 5,
            "Clarity": 5
        },
        "reason_zh": "这是一篇概念性论文，比较并澄清了因果推断三大框架（潜在结果、结构方程模型、DAG）之间的联系、优缺点，对理解因果逻辑和理论基础非常有帮助，清晰度极高。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21414v1",
        "title": "SUPN: Shallow Universal Polynomial Networks",
        "summary": "Deep neural networks (DNNs) and Kolmogorov-Arnold networks (KANs) are popular methods for function approximation due to their flexibility and expressivity. However, they typically require a large number of trainable parameters to produce a suitable approximation. Beyond making the resulting network less transparent, overparameterization creates a large optimization space, likely producing local minima in training that have quite different generalization errors. In this case, network initialization can have an outsize impact on the model's out-of-sample accuracy. For these reasons, we propose shallow universal polynomial networks (SUPNs). These networks replace all but the last hidden layer with a single layer of polynomials with learnable coefficients, leveraging the strengths of DNNs and polynomials to achieve sufficient expressivity with far fewer parameters. We prove that SUPNs converge at the same rate as the best polynomial approximation of the same degree, and we derive explicit formulas for quasi-optimal SUPN parameters. We complement theory with an extensive suite of numerical experiments involving SUPNs, DNNs, KANs, and polynomial projection in one, two, and ten dimensions, consisting of over 13,000 trained models. On the target functions we numerically studied, for a given number of trainable parameters, the approximation error and variability are often lower for SUPNs than for DNNs and KANs by an order of magnitude. In our examples, SUPNs even outperform polynomial projection on non-smooth functions.",
        "authors": "Zachary Morrow, Michael Penwarden, Brian Chen, Aurya Javeed, Akil Narayan, John D. Jakeman",
        "url": "http://arxiv.org/abs/2511.21414v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21414v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "提出了浅层通用多项式网络（SUPNs），并从理论上证明了其收敛速度与最优多项式逼近相同，并推导了准最优参数的显式公式，对函数逼近理论有重要贡献，数学严谨性极高。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21471v1",
        "title": "SpatialBench: Benchmarking Multimodal Large Language Models for Spatial Cognition",
        "summary": "Spatial cognition is fundamental to real-world multimodal intelligence, allowing models to effectively interact with the physical environment. While multimodal large language models (MLLMs) have made significant strides, existing benchmarks often oversimplify spatial cognition, reducing it to a single-dimensional metric, which fails to capture the hierarchical structure and interdependence of spatial abilities. To address this gap, we propose a hierarchical spatial cognition framework that decomposes spatial intelligence into five progressively complex levels from basic observation to high-level planning. Building upon this taxonomy, we construct SpatialBench, a large-scale, fine-grained benchmark covering 15 tasks aligned with these cognitive levels. To provide a unified evaluation across heterogeneous tasks, we further introduce a high-level capability-oriented metric that reliably assesses a model's overall spatial reasoning ability. Extensive experiments over massive MLLMs reveal distinct performance stratification across cognitive levels: models exhibit strong perceptual grounding yet remain limited in symbolic reasoning, causal inference, and planning. Additional human tests demonstrate that humans perform selective, goal-directed abstraction, while MLLMs tend to over-attend to surface details without coherent spatial intent. Our work establishes the first systematic framework for measuring hierarchical spatial cognition in MLLMs, laying the foundation for future spatially intelligent systems.",
        "authors": "Peiran Xu, Sudong Wang, Yao Zhu, Jianing Li, Yunjian Zhang",
        "url": "http://arxiv.org/abs/2511.21471v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21471v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "该论文结合EnKF和SMC^2算法，针对非线性状态空间模型中的静态参数推断，具有扎实的贝叶斯统计推断理论基础和方法创新。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21280v1",
        "title": "Improvement of Collision Avoidance in Cut-In Maneuvers Using Time-to-Collision Metrics",
        "summary": "This paper proposes a new strategy for collision avoidance system leveraging Time-to-Collision (TTC) metrics for handling cut-in scenarios, which are particularly challenging for autonomous vehicles (AVs). By integrating a deep learning with TTC calculations, the system predicts potential collisions and determines appropriate evasive actions compared to traditional TTC -based approaches.",
        "authors": "Jamal Raiyn",
        "url": "http://arxiv.org/abs/2511.21280v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21280v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 5,
            "Clarity": 4
        },
        "reason_zh": "针对A/B测试中的异质性问题，提出了局部经验贝叶斯框架，并进行了理论分析，旨在降低方差和避免偏差，对因果推断和统计学有重要贡献。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21272v1",
        "title": "Co-Training Vision Language Models for Remote Sensing Multi-task Learning",
        "summary": "With Transformers achieving outstanding performance on individual remote sensing (RS) tasks, we are now approaching the realization of a unified model that excels across multiple tasks through multi-task learning (MTL). Compared to single-task approaches, MTL methods offer improved generalization, enhanced scalability, and greater practical applicability. Recently, vision language models (VLMs) have achieved promising results in RS image understanding, grounding, and ultra-high-resolution (UHR) image reasoning, respectively. Moreover, the unified text-based interface demonstrates significant potential for MTL. Hence, in this work, we present RSCoVLM, a simple yet flexible VLM baseline for RS MTL. Firstly, we create the data curation engine, including data acquisition, offline processing and integrating, as well as online loading and weighting. This data engine effectively addresses complex RS data enviroment and generates flexible vision-language conversations. Furthermore, we propose a unified dynamic-resolution strategy to address the diverse image scales inherent in RS imagery. For UHR images, we introduce the Zoom-in Chain mechanism together with its corresponding dataset, LRS-VQA-Zoom. The strategies are flexible and effectively mitigate the computational burdens. Additionally, we significantly enhance the model's object detection capability and propose a novel evaluation protocol that ensures fair comparison between VLMs and conventional detection models. Extensive experiments demonstrate that RSCoVLM achieves state-of-the-art performance across diverse tasks, outperforming existing RS VLMs and even rivaling specialized expert models. All the training and evaluating tools, model weights, and datasets have been fully open-sourced to support reproducibility. We expect that this baseline will promote further progress toward general-purpose RS models.",
        "authors": "Qingyun Li, Shuran Ma, Junwei Luo, Yi Yu, Yue Zhou, Fengxiang Wang, Xudong Lu, Xiaoxing Wang, Xin He, Yushi Chen, Xue Yang, Junchi Yan",
        "url": "http://arxiv.org/abs/2511.21272v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21272v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "在垂直联邦学习中处理缺失值的企业利润预测问题，提出了VFEM方法，并建立了线性收敛率和统计推断框架，理论严谨性高。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21245v1",
        "title": "FIELDS: Face reconstruction with accurate Inference of Expression using Learning with Direct Supervision",
        "summary": "Facial expressions convey the bulk of emotional information in human communication, yet existing 3D face reconstruction methods often miss subtle affective details due to reliance on 2D supervision and lack of 3D ground truth. We propose FIELDS (Face reconstruction with accurate Inference of Expression using Learning with Direct Supervision) to address these limitations by extending self-supervised 2D image consistency cues with direct 3D expression parameter supervision and an auxiliary emotion recognition branch. Our encoder is guided by authentic expression parameters from spontaneous 4D facial scans, while an intensity-aware emotion loss encourages the 3D expression parameters to capture genuine emotion content without exaggeration. This dual-supervision strategy bridges the 2D/3D domain gap and mitigates expression-intensity bias, yielding high-fidelity 3D reconstructions that preserve subtle emotional cues. From a single image, FIELDS produces emotion-rich face models with highly realistic expressions, significantly improving in-the-wild facial expression recognition performance without sacrificing naturalness.",
        "authors": "Chen Ling, Henglin Shi, Hedvig Kjellström",
        "url": "http://arxiv.org/abs/2511.21245v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21245v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "数据驱动的Koopman MPC的稳定性分析，推导了渐近稳定性和递归可行性的条件，并利用Koopman算子，具有控制理论和优化收敛性的严谨理论基础。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21223v1",
        "title": "Maxitive Donsker-Varadhan Formulation for Possibilistic Variational Inference",
        "summary": "Variational inference (VI) is a cornerstone of modern Bayesian learning, enabling approximate inference in complex models that would otherwise be intractable. However, its formulation depends on expectations and divergences defined through high-dimensional integrals, often rendering analytical treatment impossible and necessitating heavy reliance on approximate learning and inference techniques. Possibility theory, an imprecise probability framework, allows to directly model epistemic uncertainty instead of leveraging subjective probabilities. While this framework provides robustness and interpretability under sparse or imprecise information, adapting VI to the possibilistic setting requires rethinking core concepts such as entropy and divergence, which presuppose additivity. In this work, we develop a principled formulation of possibilistic variational inference and apply it to a special class of exponential-family functions, highlighting parallels with their probabilistic counterparts and revealing the distinctive mathematical structures of possibility theory.",
        "authors": "Jasraj Singh, Shelvia Wongso, Jeremie Houssineau, Badr-Eddine Chérief-Abdellatif",
        "url": "http://arxiv.org/abs/2511.21223v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21223v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 3,
            "Clarity": 4
        },
        "reason_zh": "提出了可能性变分推断的原理性公式，涉及对熵和散度等核心概念的重新思考，并利用Donsker-Varadhan公式，具有极高的数学理论深度。"
    },
    {
        "id": "http://arxiv.org/abs/2511.21219v1",
        "title": "Conditional Generative Modeling of Stochastic LTI Systems: A Behavioral Approach",
        "summary": "This paper presents a data-driven model for Linear Time-Invariant (LTI) stochastic systems by sampling from the conditional probability distribution of future outputs given past input-outputs and future inputs. It operates in a fully behavioral manner, relying solely on the current trajectory and pre-collected input-output data, without requiring explicit identification of system parameters. We refer to this model as a behavioral Conditional Generative Model (CGM). We prove the convergence of the distribution of samples generated by the CGM as the size of the trajectory library increases, with an explicit characterization of the convergence rate. Furthermore, we demonstrate that the gap between the asymptotic distribution of the proposed CGM and the true posterior distribution obtained by Kalman filter, which leverages the knowledge of all system parameters and all historical data, decreases exponentially with respect to the length of past samples. Finally, we integrate this generative model into predictive controllers for stochastic LTI systems. Numerical results verify the derived bounds and demonstrate the effectiveness of the controller equipped with the proposed behavioral CGM.",
        "authors": "Jiayun Li, Yilin Mo",
        "url": "http://arxiv.org/abs/2511.21219v1",
        "pdf_url": "https://arxiv.org/pdf/2511.21219v1",
        "scores": {
            "Novelty": 4,
            "Rigor": 5,
            "Impact": 3,
            "Clarity": 4
        },
        "reason_zh": "针对随机LTI系统提出了条件生成建模方法，并证明了样本分布的收敛性及收敛速度，与卡尔曼滤波器进行了比较，具有扎实的随机过程和控制理论基础。"
    }
]