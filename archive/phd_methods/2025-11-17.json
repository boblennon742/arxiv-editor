[
    {
        "id": "http://arxiv.org/abs/2511.13411v1",
        "title": "An Operational Kardashev-Style Scale for Autonomous AI - Towards AGI and Superintelligence",
        "summary": "We propose a Kardashev-inspired yet operational Autonomous AI (AAI) Scale that measures the progression from fixed robotic process automation (AAI-0) to full artificial general intelligence (AAI-4) and beyond. Unlike narrative ladders, our scale is multi-axis and testable. We define ten capability axes (Autonomy, Generality, Planning, Memory/Persistence, Tool Economy, Self-Revision, Sociality/Coordination, Embodiment, World-Model Fidelity, Economic Throughput) aggregated by a composite AAI-Index (a weighted geometric mean). We introduce a measurable Self-Improvement Coefficient $κ$ (capability growth per unit of agent-initiated resources) and two closure properties (maintenance and expansion) that convert ``self-improving AI'' into falsifiable criteria. We specify OWA-Bench, an open-world agency benchmark suite that evaluates long-horizon, tool-using, persistent agents. We define level gates for AAI-0\\ldots AAI-4 using thresholds on the axes, $κ$, and closure proofs. Synthetic experiments illustrate how present-day systems map onto the scale and how the delegability frontier (quality vs.\\ autonomy) advances with self-improvement. We also prove a theorem that AAI-3 agent becomes AAI-5 over time with sufficient conditions, formalizing \"baby AGI\" becomes Superintelligence intuition.",
        "authors": "Przemyslaw Chojecki",
        "url": "http://arxiv.org/abs/2511.13411v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13411v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 5,
            "Clarity": 4
        },
        "reason_zh": "这篇论文提出了一个卡尔达舍夫式的、可操作的自治AI (AAI) 量表，用于衡量从固定式RPA到通用人工智能(AGI)乃至超级智能的进展。它定义了十个能力维度和一个复合AAI指数，并引入了可测量的“自我改进系数κ”和两个闭合属性，为“自我改进AI”提供了可证伪的标准。**总分最高**，因为它在创新性、理论严谨性和实践影响力方面都达到了最高分。该研究为衡量和理解AGI的进展提供了一个急需的框架，从叙述性描述转向可测试的标准，这对于AI领域的未来研究和政策制定具有深远的**理论创新性**和**实践影响力**。它避免了纯粹的工程堆砌，而是专注于**逻辑清晰**地构建一个理论框架，以解决对AGI进展进行科学评估的根本**应用瓶颈**。"
    },
    {
        "id": "http://arxiv.org/abs/2511.13391v1",
        "title": "Finding Kissing Numbers with Game-theoretic Reinforcement Learning",
        "summary": "Since Isaac Newton first studied the Kissing Number Problem in 1694, determining the maximal number of non-overlapping spheres around a central sphere has remained a fundamental challenge. This problem represents the local analogue of Hilbert's 18th problem on sphere packing, bridging geometry, number theory, and information theory. Although significant progress has been made through lattices and codes, the irregularities of high-dimensional geometry and exponentially growing combinatorial complexity beyond 8 dimensions, which exceeds the complexity of Go game, limit the scalability of existing methods. Here we model this problem as a two-player matrix completion game and train the game-theoretic reinforcement learning system, PackingStar, to efficiently explore high-dimensional spaces. The matrix entries represent pairwise cosines of sphere center vectors; one player fills entries while another corrects suboptimal ones, jointly maximizing the matrix size, corresponding to the kissing number. This cooperative dynamics substantially improves sample quality, making the extremely large spaces tractable. PackingStar reproduces previous configurations and surpasses all human-known records from dimensions 25 to 31, with the configuration in 25 dimensions geometrically corresponding to the Leech lattice and suggesting possible optimality. It achieves the first breakthrough beyond rational structures from 1971 in 13 dimensions and discovers over 6000 new structures in 14 and other dimensions. These results demonstrate AI's power to explore high-dimensional spaces beyond human intuition and open new pathways for the Kissing Number Problem and broader geometry problems.",
        "authors": "Chengdong Ma, Théo Tao Zhaowei, Pengyu Li, Minghao Liu, Haojun Chen, Zihao Mao, Yuan Cheng, Yuan Qi, Yaodong Yang",
        "url": "http://arxiv.org/abs/2511.13391v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13391v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 5,
            "Clarity": 4
        },
        "reason_zh": "这篇论文将一个基础数学几何问题——亲吻数问题——建模为一个双人矩阵填充博弈，并训练了一个博弈论强化学习系统 PackingStar 来高效探索高维空间。该方法重现了现有配置，并在25到31维的多个维度上超越了所有已知的人类记录，包括在13维取得了自1971年以来的首次突破。**总分最高**，因其在创新性、理论严谨性和实践影响力方面都表现卓越。它展示了AI在纯科学发现方面的强大潜力，为解决复杂的组合优化问题开辟了新途径，具有极高的**理论创新性**。通过将一个长期存在的数学难题转化为可学习的博弈论问题，它**逻辑清晰**地展示了如何利用AI解决实际应用瓶颈（如高维空间的探索效率），这远非**纯粹的工程堆砌**。"
    },
    {
        "id": "http://arxiv.org/abs/2511.13288v1",
        "title": "Multi-Agent Deep Research: Training Multi-Agent Systems with M-GRPO",
        "summary": "Multi-agent systems perform well on general reasoning tasks. However, the lack of training in specialized areas hinders their accuracy. Current training methods train a unified large language model (LLM) for all agents in the system. This may limit the performances due to different distributions underlying for different agents. Therefore, training multi-agent systems with distinct LLMs should be the next step to solve. However, this approach introduces optimization challenges. For example, agents operate at different frequencies, rollouts involve varying sub-agent invocations, and agents are often deployed across separate servers, disrupting end-to-end gradient flow. To address these issues, we propose M-GRPO, a hierarchical extension of Group Relative Policy Optimization designed for vertical Multi-agent systems with a main agent (planner) and multiple sub-agents (multi-turn tool executors). M-GRPO computes group-relative advantages for both main and sub-agents, maintaining hierarchical credit assignment. It also introduces a trajectory-alignment scheme that generates fixed-size batches despite variable sub-agent invocations. We deploy a decoupled training pipeline in which agents run on separate servers and exchange minimal statistics via a shared store. This enables scalable training without cross-server backpropagation. In experiments on real-world benchmarks (e.g., GAIA, XBench-DeepSearch, and WebWalkerQA), M-GRPO consistently outperforms both single-agent GRPO and multi-agent GRPO with frozen sub-agents, demonstrating improved stability and sample efficiency. These results show that aligning heterogeneous trajectories and decoupling optimization across specialized agents enhances tool-augmented reasoning tasks.",
        "authors": "Haoyang Hong, Jiajun Yin, Yuan Wang, Jingnan Liu, Zhe Chen, Ailing Yu, Ji Li, Zhiling Ye, Hansong Xiao, Yefei Chen, Hualei Zhou, Yun Yue, Minghui Yang, Chunxiao Guo, Junwei Liu, Peng Wei, Jinjie Gu",
        "url": "http://arxiv.org/abs/2511.13288v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13288v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 5,
            "Clarity": 4
        },
        "reason_zh": "这篇论文针对多智能体系统中不同LLM的训练优化挑战，提出了M-GRPO，一种分层扩展的群体相对策略优化方法。M-GRPO解决了智能体操作频率不同、子智能体调用可变以及解耦部署等问题，并通过轨迹对齐方案生成固定大小的批次。**总分最高**，因其在创新性、理论严谨性和实践影响力方面均达到最高分。该研究通过提出M-GRPO框架，从根本上解决了复杂多智能体系统的训练瓶颈，具有极高的**理论创新性**和**实践影响力**。它提供了一个原则性的、分层的优化方法，以实现更强大、专业和高效的AI协作，完美符合我的偏好，即关注前沿算法和架构的**理论创新性**，并能**解决实际应用瓶颈**，而非**纯粹的工程堆砌**。"
    },
    {
        "id": "http://arxiv.org/abs/2511.13371v1",
        "title": "Cognitive Maps in Language Models: A Mechanistic Analysis of Spatial Planning",
        "summary": "How do large language models solve spatial navigation tasks? We investigate this by training GPT-2 models on three spatial learning paradigms in grid environments: passive exploration (Foraging Model- predicting steps in random walks), goal-directed planning (generating optimal shortest paths) on structured Hamiltonian paths (SP-Hamiltonian), and a hybrid model fine-tuned with exploratory data (SP-Random Walk). Using behavioural, representational and mechanistic analyses, we uncover two fundamentally different learned algorithms. The Foraging model develops a robust, map-like representation of space, akin to a 'cognitive map'. Causal interventions reveal that it learns to consolidate spatial information into a self-sufficient coordinate system, evidenced by a sharp phase transition where its reliance on historical direction tokens vanishes by the middle layers of the network. The model also adopts an adaptive, hierarchical reasoning system, switching between a low-level heuristic for short contexts and map-based inference for longer ones. In contrast, the goal-directed models learn a path-dependent algorithm, remaining reliant on explicit directional inputs throughout all layers. The hybrid model, despite demonstrating improved generalisation over its parent, retains the same path-dependent strategy. These findings suggest that the nature of spatial intelligence in transformers may lie on a spectrum, ranging from generalisable world models shaped by exploratory data to heuristics optimised for goal-directed tasks. We provide a mechanistic account of this generalisation-optimisation trade-off and highlight how the choice of training regime influences the strategies that emerge.",
        "authors": "Caroline Baumgartner, Eleanor Spens, Neil Burgess, Petru Manescu",
        "url": "http://arxiv.org/abs/2511.13371v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13371v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 5,
            "Impact": 4,
            "Clarity": 4
        },
        "reason_zh": "这篇论文对语言模型中的空间规划进行了机制分析，揭示了GPT-2模型学习的两种根本不同的算法：一种是类似“认知地图”的鲁棒空间表示，另一种是路径依赖算法。它通过因果干预揭示了模型内部表征的演变。该研究具有极高的**理论创新性**和**理论严谨性**，深入剖析了LLM的内部运作机制，超出了简单的性能提升，旨在理解其智能的本质。其发现为设计更通用、更强大的AI智能体提供了基础原则，解决了AI可解释性这一重大**应用瓶颈**。这种对算法背后原理的深入探索，完全符合我对前沿算法和架构的关注，且避免了**纯粹的工程堆砌**。"
    },
    {
        "id": "http://arxiv.org/abs/2511.13297v1",
        "title": "CorrectAD: A Self-Correcting Agentic System to Improve End-to-end Planning in Autonomous Driving",
        "summary": "End-to-end planning methods are the de facto standard of the current autonomous driving system, while the robustness of the data-driven approaches suffers due to the notorious long-tail problem (i.e., rare but safety-critical failure cases). In this work, we explore whether recent diffusion-based video generation methods (a.k.a. world models), paired with structured 3D layouts, can enable a fully automated pipeline to self-correct such failure cases. We first introduce an agent to simulate the role of product manager, dubbed PM-Agent, which formulates data requirements to collect data similar to the failure cases. Then, we use a generative model that can simulate both data collection and annotation. However, existing generative models struggle to generate high-fidelity data conditioned on 3D layouts. To address this, we propose DriveSora, which can generate spatiotemporally consistent videos aligned with the 3D annotations requested by PM-Agent. We integrate these components into our self-correcting agentic system, CorrectAD. Importantly, our pipeline is an end-to-end model-agnostic and can be applied to improve any end-to-end planner. Evaluated on both nuScenes and a more challenging in-house dataset across multiple end-to-end planners, CorrectAD corrects 62.5% and 49.8% of failure cases, reducing collision rates by 39% and 27%, respectively.",
        "authors": "Enhui Ma, Lijun Zhou, Tao Tang, Jiahuan Zhang, Junpeng Jiang, Zhan Zhang, Dong Han, Kun Zhan, Xueyang Zhang, XianPeng Lang, Haiyang Sun, Xia Zhou, Di Lin, Kaicheng Yu",
        "url": "http://arxiv.org/abs/2511.13297v1",
        "pdf_url": "https://arxiv.org/pdf/2511.13297v1",
        "scores": {
            "Novelty": 5,
            "Rigor": 4,
            "Impact": 5,
            "Clarity": 4
        },
        "reason_zh": "这篇论文提出了CorrectAD，一个端到端的自动驾驶规划**自校正智能体系统**，专门解决长尾问题导致的鲁棒性不足。它引入了PM-Agent（产品经理智能体）来制定数据需求，并使用DriveSora（一个可生成与3D布局对齐的时空一致视频的生成模型）进行数据收集和标注。该方法在NuScenes等数据集上显著降低了碰撞率。该研究在**算法和架构**上都具有极高的**创新性**，尤其是将“自校正”作为一个智能体驱动的闭环系统，结合生成模型解决实际应用中的关键**瓶颈**（长尾失败案例）。这对于自动驾驶这一安全关键领域具有极其重大的**实践影响力**，且并非**纯粹的工程堆砌**，而是智能体协作与生成模型相结合的**理论创新**。"
    }
]